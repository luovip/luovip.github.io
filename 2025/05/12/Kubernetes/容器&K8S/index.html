<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>容器&amp;K8S - Linux技术博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Linux技术博客"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Linux技术博客"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1 微服务"><meta property="og:type" content="blog"><meta property="og:title" content="罗宇"><meta property="og:url" content="https://luovip.github.io/"><meta property="og:site_name" content="罗宇"><meta property="og:description" content="1 微服务"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://luovip.github.io/img/avatar.png"><meta property="article:published_time" content="2025-05-12T07:21:42.000Z"><meta property="article:modified_time" content="2025-05-20T14:20:41.100Z"><meta property="article:author" content="removeif"><meta property="article:tag" content="容器&amp;K8S"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://luovip.github.io/img/avatar.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2025/05/12/Kubernetes/%E5%AE%B9%E5%99%A8&K8S/"},"headline":"Linux技术博客","image":["http://example.com/img/docker&k8s.jpg"],"datePublished":"2025-05-12T07:21:42.000Z","dateModified":"2025-05-20T14:20:41.100Z","author":{"@type":"Person","name":"罗宇"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject"}},"description":"1 微服务"}</script><link rel="canonical" href="http://example.com/2025/05/12/Kubernetes/%E5%AE%B9%E5%99%A8&amp;K8S/"><link rel="icon" href="/img/favicon.svg"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark-reasonable.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Linux技术博客</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/media">音乐</a><a class="navbar-item" href="/album">相册</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/docker&amp;k8s.jpg" alt="容器&amp;K8S"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2025-05-12 15:21:42  <span class="level-item"> 罗宇 </span><a class="commentCountImg" href="/2025/05/12/Kubernetes/%E5%AE%B9%E5%99%A8&amp;K8S/#comment-container"><span class="display-none-class">/2025/05/12/Kubernetes/容器&amp;K8S/</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="4c3953c05261a2c206c3b3b0d761cc70">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>2 小时  <i class="fas fa-pencil-alt"> </i>17.8 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">容器&amp;K8S</h1><div class="content"><h1 id="1-微服务"><a href="#1-微服务" class="headerlink" title="1 微服务"></a>1 微服务</h1><span id="more"></span>

<p>&emsp;&emsp;把一个庞大的应用拆成几个小的独立的服务，再把独立的服务串起来的一种架构设计:内聚更强，更加敏捷</p>
<p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1.png" title="微服务"></p>
<h2 id="1-1-应用架构的发展"><a href="#1-1-应用架构的发展" class="headerlink" title="1.1 应用架构的发展"></a>1.1 应用架构的发展</h2><p><img src="/images/%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95.png" title="应用架构的发展"></p>
<h2 id="1-2-传统单体架构vs微服务软件架构"><a href="#1-2-传统单体架构vs微服务软件架构" class="headerlink" title="1.2 传统单体架构vs微服务软件架构"></a>1.2 传统单体架构vs微服务软件架构</h2><p>&emsp;&emsp;不同于微服务，传统的项目会包含很多功能，是一个大而全的“超级”工程</p>
<p>&emsp;&emsp;例如：以普通架构方式实现的电商平台包含：登录、权限、会员、商品库存、订单、收藏、关注、购物车等功能的多个单一项目。随着项目业务越来越复杂、开发人员越来越多，相应开发、编译、部署、技术扩展、水平扩展都会受到限制</p>
<p><img src="/images/%E4%BC%A0%E7%BB%9F%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84vs%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.png" title="传统单体架构vs微服务架构"></p>
<h2 id="1-3-基于微服务的系统架构"><a href="#1-3-基于微服务的系统架构" class="headerlink" title="1.3 基于微服务的系统架构"></a>1.3 基于微服务的系统架构</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png" title="微服务系统架构"></p>
<p>&emsp;&emsp;核心思路是拆分</p>
<p>&emsp;&emsp;单体项目的问题，通过把项目拆分成一个个小项目就可以解决</p>
<h2 id="1-4-微服务的特征"><a href="#1-4-微服务的特征" class="headerlink" title="1.4 微服务的特征"></a>1.4 微服务的特征</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E5%BE%81.png" title="微服务的特征"></p>
<h2 id="1-5-单体架构"><a href="#1-5-单体架构" class="headerlink" title="1.5 单体架构"></a>1.5 单体架构</h2><p>&emsp;&emsp;紧耦合面临的问题：</p>
<p>&emsp;&emsp;&emsp;1.故障影响范围大</p>
<p>&emsp;&emsp;&emsp;2.变更成本高</p>
<p>&emsp;&emsp;&emsp;3.无法支持大规模计算</p>
<p><img src="/images/%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84.png" title="单体架构"></p>
<p>&emsp;&emsp;如果需要加入模块C，需要更改模块A、B的代码，需要各个系统人员协调处理</p>
<h2 id="1-6-解耦架构"><a href="#1-6-解耦架构" class="headerlink" title="1.6 解耦架构"></a>1.6 解耦架构</h2><p><img src="/images/%E8%A7%A3%E8%80%A6%E6%9E%B6%E6%9E%84.png" title="解耦架构"></p>
<p>&emsp;&emsp;解耦架构的优势：</p>
<p>&emsp;&emsp;&emsp;1.模块化，缩小故障范围</p>
<p>&emsp;&emsp;&emsp;2.降低变更成本，插入新模块不影响其他模块</p>
<p>&emsp;&emsp;&emsp;3.开发人员协作更简单</p>
<p>&emsp;&emsp;&emsp;4.易于扩展</p>
<h2 id="1-7-消息队列"><a href="#1-7-消息队列" class="headerlink" title="1.7 消息队列"></a>1.7 消息队列</h2><h3 id="1-7-1-传统架构"><a href="#1-7-1-传统架构" class="headerlink" title="1.7.1 传统架构"></a>1.7.1 传统架构</h3><p><img src="/images/%E4%BC%A0%E7%BB%9F%E6%9E%B6%E6%9E%84.png" title="传统架构"></p>
<h3 id="1-7-2-消息队列架构"><a href="#1-7-2-消息队列架构" class="headerlink" title="1.7.2 消息队列架构"></a>1.7.2 消息队列架构</h3><p><img src="/images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9E%B6%E6%9E%84.png" title="消息队列架构"></p>
<h2 id="1-8-微服务面临的挑战"><a href="#1-8-微服务面临的挑战" class="headerlink" title="1.8 微服务面临的挑战"></a>1.8 微服务面临的挑战</h2><table>
<thead>
<tr>
<th></th>
<th>单体架构</th>
<th>微服务架构</th>
</tr>
</thead>
<tbody><tr>
<td>迭代速度</td>
<td>较慢</td>
<td>快</td>
</tr>
<tr>
<td>部署频率</td>
<td>不经常部署</td>
<td>经常发布</td>
</tr>
<tr>
<td>系统性能</td>
<td>吞吐量小</td>
<td>吞吐量大</td>
</tr>
<tr>
<td>系统扩展性</td>
<td>扩展性差</td>
<td>扩展性好</td>
</tr>
<tr>
<td>技术栈多样性</td>
<td>单一、封闭</td>
<td>多样、开放</td>
</tr>
<tr>
<td>运维</td>
<td>简单</td>
<td>运维复杂</td>
</tr>
<tr>
<td>部署难度</td>
<td>容易部署</td>
<td>较难部署</td>
</tr>
<tr>
<td>架构复杂度</td>
<td>较小</td>
<td>复杂度高</td>
</tr>
<tr>
<td>查错</td>
<td>简单</td>
<td>定位问题较难</td>
</tr>
<tr>
<td>管理成本</td>
<td>主要在于开发成本</td>
<td>服务治理、运维</td>
</tr>
</tbody></table>
<h2 id="1-9-虚拟机与容器的比较"><a href="#1-9-虚拟机与容器的比较" class="headerlink" title="1.9 虚拟机与容器的比较"></a>1.9 虚拟机与容器的比较</h2><p><img src="/images/%E8%99%9A%E6%8B%9F%E6%9C%BAvs%E5%AE%B9%E5%99%A8.png" title="虚拟机vs容器"></p>
<table>
<thead>
<tr>
<th>对比模块</th>
<th>虚拟机</th>
<th>容器</th>
</tr>
</thead>
<tbody><tr>
<td>占用空间</td>
<td>非常大，GB级别</td>
<td>小，MB&#x2F;KB级别</td>
</tr>
<tr>
<td>启用速度</td>
<td>慢，分钟级</td>
<td>快，秒级</td>
</tr>
<tr>
<td>运行形态</td>
<td>运行于Hypervisor</td>
<td>直接运行在宿主机内核上</td>
</tr>
<tr>
<td>并发性</td>
<td>一台宿主机上十几个，最多几 十个</td>
<td>上百个，甚至数百个</td>
</tr>
<tr>
<td>性能</td>
<td>低于宿主机</td>
<td>接近于宿主机本地进程</td>
</tr>
<tr>
<td>资源利用率</td>
<td>低</td>
<td>高</td>
</tr>
</tbody></table>
<h1 id="2-容器的基本使用"><a href="#2-容器的基本使用" class="headerlink" title="2 容器的基本使用"></a>2 容器的基本使用</h1><h2 id="2-1-容器介绍"><a href="#2-1-容器介绍" class="headerlink" title="2.1 容器介绍"></a>2.1 容器介绍</h2><p>&emsp;&emsp;容器是一个可以在共享的操作系统上将应用程序以指定格式打包并运行在一个与操作系统相关联的环境中的方法</p>
<p>&emsp;&emsp;和虚拟机相比，容器并不会打包整个操作系统，而只是打包应用程序所必须的库和设置，这将使得容器具备高效率、轻量化、系统隔离性，以上特性将会确保无论在何处部署，容器每次运行都会完全一致</p>
<p>&emsp;&emsp;容器工具：Rkt、Containerd、Docker、Podman</p>
<h2 id="2-2-部署Docker"><a href="#2-2-部署Docker" class="headerlink" title="2.2 部署Docker"></a>2.2 部署Docker</h2><p>从南京大学开源镜像站在Ubuntu上安装docker</p>
<p><img src="/images/docker%E5%AE%89%E8%A3%85.png" title="docker安装"></p>
<h3 id="2-2-1-安装依赖"><a href="#2-2-1-安装依赖" class="headerlink" title="2.2.1 安装依赖"></a>2.2.1 安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检测系统是否安装了docker</span></span><br><span class="line">root@k8s-master:~# <span class="keyword">for</span> pkg <span class="keyword">in</span> docker.io docker-doc docker-compose podman-docker containerd runc; <span class="keyword">do</span> <span class="built_in">sudo</span> apt-get remove <span class="variable">$pkg</span>; <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> apt-get update</span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> apt-get install ca-certificates curl gnupg</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-安装GPG公钥"><a href="#2-2-2-安装GPG公钥" class="headerlink" title="2.2.2 安装GPG公钥"></a>2.2.2 安装GPG公钥</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> install -m 0755 -d /etc/apt/keyrings</span><br><span class="line">root@k8s-master:~# curl -fsSL https://mirror.nju.edu.cn/docker-ce/linux/ubuntu/gpg | <span class="built_in">sudo</span> gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> <span class="built_in">chmod</span> a+r /etc/apt/keyrings/docker.gpg</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-添加Docker仓库"><a href="#2-2-3-添加Docker仓库" class="headerlink" title="2.2.3 添加Docker仓库"></a>2.2.3 添加Docker仓库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# <span class="built_in">echo</span> \</span><br><span class="line">  <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.gpg] https://mirror.nju.edu.cn/docker-ce/linux/ubuntu \</span></span><br><span class="line"><span class="string">  &quot;</span>$(. /etc/os-release &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$VERSION_CODENAME</span>&quot;</span>)<span class="string">&quot; stable&quot;</span> | \</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br></pre></td></tr></table></figure>

<h3 id="2-2-4-安装Docker"><a href="#2-2-4-安装Docker" class="headerlink" title="2.2.4 安装Docker"></a>2.2.4 安装Docker</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> apt-get update</span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拉取失败，因此在中国需要加速器</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> docker run hello-world</span><br><span class="line">Unable to find image <span class="string">&#x27;hello-world:latest&#x27;</span> locally</span><br><span class="line">docker: Error response from daemon: Get <span class="string">&quot;https://registry-1.docker.io/v2/&quot;</span>: context deadline exceeded (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line"></span><br><span class="line">Run <span class="string">&#x27;docker run --help&#x27;</span> <span class="keyword">for</span> more information</span><br></pre></td></tr></table></figure>

<h3 id="2-2-5-Docker镜像加速器"><a href="#2-2-5-Docker镜像加速器" class="headerlink" title="2.2.5 Docker镜像加速器"></a>2.2.5 Docker镜像加速器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line">root@k8s-master:~# <span class="built_in">cd</span> /etc/docker</span><br><span class="line">root@k8s-master:/etc/docker# vim daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.baidubce.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.nju.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.gcr.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker-cf.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockercf.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockertest.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.aliyuncs.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockerproxy.com&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">root@k8s-master:~# systemctl daemon-reload</span><br><span class="line">root@k8s-master:~# systemctl restart docker</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# <span class="built_in">sudo</span> docker pull hello-world</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">Digest: sha256:c41088499908a59aae84b0a49c70e86f4731e588a737f1637e73c8c09d995654</span><br><span class="line">Status: Image is up to <span class="built_in">date</span> <span class="keyword">for</span> hello-world:latest</span><br><span class="line">docker.io/library/hello-world:latest</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">hello-world   latest    74cc54e27dc4   3 months ago   10.1kB</span><br></pre></td></tr></table></figure>

<h3 id="2-2-6-重启Docker服务"><a href="#2-2-6-重启Docker服务" class="headerlink" title="2.2.6 重启Docker服务"></a>2.2.6 重启Docker服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# systemctl restart docker</span><br><span class="line">root@k8s-master:~# docker info</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:    28.1.1</span><br><span class="line"> Context:    default</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line"> Plugins:</span><br><span class="line">  buildx: Docker Buildx (Docker Inc.)</span><br><span class="line">    Version:  v0.23.0</span><br><span class="line">    Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span><br><span class="line">  compose: Docker Compose (Docker Inc.)</span><br><span class="line">    Version:  v2.35.1</span><br><span class="line">    Path:     /usr/libexec/docker/cli-plugins/docker-compose</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 2</span><br><span class="line">  Running: 1</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 1</span><br><span class="line"> Images: 2</span><br><span class="line"> Server Version: 28.1.1</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: extfs</span><br><span class="line">  Supports d_type: <span class="literal">true</span></span><br><span class="line">  Using metacopy: <span class="literal">false</span></span><br><span class="line">  Native Overlay Diff: <span class="literal">true</span></span><br><span class="line">  userxattr: <span class="literal">false</span></span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: systemd</span><br><span class="line"> Cgroup Version: 2</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: <span class="built_in">local</span></span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file <span class="built_in">local</span> splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: io.containerd.runc.v2 runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da</span><br><span class="line"> runc version: v1.2.5-0-g59923ef</span><br><span class="line"> init version: de40ad0</span><br><span class="line"> Security Options:</span><br><span class="line">  apparmor</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: <span class="built_in">builtin</span></span><br><span class="line">  cgroupns</span><br><span class="line"> Kernel Version: 6.8.0-53-generic</span><br><span class="line"> Operating System: Ubuntu 24.04.2 LTS</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 2</span><br><span class="line"> Total Memory: 3.777GiB</span><br><span class="line"> Name: k8s-master</span><br><span class="line"> ID: 6c5b4dc6-423d-47e6-a687-e75062cf4fd9</span><br><span class="line"> Docker Root Dir: /var/lib/docker</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line"> Experimental: <span class="literal">false</span></span><br><span class="line"> Insecure Registries:</span><br><span class="line">  ::1/128</span><br><span class="line">  127.0.0.0/8</span><br><span class="line"> Registry Mirrors:</span><br><span class="line">  https://docker.mirrors.ustc.edu.cn/</span><br><span class="line">  https://mirror.baidubce.com/</span><br><span class="line">  https://docker.m.daocloud.io/</span><br><span class="line">  https://mirror.ccs.tencentyun.com/</span><br><span class="line">  https://docker.nju.edu.cn/</span><br><span class="line">  https://docker.mirrors.sjtug.sjtu.edu.cn/</span><br><span class="line">  https://mirror.gcr.io/</span><br><span class="line">  https://docker.registry.cyou/</span><br><span class="line">  https://docker-cf.registry.cyou/</span><br><span class="line">  https://dockercf.jsdelivr.fyi/</span><br><span class="line">  https://docker.jsdelivr.fyi/</span><br><span class="line">  https://dockertest.jsdelivr.fyi/</span><br><span class="line">  https://mirror.aliyuncs.com/</span><br><span class="line">  https://dockerproxy.com/</span><br></pre></td></tr></table></figure>

<h2 id="2-3-操作容器"><a href="#2-3-操作容器" class="headerlink" title="2.3 操作容器"></a>2.3 操作容器</h2><h3 id="2-3-1-创建持续运行的容器"><a href="#2-3-1-创建持续运行的容器" class="headerlink" title="2.3.1 创建持续运行的容器"></a>2.3.1 创建持续运行的容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker run -d --name nginxtest nginx</span><br><span class="line">root@k8s-master:~# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND                  CREATED              STATUS              PORTS     NAMES</span><br><span class="line">b68184fd3b9b   nginx     <span class="string">&quot;/docker-entrypoint.…&quot;</span>   About a minute ago   Up About a minute   80/tcp  nginxtest</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE    COMMAND                  CREATED              STATUS               PORTS     NAMES</span><br><span class="line">b68184fd3b9b   nginx    <span class="string">&quot;/docker-entrypoint.…&quot;</span>   About a minute ago   Up About a minute     80/tcp  nginxtest</span><br><span class="line">8ea8394296ac   hello-world   <span class="string">&quot;/hello&quot;</span>            22 minutes ago    Exited (0) 22 minutes ago   goofy_brattain</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-进入容器"><a href="#2-3-2-进入容器" class="headerlink" title="2.3.2 进入容器"></a>2.3.2 进入容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker <span class="built_in">exec</span> -it nginxtest /bin/bash</span><br><span class="line">root@b68184fd3b9b:/# <span class="built_in">cat</span> /etc/nginx/nginx.conf</span><br><span class="line">root@b68184fd3b9b:/# <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">root@k8s-master:~#</span><br><span class="line"></span><br><span class="line"><span class="comment"># @后的主机名在exec后发生了变化，这就是进入容器内的标志</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-删除容器"><a href="#2-3-3-删除容器" class="headerlink" title="2.3.3 删除容器"></a>2.3.3 删除容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker ps</span><br><span class="line">CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES</span><br><span class="line">260028d6b4a2   httpd:v1   <span class="string">&quot;httpd-foreground&quot;</span>       5 seconds ago   Up 4 seconds   0.0.0.0:4000-&gt;80/tcp, [::]:4000-&gt;80/tcp   luoyudockerfile</span><br><span class="line">b68184fd3b9b   nginx      <span class="string">&quot;/docker-entrypoint.…&quot;</span>   12 hours ago    Up 12 hours    80/tcp    nginxtest</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker <span class="built_in">rm</span> -f nginxtest luoyudockerfile</span><br><span class="line">nginxtest</span><br><span class="line">luoyudockerfile</span><br><span class="line">root@k8s-master:~# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span><br></pre></td></tr></table></figure>

<h2 id="2-4-构建-使用镜像"><a href="#2-4-构建-使用镜像" class="headerlink" title="2.4 构建&amp;使用镜像"></a>2.4 构建&amp;使用镜像</h2><h3 id="2-4-1-镜像概述"><a href="#2-4-1-镜像概述" class="headerlink" title="2.4.1 镜像概述"></a>2.4.1 镜像概述</h3><p>&emsp;&emsp;镜像是一个用于创建容器的只读模板，通常来讲，包含一些额外的自定义，比如说，可以构建一个基于centos的镜像，在镜像构建时，直接包含一些应用程序，比如Apache或者其他程序，构建完成后，可以直接基于这个镜像启动容器，快速获得期望的业务<br>&emsp;&emsp;镜像可以来自公共的仓库，也可通过Dockerfile等定义文件来构建，并且把自己的镜像推送到仓库中，以备在任何地方任何时间下载使用</p>
<h3 id="2-4-2-公共镜像仓库"><a href="#2-4-2-公共镜像仓库" class="headerlink" title="2.4.2 公共镜像仓库"></a>2.4.2 公共镜像仓库</h3><p>&emsp;&emsp;Docker公共镜像仓库：<a target="_blank" rel="noopener" href="https://hub.docker.com/">https://hub.docker.com</a></p>
<p>&emsp;&emsp;Docker Hub是一个基于云端的registry服务，这个服务允许我们连接仓库代码、建立镜像、 推送镜像等功能，提供了一个集中式的容器资源管理平台，包含了各式各样的官方镜像，例如Apache、Centos以及各种企业级应用镜像，还以星级和评分来确保镜像的可靠性和适用性</p>
<p><img src="/images/%E5%85%AC%E5%85%B1%E9%95%9C%E5%83%8F%E5%BA%93.png" title="公共镜像库"></p>
<p>&emsp;&emsp;打开<a target="_blank" rel="noopener" href="https://hub.docker.com,注册一个docker/">https://hub.docker.com，注册一个Docker</a> ID，登陆后浏览各项功能</p>
<h3 id="2-4-3-镜像分层技术"><a href="#2-4-3-镜像分层技术" class="headerlink" title="2.4.3 镜像分层技术"></a>2.4.3 镜像分层技术</h3><p><img src="/images/%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82.png" title="镜像分层技术"></p>
<h3 id="2-4-4-构建镜像的方法"><a href="#2-4-4-构建镜像的方法" class="headerlink" title="2.4.4 构建镜像的方法"></a>2.4.4 构建镜像的方法</h3><p>1.docker commit<br>&emsp;&emsp;使用容器中发生更改的部分生成一个新的镜像，通常的使用场景为，基于普通镜像启动了容器，在容器内部署了所需的业务后，把当前的状态重新生成镜像，以便以当前状态快速部署业务所用</p>
<p>2.Dockerfile 创建镜像<br>&emsp;&emsp;从零开始构建自己所需的镜像，在创建镜像之初把所需的各种设置和所需要的各种应用程序包含进去，生成的镜像可直接用于业务部署</p>
<p>3.Dockerfile高频指令集</p>
<p><img src="/images/dockerfile%E6%8C%87%E4%BB%A4.png" title="dockerfile指令"></p>
<h3 id="2-4-5-Dockerfile-image"><a href="#2-4-5-Dockerfile-image" class="headerlink" title="2.4.5 Dockerfile image"></a>2.4.5 Dockerfile image</h3><p>&emsp;&emsp;在设计Dockerfile时应考虑以下事项：</p>
<p>&emsp;&emsp;&emsp;1.容器应该是暂时的</p>
<p>&emsp;&emsp;&emsp;2.避免安装不必要的软件包</p>
<p>&emsp;&emsp;&emsp;3.每个容器只应该有一个用途</p>
<p>&emsp;&emsp;&emsp;4.避免容器有过多的层</p>
<p>&emsp;&emsp;&emsp;5.多行排序</p>
<p>&emsp;&emsp;&emsp;6.建立缓存</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建dockerfile文件</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">cat</span> &gt; dockerfile &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">FROM httpd</span></span><br><span class="line"><span class="string">MAINTAINER luovipyu@163.com</span></span><br><span class="line"><span class="string">RUN echo hello luoyu dockerfile container &gt; /usr/local/apache2/htdocs/index.html</span></span><br><span class="line"><span class="string">EXPOSE 80</span></span><br><span class="line"><span class="string">WORKDIR /usr/local/apache2/htdocs/</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始构建镜像</span></span><br><span class="line">root@k8s-master:~# docker build -t httpd:v1 -f dockerfile .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker镜像</span></span><br><span class="line">root@k8s-master:~# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">httpd         v1        d6d24a446dd4   25 seconds ago   148MB</span><br><span class="line">nginx         latest    a830707172e8   3 weeks ago      192MB</span><br><span class="line">hello-world   latest    74cc54e27dc4   3 months ago     10.1kB</span><br><span class="line"></span><br><span class="line">注明：如果文件名是Dockerfile时可不指定</span><br><span class="line">docker build -t web:v1 .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果用的是containerd，dockerfile方式构建容器镜像的命令就是下面这样的</span></span><br><span class="line">nerdctl build  -t httpd:v1 -f dockerfile .</span><br><span class="line">nerdctl images</span><br></pre></td></tr></table></figure>

<h3 id="2-4-6-使用Dockerfile镜像"><a href="#2-4-6-使用Dockerfile镜像" class="headerlink" title="2.4.6 使用Dockerfile镜像"></a>2.4.6 使用Dockerfile镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用httpd:v1的镜像在本机4000端口上提供一个名为luoyudockerfile的容器</span></span><br><span class="line">root@k8s-master:~# docker run -d -p 4000:80 --name luoyudockerfile httpd:v1</span><br><span class="line">260028d6b4a2b11cd2cfca9ab6ae9d406cc8fa9afd33131db03c880cc235e68f</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker ps</span><br><span class="line">CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES</span><br><span class="line">260028d6b4a2   httpd:v1   <span class="string">&quot;httpd-foreground&quot;</span>       5 seconds ago   Up 4 seconds   0.0.0.0:4000-&gt;80/tcp, [::]:4000-&gt;80/tcp   luoyudockerfile</span><br><span class="line">b68184fd3b9b   nginx      <span class="string">&quot;/docker-entrypoint.…&quot;</span>   12 hours ago    Up 12 hours    80/tcp    nginxtest</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# curl http://127.0.0.1:4000</span><br><span class="line">hello luoyu dockerfile container</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果用的是containerd，dockerfile方式构建容器镜像的使用命令就是下面这样的</span></span><br><span class="line">nerdctl run -d -p 4000:80 --name luoyudockerfile httpd:v1</span><br><span class="line">nerdctl ps</span><br></pre></td></tr></table></figure>

<h3 id="2-4-7-关于镜像命名"><a href="#2-4-7-关于镜像命名" class="headerlink" title="2.4.7 关于镜像命名"></a>2.4.7 关于镜像命名</h3><p>1.镜像命名格式：REPOSITORY+TAG，使用版本号作为命名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">httpd         v1        d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">nginx         latest    a830707172e8   3 weeks ago    192MB</span><br><span class="line">hello-world   latest    74cc54e27dc4   3 months ago   10.1kB</span><br></pre></td></tr></table></figure>

<p>2.关于latest tag的说明</p>
<p>&emsp;&emsp;如果在建立镜像时没有指定Tag，会使用默认值latest，所以，当看到一个镜像的Tag处显示latest的时候，并不一定意味着此版本是最新版，而只意味着在建立镜像的时候，没有指定Tag</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker build -t web .</span><br><span class="line">root@k8s-master:~# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">httpd         v1        d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">web           latest    d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">nginx         latest    a830707172e8   3 weeks ago    192MB</span><br><span class="line">hello-world   latest    74cc54e27dc4   3 months ago   10.1kB</span><br></pre></td></tr></table></figure>

<h3 id="2-4-8-删除镜像"><a href="#2-4-8-删除镜像" class="headerlink" title="2.4.8 删除镜像"></a>2.4.8 删除镜像</h3><p>&emsp;&emsp;删除一个特定的镜像，需要知道该镜像的ID或者标签(repository:tag)。或者，如果只记得镜像的部分ID，可以使用这个ID来删除镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# docker images</span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">httpd         v1        d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">web           latest    d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">nginx         latest    a830707172e8   3 weeks ago    192MB</span><br><span class="line">hello-world   latest    74cc54e27dc4   3 months ago   10.1kB</span><br><span class="line">root@k8s-master:~# docker rmi web:latest</span><br><span class="line">Untagged: web:latest</span><br><span class="line">root@k8s-master:~# docker rmi 74cc54e27dc4</span><br><span class="line">Error response from daemon: conflict: unable to delete 74cc54e27dc4 (must be forced) - image is being used by stopped container 8ea8394296ac</span><br><span class="line">root@k8s-master:~# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE         COMMAND    CREATED        STATUS                    PORTS     NAMES</span><br><span class="line">8ea8394296ac   hello-world   <span class="string">&quot;/hello&quot;</span>   13 hours ago   Exited (0) 13 hours ago             goofy_brattain</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker <span class="built_in">rm</span> 8ea8394296ac</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker rmi 74cc54e27dc4</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# docker images</span><br><span class="line">\REPOSITORY   TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">httpd        v1        d6d24a446dd4   11 hours ago   148MB</span><br><span class="line">nginx        latest    a830707172e8   3 weeks ago    192MB</span><br></pre></td></tr></table></figure>

<h3 id="2-4-9-私有镜像仓库"><a href="#2-4-9-私有镜像仓库" class="headerlink" title="2.4.9 私有镜像仓库"></a>2.4.9 私有镜像仓库</h3><p>&emsp;&emsp;构建私有镜像存储考虑：</p>
<p>&emsp;&emsp;&emsp;1.交付时效，例如，下载并运行镜像，需要消耗带宽和时间</p>
<p>&emsp;&emsp;&emsp;2.机房不允许接入外网</p>
<p>&emsp;&emsp;&emsp;3.镜像私密，不允许将数据放到外网</p>
<p>&emsp;&emsp;&emsp;4.内网速率更高</p>
<p>1.什么是Registry？</p>
<p>&emsp;&emsp;Registry是一个无状态、高度可扩展的服务，可以存储和分发镜像</p>
<p>&emsp;&emsp;Registry是一个基于Apache License许可的开源服务<br>2.为什么使用Registry？</p>
<p>&emsp;&emsp;严格控制映像存储位置</p>
<p>&emsp;&emsp;拥有完全属于自己的镜像分发渠道</p>
<p>&emsp;&emsp;将镜像存储和分布紧密集成到内部开发工作流程中</p>
<p>3.部署Registry步骤如下：如果选用Harbor，请参考Gitee文档</p>
<p>&emsp;&emsp;下载Docker官方最新版的Registry镜像 2、启动Registry容器</p>
<p>&emsp;&emsp;下载测试镜像</p>
<p>&emsp;&emsp;将测试镜像上传至自己的私有仓库</p>
<p>&emsp;&emsp;验证从自有仓库下载并启动容器</p>
<h1 id="3-部署Harbor私有仓库"><a href="#3-部署Harbor私有仓库" class="headerlink" title="3 部署Harbor私有仓库"></a>3 部署Harbor私有仓库</h1><p>&emsp;&emsp;在现代软件开发中，容器化应用已经成为主流，而容器镜像仓库则是确保容器镜像安全、管理和分发的重要工具。Harbor作为一款开源的企业级容器镜像仓库管理工具，不仅支持多种认证方式，还提供镜像复制、漏洞扫描和用户访问控制等功能，为企业提供了一个安全、高效的镜像管理方案</p>
<table>
<thead>
<tr>
<th>主机名</th>
<th>角色</th>
<th>IP</th>
<th>VMware网络类型</th>
<th>用户名</th>
<th>密码</th>
<th>系统</th>
</tr>
</thead>
<tbody><tr>
<td>harbor</td>
<td>Harbor主机</td>
<td>192.168.8.52</td>
<td>NAT</td>
<td>root</td>
<td>harbor</td>
<td>RHEL-9.5</td>
</tr>
</tbody></table>
<h2 id="3-1-RedHat9镜像源配置"><a href="#3-1-RedHat9镜像源配置" class="headerlink" title="3.1 RedHat9镜像源配置"></a>3.1 RedHat9镜像源配置</h2><h3 id="3-1-1-国内镜像源"><a href="#3-1-1-国内镜像源" class="headerlink" title="3.1.1 国内镜像源"></a>3.1.1 国内镜像源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@harbor ~]# <span class="built_in">cd</span> /etc/yum.repos.d</span><br><span class="line">[root@harbor yum.repos.d]# ll</span><br><span class="line">-rw-r--r--. 1 root root 358 May 14 11:25 redhat.repo</span><br><span class="line"></span><br><span class="line">[root@harbor yum.repos.d]# vim aliyun_yum.repo</span><br><span class="line">[ali_baseos]</span><br><span class="line">name=ali_baseos</span><br><span class="line">baseurl=https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os/</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[ali_appstream]</span><br><span class="line">name=ali_appstream</span><br><span class="line">baseurl=https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">[root@harbor yum.repos.d]# yum makecache</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据需要选择是否更新yum源</span></span><br><span class="line">[root@harbor yum.repos.d]# yum -y update</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-本地yum源配置"><a href="#3-1-2-本地yum源配置" class="headerlink" title="3.1.2 本地yum源配置"></a>3.1.2 本地yum源配置</h3><p>&emsp;&emsp;配置本地yum源可以创建一个本地的软件包存储库，以便更快地安装、更新和管理软件包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹并将光盘挂载到新建的文件中</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">mkdir</span> -p /GuaZai/Iso</span><br><span class="line">[root@harbor ~]# mount /dev/sr0 /GuaZai/Iso</span><br><span class="line">mount: /GuaZai/Iso: WARNING: <span class="built_in">source</span> write-protected, mounted read-only.</span><br><span class="line"></span><br><span class="line">[root@harbor ~]# <span class="built_in">cd</span> /GuaZai/Iso</span><br><span class="line">[root@harbor Iso]# <span class="built_in">ls</span></span><br><span class="line">AppStream  BaseOS  EFI  EULA  extra_files.json  GPL  images  isolinux  media.repo  RPM-GPG-KEY-redhat-beta  RPM-GPG-KEY-redhat-release</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置yum文件</span></span><br><span class="line">[root@harbor ~]# vim /etc/yum.repos.d/rhel9.repo</span><br><span class="line">[BaseOS]</span><br><span class="line">name=rhel9-BaseOS</span><br><span class="line">baseurl=file:///GuaZai/Iso/BaseOS</span><br><span class="line">gpgcheck=0</span><br><span class="line">[Appstream]</span><br><span class="line">name=rhel9-Appstream</span><br><span class="line">baseurl=file:///GuaZai/Iso/AppStream</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看仓库序列</span></span><br><span class="line">[root@harbor ~]# yum repolist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成yum缓存</span></span><br><span class="line">[root@harbor ~]# yum makecache</span><br></pre></td></tr></table></figure>

<h2 id="3-2-主机名和IP地址映射"><a href="#3-2-主机名和IP地址映射" class="headerlink" title="3.2 主机名和IP地址映射"></a>3.2 主机名和IP地址映射</h2><p>&emsp;&emsp;配置Harbor主机的主机名和IP地址映射，映射文件“&#x2F;etc&#x2F;hosts”加入如下内容</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@harbor ~]# vim /etc/hosts</span><br><span class="line">192.168.8.52 registry.luovip.cn</span><br></pre></td></tr></table></figure>

<h2 id="3-3-部署Docker-CE"><a href="#3-3-部署Docker-CE" class="headerlink" title="3.3 部署Docker CE"></a>3.3 部署Docker CE</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检测系统是否安装了docker并卸载旧版本的容器</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> dnf remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine \</span><br><span class="line">                  podman \</span><br><span class="line">                  runc</span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> yum install -y yum-utils</span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> dnf -y install dnf-plugins-core</span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> dnf config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装docker</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> sed -i <span class="string">&#x27;s+https://download.docker.com+https://mirror.nju.edu.cn/docker-ce+&#x27;</span> /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker状态</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> --now docker</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.</span><br><span class="line">[root@harbor ~]# <span class="built_in">sudo</span> systemctl status docker</span><br><span class="line">[root@harbor ~]# docker info                         </span><br></pre></td></tr></table></figure>

<h2 id="3-4-Docker镜像加速器"><a href="#3-4-Docker镜像加速器" class="headerlink" title="3.4 Docker镜像加速器"></a>3.4 Docker镜像加速器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@harbor ~]# <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line">[root@harbor ~]# <span class="built_in">cd</span> /etc/docker</span><br><span class="line">[root@harbor docker]# vim /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.baidubce.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.nju.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.gcr.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker-cf.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockercf.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockertest.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.aliyuncs.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockerproxy.com&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;data-root&quot;</span>: <span class="string">&quot;/data/docker&quot;</span>   <span class="comment"># 自定义Docker的镜像存储路径</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[root@harbor ~]# <span class="built_in">mkdir</span> -p /data/docker</span><br><span class="line">[root@harbor ~]# <span class="built_in">cp</span> -a /var/lib/docker/* /data/docker/</span><br><span class="line"></span><br><span class="line">[root@harbor ~]# systemctl daemon-reload</span><br><span class="line">[root@harbor ~]# systemctl restart docker</span><br><span class="line">[root@harbor ~]# docker info</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">[root@harbor ~]# docker pull nginx</span><br><span class="line">[root@harbor ~]# docker images</span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED       SIZE</span><br><span class="line">nginx        latest    a830707172e8   3 weeks ago   192MB</span><br></pre></td></tr></table></figure>

<h2 id="3-5-Compose支持"><a href="#3-5-Compose支持" class="headerlink" title="3.5 Compose支持"></a>3.5 Compose支持</h2><p>&emsp;&emsp;添加Compose支持，并启动Docker服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载docker-compose并放在/usr/local/bin下</span></span><br><span class="line">curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/v2.36.0/docker-compose-linux-x86_64&quot;</span> -o /usr/local/bin/docker-compose</span><br><span class="line"></span><br><span class="line"><span class="built_in">chmod</span> +x /usr/local/bin/docker-compose</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br><span class="line">[root@harbor ~]# docker-compose version</span><br><span class="line">Docker Compose version v2.36.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注明：github可能会访问不了，故先从github下载到本地，再上传到服务器</span></span><br><span class="line">https://github.com/docker/compose/releases</span><br></pre></td></tr></table></figure>

<h2 id="3-6-下载Harbor"><a href="#3-6-下载Harbor" class="headerlink" title="3.6 下载Harbor"></a>3.6 下载Harbor</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@harbor ~]# wget https://github.com/goharbor/harbor/releases/download/v2.13.0/harbor-offline-installer-v2.13.0.tgz</span><br><span class="line"></span><br><span class="line">[root@harbor ~]# tar xf harbor-offline-installer-v2.13.0.tgz -C /usr/local/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用docker load命令将解压后的tar文件加载为Docker镜像</span></span><br><span class="line">[root@harbor ~]# <span class="built_in">cd</span> /usr/local/bin</span><br><span class="line">[root@harbor bin]# ll</span><br><span class="line">total 72004</span><br><span class="line">-rwxr-xr-x. 1 root root 73731911 May 14 14:25 docker-compose</span><br><span class="line">drwxr-xr-x. 2 root root      123 May 14 16:33 harbor</span><br><span class="line">[root@harbor bin]# <span class="built_in">cd</span> harbor</span><br><span class="line">[root@harbor harbor]# docker load -i harbor.v2.13.0.tar.gz</span><br></pre></td></tr></table></figure>

<h2 id="3-7-修改harbor-yml文件"><a href="#3-7-修改harbor-yml文件" class="headerlink" title="3.7 修改harbor.yml文件"></a>3.7 修改harbor.yml文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> harbor.yml.tmpl harbor.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 备份harbor.yml文件</span></span><br><span class="line"><span class="built_in">cp</span> harbor.yml harbor.yml.bak</span><br><span class="line"></span><br><span class="line">[root@harbor ~]# vim /usr/local/bin/harbor/harbor.yml</span><br><span class="line">1.修改hostname为192.168.8.52</span><br><span class="line">2.修改http的端口为82</span><br><span class="line">3.修改harbor_admin_password为admin</span><br><span class="line"><span class="comment"># 如果不启用https就注释掉12行-20行</span></span><br></pre></td></tr></table></figure>

<h2 id="3-8-安装Harbor"><a href="#3-8-安装Harbor" class="headerlink" title="3.8 安装Harbor"></a>3.8 安装Harbor</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载配置并安装</span></span><br><span class="line">[root@harbor harbor]# ./prepare</span><br><span class="line">[root@harbor harbor]# ./install.sh</span><br><span class="line">...</span><br><span class="line">[Step 5]: starting Harbor ...</span><br><span class="line">[+] Running 10/10</span><br><span class="line"> ✔ Network harbor_harbor        Created    0.0s                                                    </span><br><span class="line"> ✔ Container harbor-log         Started    0.3s                                                      </span><br><span class="line"> ✔ Container registryctl        Started    0.8s                                                    </span><br><span class="line"> ✔ Container harbor-db          Started    1.2s                                                     </span><br><span class="line"> ✔ Container redis              Started    1.2s                                                 </span><br><span class="line"> ✔ Container harbor-portal      Started    1.2s                                                          </span><br><span class="line"> ✔ Container registry           Started    1.3s                                                 </span><br><span class="line"> ✔ Container harbor-core        Started    1.4s                                              </span><br><span class="line"> ✔ Container harbor-jobservice  Started    2.0s                                               </span><br><span class="line"> ✔ Container nginx              Started    2.0s                                           </span><br><span class="line">✔ ----Harbor has been installed and started successfully.----</span><br></pre></td></tr></table></figure>

<h2 id="3-9-重启Harbor"><a href="#3-9-重启Harbor" class="headerlink" title="3.9 重启Harbor"></a>3.9 重启Harbor</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@harbor harbor]# docker-compose down</span><br><span class="line">[root@harbor harbor]# ./prepare</span><br><span class="line">[root@harbor harbor]# docker-compose up -d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 浏览器访问Harbor   http://192.168.8.52:82  用户名/密码:admin/admin</span></span><br></pre></td></tr></table></figure>

<h2 id="3-10-生成服务文件"><a href="#3-10-生成服务文件" class="headerlink" title="3.10 生成服务文件"></a>3.10 生成服务文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/harbor.service &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Harbor</span></span><br><span class="line"><span class="string">After=docker.service systemd-networkd.service systemd-resolved.service</span></span><br><span class="line"><span class="string">Requires=docker.service</span></span><br><span class="line"><span class="string">Documentation=http://github.com/vmware/harbor</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=simple</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">RestartSec=5</span></span><br><span class="line"><span class="string">ExecStart=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml up</span></span><br><span class="line"><span class="string">ExecStop=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml down</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">[root@harbor ~]# systemctl daemon-reload</span><br><span class="line">[root@harbor ~]# systemctl <span class="built_in">enable</span> harbor --now</span><br><span class="line">[root@harbor ~]# systemctl stop harbor</span><br><span class="line">[root@harbor ~]# systemctl status harbor</span><br><span class="line">[root@harbor ~]# systemctl start harbor</span><br><span class="line">[root@harbor ~]# systemctl restart harbor</span><br></pre></td></tr></table></figure>

<h2 id="3-11-推送镜像到Harbor"><a href="#3-11-推送镜像到Harbor" class="headerlink" title="3.11 推送镜像到Harbor"></a>3.11 推送镜像到Harbor</h2><p>&emsp;&emsp;将registry.luovip.cn以及其对应的IP添加到&#x2F;etc&#x2F;hosts，然后将上述实验中的httpd:v1镜像，改名为带上IP:PORT形式，上传的镜像到本地仓库</p>
<p>1.添加域名解析</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# vim /etc/hosts</span><br><span class="line">192.168.8.52 registry.luovip.cn</span><br></pre></td></tr></table></figure>

<p>2.编辑文件“&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service”，输入以下内容。其中，my.harbor.com是Harbor主机的主机名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# vim /usr/lib/systemd/system/docker.service</span><br><span class="line">ExecStart=/usr/bin/dockerd --insecure-registry registry.luovip.cn</span><br></pre></td></tr></table></figure>

<p>3.编辑“&#x2F;etc&#x2F;docker&#x2F;daemon.json”文件，在该文件中指定私有镜像仓库地址</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# vim /etc/docker/daemon.json</span><br><span class="line"><span class="string">&quot;insecure-registries&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;192.168.8.52:82&quot;</span></span><br><span class="line">  ]</span><br><span class="line">[root@docker ~]# systemctl daemon-reload</span><br><span class="line">[root@docker ~]# systemctl restart docker.service</span><br></pre></td></tr></table></figure>

<p>4.推送的命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Docker推送命令:</span></span><br><span class="line">1.在项目中标记镜像:</span><br><span class="line">docker tag SOURCE_IMAGE[:TAG] 192.168.8.52:82/library/REPOSITORY[:TAG]</span><br><span class="line">2.推送镜像到当前项目：</span><br><span class="line">docker push 192.168.8.52:82/library/REPOSITORY[:TAG]</span><br><span class="line"></span><br><span class="line">Podman推送命令：</span><br><span class="line">1.推送镜像到当前项目：</span><br><span class="line">podman push IMAGE_ID 192.168.8.52:82/library/REPOSITORY[:TAG]</span><br></pre></td></tr></table></figure>

<p>5.推送镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# docker images</span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">tomcat       latest    c6c6349a7df2   47 hours ago   468MB</span><br><span class="line">nginx        latest    a830707172e8   4 weeks ago    192MB</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker login 192.168.8.52:82</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker tag c6c6349a7df2 192.168.8.52:82/library/tomcat:v2</span><br><span class="line">[root@docker ~]# docekr images</span><br><span class="line">-bash: docekr: <span class="built_in">command</span> not found</span><br><span class="line">[root@docker ~]# docker images</span><br><span class="line">REPOSITORY                       TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">192.168.8.52:82/library/tomcat   v2        c6c6349a7df2   47 hours ago   468MB</span><br><span class="line">tomcat                           latest    c6c6349a7df2   47 hours ago   468MB</span><br><span class="line">nginx                            latest    a830707172e8   4 weeks ago    192MB</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker push 192.168.8.52:82/library/tomcat:v2</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker pull 192.168.8.52:82/library/tomcat:v2</span><br></pre></td></tr></table></figure>

<h1 id="4-管理容器的资源"><a href="#4-管理容器的资源" class="headerlink" title="4 管理容器的资源"></a>4 管理容器的资源</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建容器并观察内存量</span></span><br><span class="line">[root@docker ~]# docker run -d --name=httpd_server httpd</span><br><span class="line">[root@docker ~]# docker run -d --name=httpd_tomcat tomcat</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND              CREATED         STATUS         PORTS      NAMES</span><br><span class="line">796227a2aac7   tomcat    <span class="string">&quot;catalina.sh run&quot;</span>    2 minutes ago   Up 2 minutes   8080/tcp   httpd_tomcat</span><br><span class="line">b025ca41d951   httpd     <span class="string">&quot;httpd-foreground&quot;</span>   3 minutes ago   Up 3 minutes   80/tcp     httpd_server</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker <span class="built_in">exec</span> -it httpd_server grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:        3974748 kB</span><br><span class="line">[root@docker ~]# docker <span class="built_in">exec</span> -it httpd_tomcat grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:        3974748 kB</span><br></pre></td></tr></table></figure>

<h2 id="4-1-容器的内存配额"><a href="#4-1-容器的内存配额" class="headerlink" title="4.1 容器的内存配额"></a>4.1 容器的内存配额</h2><p>&emsp;&emsp;根据以上得出结论，每个容器的内存量，全部等于物理宿主机的内存总量，这意味这更好的性能，但同时也意味着一旦业务需求上升，将有可能发生资源争用，这通常在运维规划时，应当极力避免</p>
<p>&emsp;&emsp;容器可使用的内存：物理内存和交换空间(Swap)</p>
<p>&emsp;&emsp;Docker默认没有设置内存限制。可以通过相关选项限制设置：</p>
<p>&emsp;&emsp;&emsp;1.-m(–memory)：设置容器可用的最大内存，该值最低为4MB</p>
<p>&emsp;&emsp;&emsp;2.–memory-swap：允许容器置入磁盘交换空间中的内存大小</p>
<h3 id="4-1-1-用户内存限制"><a href="#4-1-1-用户内存限制" class="headerlink" title="4.1.1 用户内存限制"></a>4.1.1 用户内存限制</h3><p>Docker提供4种方式设置容器的用户内存使用:</p>
<p>1.对容器内存使用无限制（两个选项都不使用）</p>
<p>2.设置内存限制并取消<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4&spm=1001.2101.3001.7020">交换空间</a>内存限制</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用300内存和尽可能多的交换空间</span></span><br><span class="line">[root@docker ~]# docker run -it -m 300M --memory-swap -1 ubuntu /bin/bash</span><br></pre></td></tr></table></figure>

<p>3.只设置内存限制</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 300MB的内存和300MB的交换空间</span></span><br><span class="line"> <span class="comment"># 默认情况下虚拟内存总量将设置为内存大小的两倍，因此容器能使用300M的交换空间</span></span><br><span class="line">[root@docker ~]# docker run -it -m 300M ubuntu /bin/bash</span><br></pre></td></tr></table></figure>

<p>4.同时设置内存和交换空间</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 300MB的内存和700MB的交换空间</span></span><br><span class="line">[root@docker ~]# docker run -it -m 300M --memory-swap 700m ubuntu /bin/bash</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-内核内存限制"><a href="#4-1-2-内核内存限制" class="headerlink" title="4.1.2 内核内存限制"></a>4.1.2 内核内存限制</h3><p>&emsp;&emsp;内核内存不能交换到磁盘中，无法使用交换空间，消耗过多可能导致其阻塞系统服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在500MB的内存中，可以使用最高50MB的内核内存</span></span><br><span class="line">[root@docker ~]# docker run -it -m 500M --kernel-memory 50M ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只可以使用50MB的内核内存</span></span><br><span class="line">[root@docker ~]# docker run -it --kernel-memory 50M ubuntu /bin/bash</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-内存预留实现软限制"><a href="#4-1-3-内存预留实现软限制" class="headerlink" title="4.1.3 内存预留实现软限制"></a>4.1.3 内存预留实现软限制</h3><p>&emsp;&emsp;使用–memory-reservation选项设置内存预留，它是一种内存软限制，允许更多的内存共享。设置后，Docker将检测内存争用或内存不足，并强制容器将其内存消耗限制为预留值。</p>
<p>&emsp;&emsp;内存预留值应当始终低于硬限制，作为一个软限制功能，内存预留并不能保证不会超过限制</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 限制内存为500MB，内存预留值(软限制)为200MB。</span></span><br><span class="line"><span class="comment"># 当容器消耗内存大于200MB、小于500MB时，下一次系统内存回收将尝试将容器内存缩减到200MB以下</span></span><br><span class="line">[root@docker ~]# docker run -it -m 500M --memory-reservation 200M ubuntu /bin/bash</span><br><span class="line">docker run –it –m 500M --memory-reservation 200M ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置内存软限制为1GB</span></span><br><span class="line">[root@docker ~]# docker run -it —-memory-reservation 1G ubuntu /bin/bash</span><br></pre></td></tr></table></figure>

<h2 id="4-2-容器的CPU配额"><a href="#4-2-容器的CPU配额" class="headerlink" title="4.2 容器的CPU配额"></a>4.2 容器的CPU配额</h2><p>&emsp;&emsp;默认情况下，所有容器都可以使用相同的CPU资源，并且没有任何限制，这和内存问题一样，一旦CPU需求业务上升，同样会引起CPU资源的争用，但是和内存指定绝对量的不同，CPU是通过指定相对权重值来进行的配额</p>
<p>&emsp;&emsp;使用–cpu-shares参数对CPU来进行配额分配，默认情况下，这个值为1024</p>
<p>&emsp;&emsp;当前容器中的业务空闲时，其他的容器有权利使用其空闲的CPU周期，这将确保业务的性能</p>
<p>&emsp;&emsp;CPU限额的分配，只有在物理机资源不足的时候才会生效，并且是根据不同的优先级进行的，当其他容器空闲时，忙碌的容器可以获得全部可用的CPU资源</p>
<h3 id="4-2-1-CPU份额限制"><a href="#4-2-1-CPU份额限制" class="headerlink" title="4.2.1 CPU份额限制"></a>4.2.1 CPU份额限制</h3><p>&emsp;&emsp;-c(–cpu-shares)选项将CPU份额权重设置为指定的值</p>
<p>&emsp;&emsp;默认值为1024，如果设置为0，系统将忽略该值并使用默认值1024</p>
<h3 id="4-2-2-CPU周期限制"><a href="#4-2-2-CPU周期限制" class="headerlink" title="4.2.2 CPU周期限制"></a>4.2.2 CPU周期限制</h3><p>&emsp;&emsp;–cpu-period选项(以μs为单位)设置CPU周期以限制容器CPU资源的使用</p>
<p>&emsp;&emsp;默认的CFS(完全公平调度器)周期为100ms(100000μs)</p>
<p>&emsp;&emsp;通常将–cpu-period与–cpu-quota这两个选项配合使用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果只有1个CPU，则容器可以每50ms(50000μs)获得50%(25000/50000)的CPU运行时间</span></span><br><span class="line">[root@docker ~]# docker run -it --cpu-period=50000 --cpu-quota=25000 ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可用--cpus选项指定容器的可用CPU资源来达到同样的目的</span></span><br><span class="line"><span class="comment"># --cpus选项值是一个浮点数，默认值为0.000，表示不受限制</span></span><br><span class="line"><span class="comment"># 上述可改为</span></span><br><span class="line">[root@docker ~]# docker run -it --cpus=0.5 ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># --cpu-period和--cpu-quota选项都是以1个CPU为基准</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-3-CPU放置限制"><a href="#4-2-3-CPU放置限制" class="headerlink" title="4.2.3 CPU放置限制"></a>4.2.3 CPU放置限制</h3><p>&emsp;&emsp;–cpuset-cpus选项限制容器进程在指定的CPU上执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 容器中的进程可以在cpu1和cpu3上执行</span></span><br><span class="line">[root@docker ~]# docker run -it --cpuset-cpus=<span class="string">&quot;1,3&quot;</span> ubuntu:14.04 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 容器中的进程可以在cpu0、cpu1和cpu 2上执行</span></span><br><span class="line">[root@docker ~]# docker run -it --cpuset-cpus=<span class="string">&quot;0-2&quot;</span> ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-CPU配额限制"><a href="#4-2-4-CPU配额限制" class="headerlink" title="4.2.4 CPU配额限制"></a>4.2.4 CPU配额限制</h3><p>&emsp;&emsp;–cpu-quota选项限制容器的CPU配额，默认值为0表示容器占用100%的CPU资源个CPU</p>
<p>&emsp;&emsp;CFS用于处理进程执行的资源分配，是由内核使用的默认Linux调度程序。将此值设置50000意味着限制容器至多使用CPU资源的50%。对于多个CPU而言，调整–cpu-quota选项必要的</p>
<h2 id="4-3-容器的I-O配额"><a href="#4-3-容器的I-O配额" class="headerlink" title="4.3 容器的I&#x2F;O配额"></a>4.3 容器的I&#x2F;O配额</h2><p>&emsp;&emsp;默认情况下，所有容器都可以使用相同的I&#x2F;O资源(500权重)，并且没有任何限制，这和内存、 CPU问题一样，一旦I&#x2F;O需求业务上升，硬盘读写会变得非常迟缓，所以为了更好的提供服务，也应该对容器使用硬盘方面进行调整</p>
<p>&emsp;&emsp;块I&#x2F;O带宽(Block I&#x2F;O Bandwidth，Blkio)是另一种可以限制容器使用的资源</p>
<p>&emsp;&emsp;块I&#x2F;O指磁盘的写，Docker可通过设置权重限制每秒字节数(B&#x2F;s)和每秒I&#x2F;O次数(IO&#x2F;s)的方式控制容器读写盘的带宽</p>
<h3 id="4-3-1-设置块I-O权重"><a href="#4-3-1-设置块I-O权重" class="headerlink" title="4.3.1 设置块I&#x2F;O权重"></a>4.3.1 设置块I&#x2F;O权重</h3><p>&emsp;&emsp;–blkio-weight选项更改比例(原默认为500)，设置相对于所有其他正在运行的容器的块I&#x2F;O带宽权重</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两个有不同块I/O带宽权重的容器</span></span><br><span class="line">[root@docker ~]# docker run -it --name c1 --blkio-weight 300 ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker run -it --name c2 --blkio-weight 600 ubuntu /bin/bash</span><br><span class="line"></span><br><span class="line">在以下案例中，权重为600的容器将比300的在I/O能力方面多出两倍:</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker run -d --name 300io --blkio-weight 300 httpd</span><br><span class="line"></span><br><span class="line">[root@docker ~]# docker run -d --name 600io --blkio-weight 600 httpd</span><br><span class="line"></span><br><span class="line">命令测试I/O性能:</span><br><span class="line">[root@docker ~]# <span class="keyword">time</span> <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=test.out bs=1M count=1024</span><br><span class="line">1024+0 records <span class="keyword">in</span></span><br><span class="line">1024+0 records out</span><br><span class="line">1073741824 bytes (1.1 GB, 1.0 GiB) copied, 4.05265 s, 265 MB/s</span><br><span class="line"></span><br><span class="line">real    0m4.055s</span><br><span class="line">user    0m0.000s</span><br><span class="line">sys     0m4.036s</span><br><span class="line"></span><br><span class="line">注：此设定在I/O争用时，才会体现</span><br></pre></td></tr></table></figure>

<h3 id="4-3-2-限制设备读写速率"><a href="#4-3-2-限制设备读写速率" class="headerlink" title="4.3.2 限制设备读写速率"></a>4.3.2 限制设备读写速率</h3><p>&emsp;&emsp;Docker根据两类指标限制容器的设备读写速率：一类是每秒字节数，另一类是每秒I&#x2F;O次数</p>
<p>&emsp;&emsp;1.限制每秒字节数</p>
<p>&emsp;&emsp;&emsp;–device-read-bps选项限制指定设备的读取速率，即每秒读取的字节数</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个容器，并限制对/dev/mapper/rhel-swap设备的读取速率为每秒1MB</span></span><br><span class="line">[root@docker ~]# docker run -it --device-read-bps /dev/mapper/rhel-swap:1mb ubuntu</span><br><span class="line">docker run -it --device-read-bps /dev/sda:1mb ubuntu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似地，可使用--device-write-bps选项限制指定设备的写入速率。格式： &lt;设备&gt;:&lt;速率值&gt;[单位]</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;2.限制每秒I&#x2F;O次数</p>
<p>&emsp;&emsp;&emsp;–device-read-iops和–device-write-iops选项制指定设备的读取和写入速率，用每秒I&#x2F;O次数表示</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个容器，限制它对/dev/mapper/rhel-swap设备的读取速率为每秒1000次</span></span><br><span class="line">[root@docker ~]# docker run -it --device-read-iops /dev/mapper/rhel-swap:1000 ubuntu</span><br></pre></td></tr></table></figure>

<h2 id="4-4-容器底层技术实现"><a href="#4-4-容器底层技术实现" class="headerlink" title="4.4 容器底层技术实现"></a>4.4 容器底层技术实现</h2><p>&emsp;&emsp;对容器使用的内存、CPU和块I&#x2F;O带宽资源的限制具体是由控制组(Cgroup)的相应子系统来实现的。</p>
<p>&emsp;&emsp;&emsp;1.memory子系统设置控制组中的住务所使用的内存限制</p>
<p>&emsp;&emsp;&emsp;2.cpu子系统通过调度程序提供对CPU的控制组任务的访问</p>
<p>&emsp;&emsp;&emsp;3.blkio子系统为块设备(如磁盘、固态硬盘、USB等)设置输入和输出限制</p>
<p>&emsp;&emsp;在docker run命令中使用–cpu-shares、–memory、–device-read-bps等选项实际上就是在配置控制组，相关的配置文件保存在&#x2F;sys&#x2F;fs&#x2F;cgroup目录中</p>
<h3 id="4-4-1-资源限制的底层实现"><a href="#4-4-1-资源限制的底层实现" class="headerlink" title="4.4.1 资源限制的底层实现"></a>4.4.1 资源限制的底层实现</h3><p>&emsp;&emsp;Linux通过cgroup来分配进程使用的CPU、memory、I&#x2F;O资源的配额，可以通过&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;下面的设定来查看容器的配额部分</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动一个容器，设置内存限额为300MB，CPU权重为512</span></span><br><span class="line">[root@docker ~]# docker run --<span class="built_in">rm</span> -d -p 8080:80 -m 300M --cpu-shares=512 httpd</span><br><span class="line">1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动态更改容器的资源限制</span></span><br><span class="line"><span class="comment"># docker update命令可以动态地更新容器配置，其语法：docker update [选项] 容器 [容器...]</span></span><br><span class="line">[root@docker ~]# docker update -m 500M --cpu-shares=10245 1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49</span><br><span class="line">1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49</span><br></pre></td></tr></table></figure>

<h3 id="4-4-2-容器的隔离底层实现"><a href="#4-4-2-容器的隔离底层实现" class="headerlink" title="4.4.2 容器的隔离底层实现"></a>4.4.2 容器的隔离底层实现</h3><p>&emsp;&emsp;每个容器貌似都有自己独立的根目录以及&#x2F;etc、&#x2F;var等目录，而且貌似都有自己的独立网卡，但事实上物理宿主机只有一个网卡，那么容器之间是怎么实现的“独立性”的呢？<br>&emsp;&emsp;Linux使用namespace技术来实现了容器间的资源隔离，namespace管理着宿主机中的全局唯一资源，并且可以让每个容器都会认为自己拥有且只有自己在使用资源，namespace一共有6种，分别为：mount、UTS、IPC、PID、Network、User</p>
<h3 id="4-4-3-namespace"><a href="#4-4-3-namespace" class="headerlink" title="4.4.3 namespace"></a>4.4.3 namespace</h3><p>&emsp;&emsp;Mount namespace让容器看上去拥有整个文件系统，容器有自己的根目录</p>
<p>&emsp;&emsp;UTS namespace可以让容器有自己的主机名，默认情况下，容器的主机名是它本身的短ID，可通过-h或者–hostname设置主机名</p>
<p>&emsp;&emsp;IPC namespace可以让容器拥有自己的共享内存和信号量来实现进程间通信 </p>
<p>&emsp;&emsp;PID namespace让容器拥有自己的进程树，可以在容器中执行ps命令查看</p>
<p>&emsp;&emsp;Network namespace可以让容器拥有自己独立的网卡、IP、路由等资源</p>
<p>&emsp;&emsp;User namespace 让容器能够管理自己的用户，而不是和宿主机公用&#x2F;etc&#x2F;passwd</p>
<h1 id="5-容器原生网络与存储"><a href="#5-容器原生网络与存储" class="headerlink" title="5 容器原生网络与存储"></a>5 容器原生网络与存储</h1><h2 id="5-1-容器原生网络"><a href="#5-1-容器原生网络" class="headerlink" title="5.1 容器原生网络"></a>5.1 容器原生网络</h2><p>&emsp;&emsp;docker原生提供了以下几种网络，如果对原生网络不满意，还可以创建自定义网络<br>&emsp;&emsp;原生网络分为：none、bridge、host，这些网络在docker安装的时候会自动创建，可以通过以下命令来查看</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# docker network <span class="built_in">ls</span></span><br><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">f85881372579   bridge    bridge    <span class="built_in">local</span></span><br><span class="line">668aba04b5b0   host      host      <span class="built_in">local</span></span><br><span class="line">3fa8ef65ab94   none      null      <span class="built_in">local</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;如果容器使用的是none网络，那么此容器将不具备常规理解上的网卡，只具备lo网络，如果要使用这个网络，在创建容器时，指定–network&#x3D;none即可</p>
<p>&emsp;&emsp;None网络是比较封闭的网络，对一些安全要求比较高并且不需要联网的场景，可以用none网络，比如手机上接收的验证码、随机数生成等场景，就可以放在none网络中以避免被窃取</p>
<p>&emsp;&emsp;Host网络是一个共享宿主机网络栈的一个容器共享网络，可以通过–network&#x3D;host在创建容器 的时候指定host网络，处于host网络模式的容器，网络配置和宿主机是完全一样的，也就是说，在容器中可以看到宿主机的所有网卡，并且主机名也是宿主机的，这最大的好处就是性能很高，传输速率特别好，但是宿主机上已经使用的端口，容器就不可以使用</p>
<h2 id="5-2-容器和层"><a href="#5-2-容器和层" class="headerlink" title="5.2 容器和层"></a>5.2 容器和层</h2><p>&emsp;&emsp;容器和镜像最大的不同在于最顶上的可写层，所有在容器中的数据写入和修改都会直接存储到这个可写层中，这就意味着，当容器被删除时，可写层中的数据就丢失了，虽然每个容器都有自己不同的可写层，但是容器底层的镜像却是可以同时共享的</p>
<p><img src="/images/%E5%AE%B9%E5%99%A8%E5%92%8C%E5%B1%82.png" title="容器和层"></p>
<h2 id="5-3-主流存储驱动"><a href="#5-3-主流存储驱动" class="headerlink" title="5.3 主流存储驱动"></a>5.3 主流存储驱动</h2><p>&emsp;&emsp;在容器设计和使用的时候，在容器的可写层中写入的数据是非常少的，但在运维中大部分数据是必须要具备持久化保存的能力，所以在容器中引入了多种的存储驱动来解决上面说的可写层数据的易失性</p>
<p>&emsp;&emsp;目前主流受支持的存储驱动有：</p>
<p><img src="/images/%E5%AD%98%E5%82%A8%E9%A9%B1%E5%8A%A8.png" title="存储驱动"></p>
<h2 id="5-4-Copy-on-write策略"><a href="#5-4-Copy-on-write策略" class="headerlink" title="5.4 Copy-on-write策略"></a>5.4 Copy-on-write策略</h2><p><img src="/images/Copy-on-write.png" title="Copy-on-write"></p>
<h2 id="5-5-容器数据管理"><a href="#5-5-容器数据管理" class="headerlink" title="5.5 容器数据管理"></a>5.5 容器数据管理</h2><p>&emsp;&emsp;容器中持久化数据一般采用两种存储方式：</p>
<p>&emsp;&emsp;&emsp;1.volume</p>
<p>&emsp;&emsp;&emsp;2.bind mount</p>
<p><img src="/images/%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE.png" title="持久化数据"></p>
<h1 id="6-Kubernetes"><a href="#6-Kubernetes" class="headerlink" title="6 Kubernetes"></a>6 Kubernetes</h1><h2 id="6-1-K8S的概念"><a href="#6-1-K8S的概念" class="headerlink" title="6.1 K8S的概念"></a>6.1 K8S的概念</h2><p>&emsp;&emsp;Kubernetes是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化</p>
<p>&emsp;&emsp;Kubernetes拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用</p>
<p><img src="/images/k8s.png" title="k8s的概念"></p>
<h2 id="6-2-K8S的特点"><a href="#6-2-K8S的特点" class="headerlink" title="6.2 K8S的特点"></a>6.2 K8S的特点</h2><p>&emsp;&emsp;Kubernetes具有以下几个特点：</p>
<p>&emsp;&emsp;&emsp;1.可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）</p>
<p>&emsp;&emsp;&emsp;2.可扩展: 模块化、插件化、可挂载、可组合</p>
<p>&emsp;&emsp;&emsp;3.自动化:  自动部署、自动重启、自动复制、自动伸缩&#x2F;扩展</p>
<h2 id="6-3-K8S的作用"><a href="#6-3-K8S的作用" class="headerlink" title="6.3 K8S的作用"></a>6.3 K8S的作用</h2><p>&emsp;&emsp;Kubernetes的主要职责是容器编排(Container Orchestration)，即在一组服务器上启动、 监控、回收容器，在满足排程的同时，保证容器可以健康的运行</p>
<p><img src="/images/k8s%E7%9A%84%E4%BD%9C%E7%94%A8.png" title="k8s的作用"></p>
<h2 id="6-4-K8S的整体架构"><a href="#6-4-K8S的整体架构" class="headerlink" title="6.4 K8S的整体架构"></a>6.4 K8S的整体架构</h2><p><img src="/images/k8s%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png" title="k8s的整体架构"></p>
<h3 id="6-4-1-Master节点"><a href="#6-4-1-Master节点" class="headerlink" title="6.4.1 Master节点"></a>6.4.1 Master节点</h3><p>1.kube-apiserver</p>
<p>&emsp;&emsp;API服务器是Kubernetes控制面的前端</p>
<p>&emsp;&emsp;Kubernetes API服务器的主要实现是kube-apiserver</p>
<p>&emsp;&emsp;kube-apiserver设计上考虑了水平伸缩，可通过部署多个实例进行伸缩。 可以运行kube-apiserver的多个实例，并在这些实例之间平衡流</p>
<p>2.etcd</p>
<p>&emsp;&emsp;etcd是兼具一致性和高可用性的键值数据库，可以作为保存Kubernetes所有集群数据的后台数据库</p>
<p>3.cloud-controller-manager</p>
<p>&emsp;&emsp;cloud-controller-manager仅运行特定于云平台的控制回路</p>
<p>&emsp;&emsp;如果在自己的环境中运行Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器</p>
<p>4.kube-scheduler</p>
<p>&emsp;&emsp;控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行</p>
<p>5.kube-controller-manager</p>
<p>&emsp;&emsp;这些控制器包括:</p>
<p>&emsp;&emsp;节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应</p>
<p>&emsp;&emsp;任务控制器（Job controller）: 监测代表一次性任务的Job对象，然后创建Pods来运行这些任务直至完成</p>
<p>&emsp;&emsp;端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</p>
<p>&emsp;&emsp;服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和API访问令牌</p>
<h3 id="6-4-2-Node节点"><a href="#6-4-2-Node节点" class="headerlink" title="6.4.2 Node节点"></a>6.4.2 Node节点</h3><p>1.kubelet</p>
<p>&emsp;&emsp;一个在集群中每个节点（node）上运行的代理，保证容器（containers）都运行在Pod中</p>
<p>2.kube-proxy</p>
<p>&emsp;&emsp;kube-proxy是集群中每个节点上运行的网络代理， 实现Kubernetes服务(Service)概念的一部分</p>
<p>&emsp;&emsp;kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与Pod进行网络通信</p>
<p>&emsp;&emsp;如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则， kube-proxy仅转发流量本身</p>
<p>3.容器运行时（Container Runtime）</p>
<p>&emsp;&emsp;Kubernetes支持多个容器运行环境: Docker、 containerd、CRI-O以及任何实现Kubernetes CRI (容器运行环境接口)</p>
<h3 id="6-4-3-插件-Addons"><a href="#6-4-3-插件-Addons" class="headerlink" title="6.4.3 插件(Addons)"></a>6.4.3 插件(Addons)</h3><p>&emsp;&emsp;插件使用Kubernetes资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于kube-system命名空间</p>
<p>&emsp;&emsp;1.Core-dns：为整个集群提供DNS服务</p>
<p>&emsp;&emsp;2.Ingress Controller：为service提供外网访问入口</p>
<p>&emsp;&emsp;3.Dashboard: 提供图形化管理界面</p>
<p>&emsp;&emsp;4.Flannel&#x2F; Calico ：为kubernetes提供方便的网络规划服务</p>
<h1 id="7-Kubernetes集群部署"><a href="#7-Kubernetes集群部署" class="headerlink" title="7 Kubernetes集群部署"></a>7 Kubernetes集群部署</h1><h2 id="7-1-Kubernetes的安装流程"><a href="#7-1-Kubernetes的安装流程" class="headerlink" title="7.1 Kubernetes的安装流程"></a>7.1 Kubernetes的安装流程</h2><h3 id="7-1-1-先决条件"><a href="#7-1-1-先决条件" class="headerlink" title="7.1.1 先决条件"></a>7.1.1 先决条件</h3><p>&emsp;&emsp;1.最小配置：2G内存2核CPU</p>
<p>&emsp;&emsp;2.集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)</p>
<p>&emsp;&emsp;3.节点之中不可以有重复的主机名、MAC 地址或product_uuid</p>
<p>&emsp;&emsp;4.禁用交换分区</p>
<p>&emsp;&emsp;5.开启机器上的某些端口</p>
<h3 id="7-1-2-安装runtime"><a href="#7-1-2-安装runtime" class="headerlink" title="7.1.2 安装runtime"></a>7.1.2 安装runtime</h3><p>&emsp;&emsp;默认情况下，Kubernetes使用容器运行时接口（Container Runtime Interface，CRI） 与所选择的容器运行时交互</p>
<p>&emsp;&emsp;如果不指定运行时，则kubeadm会自动尝试检测到系统上已经安装的运行时， 方法是扫描一组众所周知的Unix域套接字，docker启用shim来对接K8S</p>
<p>&emsp;&emsp;运行时的域套接字：<br>&emsp;&emsp;Docker           unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;cri-dockerd.sock </p>
<p>&emsp;&emsp;containerd	&#x2F;run&#x2F;containerd&#x2F;containerd.sock</p>
<p>&emsp;&emsp;CRI-O             &#x2F;var&#x2F;run&#x2F;crio&#x2F;crio.sock</p>
<h3 id="7-1-3-安装kubeadm、kubelet和kubectl"><a href="#7-1-3-安装kubeadm、kubelet和kubectl" class="headerlink" title="7.1.3 安装kubeadm、kubelet和kubectl"></a>7.1.3 安装kubeadm、kubelet和kubectl</h3><p>&emsp;&emsp;需要在每台机器上安装以下软件包：</p>
<p>&emsp;&emsp;kubeadm：用来初始化集群的指令     </p>
<p>&emsp;&emsp;kubelet：在集群中的每个节点上用来启动Pod和容器等</p>
<p>&emsp;&emsp;kubectl：用来与集群通信的命令行工具</p>
<p>&emsp;&emsp;确保它们与通过kubeadm安装的控制平面的版本相匹配。 不然可能会导致一些预料之外的错误和问题。 然而，控制平面与kubelet间的相差一个次要版本不一致是支持的，但kubelet的版本不可以超过API服务器的版本。 例如，1.7.0 版本的kubelet可以完全兼容1.8.0版本的API 服务器，反之则不可以</p>
<h3 id="7-1-4-检查所需端口"><a href="#7-1-4-检查所需端口" class="headerlink" title="7.1.4 检查所需端口"></a>7.1.4 检查所需端口</h3><p>1.控制平面</p>
<table>
<thead>
<tr>
<th>协议</th>
<th>方向</th>
<th>端口范围</th>
<th>作用</th>
<th>使用者</th>
</tr>
</thead>
<tbody><tr>
<td>TCP</td>
<td>入站</td>
<td>6443</td>
<td>Kubernetes API服务器</td>
<td>所有组件</td>
</tr>
<tr>
<td>TCP</td>
<td>入站</td>
<td>2379-2380</td>
<td>etcd服务器客户端API</td>
<td>kube-apiserver,etcd</td>
</tr>
<tr>
<td>TCP</td>
<td>入站</td>
<td>10250</td>
<td>Kubelet API</td>
<td>kubelet自身、控制平面组件</td>
</tr>
<tr>
<td>TCP</td>
<td>入站</td>
<td>10251</td>
<td>kube-scheduler</td>
<td>kube-scheduler自身</td>
</tr>
<tr>
<td>TCP</td>
<td>入站</td>
<td>10252</td>
<td>kube-controller-manager</td>
<td>kube-controller-manager自身</td>
</tr>
</tbody></table>
<p>2.工作节点</p>
<table>
<thead>
<tr>
<th>协议</th>
<th>方向</th>
<th>端口范围</th>
<th>作用</th>
<th>使用者</th>
</tr>
</thead>
<tbody><tr>
<td>TCP</td>
<td>入站</td>
<td>10250</td>
<td>Kubelet API</td>
<td>kubelet自身、控制平面组件</td>
</tr>
<tr>
<td>TCP</td>
<td>入站</td>
<td>30000-32767</td>
<td>NodePort服务</td>
<td>所有组件</td>
</tr>
</tbody></table>
<h3 id="7-1-5-Iptables桥接流量"><a href="#7-1-5-Iptables桥接流量" class="headerlink" title="7.1.5 Iptables桥接流量"></a>7.1.5 Iptables桥接流量</h3><p>&emsp;&emsp;为了让Linux节点上的iptables能够正确地查看桥接流量，需要确保sysctl配置中将net.bridge.bridge-nf-call-iptables设置为1</p>
<p><img src="/images/iptables.png" title="iptables桥接流量"></p>
<h3 id="7-1-6-环境准备"><a href="#7-1-6-环境准备" class="headerlink" title="7.1.6 环境准备"></a>7.1.6 环境准备</h3><p>本K8S集群使用3台机器(ubuntu)进行部署，各节点信息如下表：</p>
<p>注明：使用的容器为Docker</p>
<table>
<thead>
<tr>
<th>主机名</th>
<th>角色</th>
<th>IP</th>
<th>VMware网络类型</th>
<th>用户名</th>
<th>密码</th>
<th>互联网连接</th>
</tr>
</thead>
<tbody><tr>
<td>k8s-master</td>
<td>控制平面</td>
<td>192.168.8.3</td>
<td>NAT</td>
<td>vagrant<br>root</td>
<td>vagrant<br/>vargrant</td>
<td>是</td>
</tr>
<tr>
<td>k8s-worker1</td>
<td>数据平面</td>
<td>192.168.8.4</td>
<td>NAT</td>
<td>vagrant<br/>root</td>
<td>vagrant<br/>vargrant</td>
<td>是</td>
</tr>
<tr>
<td>k8s-worker2</td>
<td>数据平面</td>
<td>192.168.8.5</td>
<td>NAT</td>
<td>vagrant<br/>root</td>
<td>vagrant<br/>vargrant</td>
<td>是</td>
</tr>
</tbody></table>
<p>准备DNS解析：</p>
<p>&emsp;&emsp;这一步需要在所有机器上完成</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这一步需要在所有机器上完成</span></span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.8.3 k8s-master</span></span><br><span class="line"><span class="string">192.168.8.4 k8s-worker1</span></span><br><span class="line"><span class="string">192.168.8.5 k8s-worker2</span></span><br><span class="line"><span class="string">192.168.30.133 registry.xiaohui.cn</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h2 id="7-2-Docker-CE-部署"><a href="#7-2-Docker-CE-部署" class="headerlink" title="7.2 Docker CE 部署"></a>7.2 Docker CE 部署</h2><h3 id="7-2-1-添加Docker仓库"><a href="#7-2-1-添加Docker仓库" class="headerlink" title="7.2.1 添加Docker仓库"></a>7.2.1 添加Docker仓库</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y ca-certificates curl gnupg lsb-release</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加公钥到系统</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> -p /etc/apt/keyrings</span><br><span class="line">curl -fsSL https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu/gpg | <span class="built_in">sudo</span> gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加仓库到系统</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断仓库是否已做好</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br></pre></td></tr></table></figure>

<h3 id="7-2-2-安装Docker-CE"><a href="#7-2-2-安装Docker-CE" class="headerlink" title="7.2.2 安装Docker CE"></a>7.2.2 安装Docker CE</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin</span><br><span class="line"><span class="comment"># 部署完Docker CE之后，还需要cri-docker shim才可以和Kubernetes集成</span></span><br></pre></td></tr></table></figure>

<h3 id="7-2-3-CRI-Docker部署"><a href="#7-2-3-CRI-Docker部署" class="headerlink" title="7.2.3 CRI-Docker部署"></a>7.2.3 CRI-Docker部署</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载cri-docker</span></span><br><span class="line">wget http://hub.gitmirror.com/https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.17/cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装cri-docker</span></span><br><span class="line">dpkg -i cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb</span><br></pre></td></tr></table></figure>

<h3 id="7-2-4-Docker镜像加速器"><a href="#7-2-4-Docker镜像加速器" class="headerlink" title="7.2.4 Docker镜像加速器"></a>7.2.4 Docker镜像加速器</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.baidubce.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.m.daocloud.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.nju.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.gcr.io&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker-cf.registry.cyou&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockercf.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://docker.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockertest.jsdelivr.fyi&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://mirror.aliyuncs.com&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://dockerproxy.com&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="7-2-5-将镜像指引到国内"><a href="#7-2-5-将镜像指引到国内" class="headerlink" title="7.2.5 将镜像指引到国内"></a>7.2.5 将镜像指引到国内</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> /lib/systemd/system/cri-docker.service /etc/systemd/system/cri-docker.service</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">&#x27;s/ExecStart=.*/ExecStart=\/usr\/bin\/cri-dockerd --container-runtime-endpoint fd:\/\/ --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com\/google_containers\/pause:3.10/&#x27;</span> /etc/systemd/system/cri-docker.service</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart cri-docker.service</span><br><span class="line">systemctl <span class="built_in">enable</span> cri-docker.service</span><br></pre></td></tr></table></figure>

<h2 id="7-3-Kubernetes部署"><a href="#7-3-Kubernetes部署" class="headerlink" title="7.3 Kubernetes部署"></a>7.3 Kubernetes部署</h2><h3 id="7-3-1-关闭swap分区"><a href="#7-3-1-关闭swap分区" class="headerlink" title="7.3.1 关闭swap分区"></a>7.3.1 关闭swap分区</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实时关闭</span></span><br><span class="line">swapoff -a</span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -i <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure>

<h3 id="7-3-2-允许iptables检查桥接流量"><a href="#7-3-2-允许iptables检查桥接流量" class="headerlink" title="7.3.2 允许iptables检查桥接流量"></a>7.3.2 允许iptables检查桥接流量</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span></span><br><span class="line"><span class="string">br_netfilter</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> sysctl --system</span><br></pre></td></tr></table></figure>

<h3 id="7-3-3-安装kubeadm"><a href="#7-3-3-安装kubeadm" class="headerlink" title="7.3.3 安装kubeadm"></a>7.3.3 安装kubeadm</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https curl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装K8S软件包仓库-阿里云</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/apt/sources.list.d/k8s.list &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">deb https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb /</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装软件包仓库的公钥</span></span><br><span class="line">curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/Release.key | apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新软件包的仓库索引</span></span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始安装</span></span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 操作系统所有软件包升级时将忽略kubelet、kubeadm、kubectl</span></span><br><span class="line">apt-mark hold kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure>

<h3 id="7-3-4-添加命令自动补齐"><a href="#7-3-4-添加命令自动补齐" class="headerlink" title="7.3.4 添加命令自动补齐"></a>7.3.4 添加命令自动补齐</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl completion bash &gt; /etc/bash_completion.d/kubectl</span><br><span class="line">kubeadm completion bash &gt; /etc/bash_completion.d/kubeadm</span><br><span class="line"><span class="built_in">source</span> /etc/bash_completion.d/kubectl</span><br><span class="line"><span class="built_in">source</span> /etc/bash_completion.d/kubeadm</span><br></pre></td></tr></table></figure>

<h3 id="7-3-5-集成CRI-Docker"><a href="#7-3-5-集成CRI-Docker" class="headerlink" title="7.3.5 集成CRI-Docker"></a>7.3.5 集成CRI-Docker</h3><p>这一步要在所有机器上完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crictl config --<span class="built_in">set</span> runtime-endpoint unix:///run/cri-dockerd.sock</span><br><span class="line">crictl images</span><br></pre></td></tr></table></figure>

<h3 id="7-3-6-集群部署"><a href="#7-3-6-集群部署" class="headerlink" title="7.3.6 集群部署"></a>7.3.6 集群部署</h3><p>&emsp;&emsp;kubeadm.yaml中name字段必须在网络中可被解析，也可以将解析记录添加到集群中所有机器的&#x2F;etc&#x2F;hosts中</p>
<p>&emsp;&emsp;初始化集群部署的操作只能在k8s-master上执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化配置</span></span><br><span class="line">kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm.yaml</span><br><span class="line">sed -i <span class="string">&#x27;s/.*advert.*/  advertiseAddress: 192.168.8.3/g&#x27;</span> kubeadm.yaml</span><br><span class="line">sed -i <span class="string">&#x27;s/.*name.*/  name: k8s-master/g&#x27;</span> kubeadm.yaml</span><br><span class="line">sed -i <span class="string">&#x27;s|imageRepo.*|imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers|g&#x27;</span> kubeadm.yaml</span><br><span class="line">sed -i <span class="string">&quot;/^\\s*networking:/a\\  podSubnet: 172.16.0.0/16&quot;</span> kubeadm.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意下面的替换，只有在集成的是CRI-Docker时才需要执行，Containerd不需要</span></span><br><span class="line">sed -i <span class="string">&#x27;s/  criSocket.*/  criSocket: unix:\/\/\/run\/cri-dockerd.sock/&#x27;</span> kubeadm.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模块加载</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 集群初始化</span></span><br><span class="line">kubeadm init --config kubeadm.yaml</span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line">......</span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.8.3:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment"># 授权管理权限</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">root@k8s-master:~# kubectl get nodes</span><br><span class="line">NAME         STATUS     ROLES           AGE   VERSION</span><br><span class="line">k8s-master   NotReady   control-plane   62m   v1.32.5</span><br></pre></td></tr></table></figure>

<h3 id="7-3-7-部署Calico网络插件"><a href="#7-3-7-部署Calico网络插件" class="headerlink" title="7.3.7 部署Calico网络插件"></a>7.3.7 部署Calico网络插件</h3><p>&emsp;&emsp;Calico网络插件部署的操作在所有节点上执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用operator安装calico组件-可能会失败</span></span><br><span class="line"><span class="comment"># 以下为github的地址，可能会失败</span></span><br><span class="line">root@k8s-master:~# kubectl create -f https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/tigera-operator.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决办法：</span></span><br><span class="line"><span class="comment"># 1.获取Calico images到本地</span></span><br><span class="line">    见Calico.txt</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 2.发布本地的yaml到集群-master</span></span><br><span class="line">kubectl create -f https://www.linuxcenter.cn/files/cka/cka-yaml/tigera-operator-calico-3.29.3.yaml</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -A</span><br><span class="line">NAMESPACE         NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system       coredns-76fccbbb6b-l7jq9             0/1     Pending   0          163m</span><br><span class="line">kube-system       coredns-76fccbbb6b-nd68g             0/1     Pending   0          163m</span><br><span class="line">kube-system       etcd-k8s-master                      1/1     Running   0          163m</span><br><span class="line">kube-system       kube-apiserver-k8s-master            1/1     Running   0          163m</span><br><span class="line">kube-system       kube-controller-manager-k8s-master   1/1     Running   0          163m</span><br><span class="line">kube-system       kube-proxy-mcwv7                     1/1     Running   0          163m</span><br><span class="line">kube-system       kube-scheduler-k8s-master            1/1     Running   0          163m</span><br><span class="line">tigera-operator   tigera-operator-75b4cd596c-9hjml     1/1     Running   0          7m5s</span><br></pre></td></tr></table></figure>

<h3 id="7-3-8-设置calico在集群的网段"><a href="#7-3-8-设置calico在集群的网段" class="headerlink" title="7.3.8 设置calico在集群的网段"></a>7.3.8 设置calico在集群的网段</h3><p>&emsp;&emsp;这一步在k8s-master上执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用下面的自定义资源设置一下calico在集群中的网段</span></span><br><span class="line"><span class="comment"># 以下为github的地址，可能会失败</span></span><br><span class="line">root@k8s-master:~# wget https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/custom-resources.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.使用下面的地址执行</span></span><br><span class="line">root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/cka-yaml/custom-resources-calico-3.29.3.yaml</span><br><span class="line">root@k8s-master:~# <span class="built_in">mv</span> custom-resources-calico-3.29.3.yaml custom-resources.yaml</span><br></pre></td></tr></table></figure>

<h3 id="7-3-9-确认资源的地址"><a href="#7-3-9-确认资源的地址" class="headerlink" title="7.3.9 确认资源的地址"></a>7.3.9 确认资源的地址</h3><p>&emsp;&emsp;这一步在k8s-master上执行</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">root@k8s-master:~#</span> <span class="string">vim</span> <span class="string">custom-resources.yaml</span></span><br><span class="line"><span class="comment"># This section includes base Calico installation configuration.</span></span><br><span class="line"><span class="comment"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">operator.tigera.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Installation</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># Configures Calico networking.</span></span><br><span class="line">  <span class="attr">calicoNetwork:</span></span><br><span class="line">    <span class="attr">ipPools:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">default-ipv4-ippool</span></span><br><span class="line">      <span class="attr">blockSize:</span> <span class="number">26</span></span><br><span class="line">      <span class="attr">cidr:</span> <span class="number">172.16</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>      <span class="comment">#这里换成上面规定好的172.16.0.0/16</span></span><br><span class="line">      <span class="attr">encapsulation:</span> <span class="string">VXLANCrossSubnet</span></span><br><span class="line">      <span class="attr">natOutgoing:</span> <span class="string">Enabled</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> <span class="string">all()</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="comment"># This section configures the Calico API server.</span></span><br><span class="line"><span class="comment"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">operator.tigera.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">APIServer</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-3-10-自定义资源发布到集群"><a href="#7-3-10-自定义资源发布到集群" class="headerlink" title="7.3.10 自定义资源发布到集群"></a>7.3.10 自定义资源发布到集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl apply -f custom-resources.yaml</span><br><span class="line">root@k8s-master:~# kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES           AGE    VERSION</span><br><span class="line">k8s-master   Ready    control-plane   173m   v1.32.5</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -A</span><br><span class="line">NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-apiserver   calico-apiserver-6499c768c8-wvrnt          1/1     Running   0          60s</span><br><span class="line">calico-apiserver   calico-apiserver-6499c768c8-zmvh6          1/1     Running   0          60s</span><br><span class="line">calico-system      calico-kube-controllers-85fb6564b7-gtsfr   1/1     Running   0          60s</span><br><span class="line">calico-system      calico-node-4mqfj                          1/1     Running   0          60s</span><br><span class="line">calico-system      calico-typha-65d47d7478-ttzx6              1/1     Running   0          60s</span><br><span class="line">calico-system      csi-node-driver-7j8pf                      2/2     Running   0          60s</span><br><span class="line">kube-system        coredns-76fccbbb6b-l7jq9                   1/1     Running   0          172m</span><br><span class="line">kube-system        coredns-76fccbbb6b-nd68g                   1/1     Running   0          172m</span><br><span class="line">kube-system        etcd-k8s-master                            1/1     Running   0          172m</span><br><span class="line">kube-system        kube-apiserver-k8s-master                  1/1     Running   0          172m</span><br><span class="line">kube-system        kube-controller-manager-k8s-master         1/1     Running   0          172m</span><br><span class="line">kube-system        kube-proxy-mcwv7                           1/1     Running   0          172m</span><br><span class="line">kube-system        kube-scheduler-k8s-master                  1/1     Running   0          172m</span><br><span class="line">tigera-operator    tigera-operator-75b4cd596c-9hjml           1/1     Running   0          16m</span><br></pre></td></tr></table></figure>

<h3 id="7-3-11-加入Worker节点"><a href="#7-3-11-加入Worker节点" class="headerlink" title="7.3.11 加入Worker节点"></a>7.3.11 加入Worker节点</h3><p>&emsp;&emsp;加入节点操作需在所有的worker节点完成，这里要注意，Worker节点需要完成以下先决条件才能执行kubeadm join</p>
<p>&emsp;&emsp;&emsp;1.Docker、CRI-Docker 部署</p>
<p>&emsp;&emsp;&emsp;2.Swap分区关闭</p>
<p>&emsp;&emsp;&emsp;3.iptables桥接流量的允许</p>
<p>&emsp;&emsp;&emsp;4.安装kubeadm等软件</p>
<p>&emsp;&emsp;&emsp;5.集成CRI-Docker</p>
<p>&emsp;&emsp;&emsp;6.所有节点的&#x2F;etc&#x2F;hosts中互相添加对方的解析</p>
<p>&emsp;&emsp;如果时间长忘记了join参数，可以在master节点上用以下方法重新生成</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubeadm token create --print-join-command</span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;如果有多个CRI对象，在worker节点上执行以下命令加入节点时，指定CRI对象，案例如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-worker1:~# kubeadm token create --print-join-command</span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207</span><br><span class="line">failed to load admin kubeconfig: open /root/.kube/config: no such file or directory</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br><span class="line">found multiple CRI endpoints on the host. Please define <span class="built_in">which</span> one <span class="keyword">do</span> you wish to use by setting the <span class="string">&#x27;criSocket&#x27;</span> field <span class="keyword">in</span> the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sock</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入两个节点</span></span><br><span class="line">1.节点worker1</span><br><span class="line">root@k8s-worker1:~# kubeadm <span class="built_in">join</span> 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock</span><br><span class="line"></span><br><span class="line">2.节点worker2</span><br><span class="line">root@k8s-worker2:~#  kubeadm <span class="built_in">join</span> 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock</span><br><span class="line"></span><br><span class="line">3.查看各节点状态</span><br><span class="line">root@k8s-master:~# kubectl get nodes</span><br><span class="line">NAME          STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master    Ready    control-plane   3h28m   v1.32.5</span><br><span class="line">k8s-worker1   Ready    &lt;none&gt;          2m2s    v1.32.5</span><br><span class="line">k8s-worker2   Ready    &lt;none&gt;          2m2s    v1.32.5</span><br><span class="line"></span><br><span class="line">4.查看pod信息</span><br><span class="line">root@k8s-master:~# kubectl get pod -A</span><br><span class="line">NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-apiserver   calico-apiserver-6499c768c8-wvrnt          1/1     Running   0          37m</span><br><span class="line">calico-apiserver   calico-apiserver-6499c768c8-zmvh6          1/1     Running   0          37m</span><br><span class="line">calico-system      calico-kube-controllers-85fb6564b7-gtsfr   1/1     Running   0          37m</span><br><span class="line">calico-system      calico-node-4mqfj                          1/1     Running   0          37m</span><br><span class="line">calico-system      calico-node-rkd6k                          1/1     Running   0          3m37s</span><br><span class="line">calico-system      calico-node-vxflh                          1/1     Running   0          3m37s</span><br><span class="line">calico-system      calico-typha-65d47d7478-cmrtt              1/1     Running   0          3m28s</span><br><span class="line">calico-system      calico-typha-65d47d7478-ttzx6              1/1     Running   0          37m</span><br><span class="line">calico-system      csi-node-driver-7j8pf                      2/2     Running   0          37m</span><br><span class="line">calico-system      csi-node-driver-nhg4c                      2/2     Running   0          3m37s</span><br><span class="line">calico-system      csi-node-driver-z6p7p                      2/2     Running   0          3m37s</span><br><span class="line">kube-system        coredns-76fccbbb6b-l7jq9                   1/1     Running   0          3h29m</span><br><span class="line">kube-system        coredns-76fccbbb6b-nd68g                   1/1     Running   0          3h29m</span><br><span class="line">kube-system        etcd-k8s-master                            1/1     Running   0          3h29m</span><br><span class="line">kube-system        kube-apiserver-k8s-master                  1/1     Running   0          3h29m</span><br><span class="line">kube-system        kube-controller-manager-k8s-master         1/1     Running   0          3h29m</span><br><span class="line">kube-system        kube-proxy-8n6x5                           1/1     Running   0          3m37s</span><br><span class="line">kube-system        kube-proxy-mcwv7                           1/1     Running   0          3h29m</span><br><span class="line">kube-system        kube-proxy-xk4h4                           1/1     Running   0          3m37s</span><br><span class="line">kube-system        kube-scheduler-k8s-master                  1/1     Running   0          3h29m</span><br><span class="line">tigera-operator    tigera-operator-75b4cd596c-9hjml           1/1     Running   0          52m</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;注意上描述命令最后的–cri-socket参数，在系统中部署了docker和cri-docker时，必须明确指明此参数，并将此参数指向我们的cri-docker，不然命令会报告有两个重复的CRI的错误</p>
<p>&emsp;&emsp;在k8s-master机器上执行以下内容给节点打上角色标签，k8s-worker1和k8s-worker2分别打上了worker1和worker2的标签</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl label nodes k8s-worker1 node-role.kubernetes.io/worker1=</span><br><span class="line">node/k8s-worker1 labeled</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl label nodes k8s-worker2 node-role.kubernetes.io/worker2=</span><br><span class="line">node/k8s-worker2 labeled</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get nodes</span><br><span class="line">NAME          STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master    Ready    control-plane   3h33m   v1.32.5</span><br><span class="line">k8s-worker1   Ready    worker1         7m37s   v1.32.5</span><br><span class="line">k8s-worker2   Ready    worker2         7m37s   v1.32.5</span><br></pre></td></tr></table></figure>

<h3 id="7-3-12-重置集群"><a href="#7-3-12-重置集群" class="headerlink" title="7.3.12 重置集群"></a>7.3.12 重置集群</h3><p>&emsp;&emsp;如果在安装好集群的情况下，想重复练习初始化集群，或者包括初始化集群报错在内的任何原因，想重新初始化集群时，可以用下面的方法重置集群，重置后，集群就会被删除，可以用于重新部署，一般来说，这个命令仅用于k8s-master这个节点</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubeadm reset --cri-socket=unix:///var/run/cri-dockerd.sock</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据提示，手工完成文件和规则的清理   清理后就可以重新部署集群了</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">rm</span> -rf /etc/cni/net.d</span><br><span class="line">root@k8s-master:~# iptables -F</span><br><span class="line">root@k8s-master:~# <span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure>

<h3 id="7-3-13-标签和注解"><a href="#7-3-13-标签和注解" class="headerlink" title="7.3.13 标签和注解"></a>7.3.13 标签和注解</h3><p>&emsp;&emsp;标签(Labels)和注解(Annotations)是附加到Kubernetes 对象(比如Pods)上的键值对</p>
<p>&emsp;&emsp;标签旨在用于指定对用户有意义的标识属性，但不直接对核心系统有语义含义。可以用来选择对象和查找满足某些条件的对象集合</p>
<p>&emsp;&emsp;注解不用于标识和选择对象。有效的注解键分为两部分： 可选的前缀和名称，以斜杠（&#x2F;）分隔。 名称段是必需项，并且必须在63个字符以内</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl get node --show-labels</span><br><span class="line">NAME          STATUS   ROLES           AGE     VERSION   LABELS</span><br><span class="line">k8s-master    Ready    control-plane   4h11m   v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=</span><br><span class="line">k8s-worker1   Ready    worker1         45m     v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-worker1,kubernetes.io/os=linux,node-role.kubernetes.io/worker1=</span><br><span class="line">k8s-worker2   Ready    worker2         45m     v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-worker2,kubernetes.io/os=linux,node-role.kubernetes.io/worker2=</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get nodes</span><br><span class="line">NAME          STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master    Ready    control-plane   4h11m   v1.32.5</span><br><span class="line">k8s-worker1   Ready    worker1         45m     v1.32.5</span><br><span class="line">k8s-worker2   Ready    worker2         45m     v1.32.5</span><br></pre></td></tr></table></figure>

<h1 id="8-Kubernetes的语法"><a href="#8-Kubernetes的语法" class="headerlink" title="8 Kubernetes的语法"></a>8 Kubernetes的语法</h1><p>&emsp;&emsp;kubectl [command] [TYPE] [NAME] [flags]<br>&emsp;&emsp;command：指定要对一个或多个资源执行的操作，例如create、get、describe、delete<br>&emsp;&emsp;TYPE：指定资源类型，资源类型不区分大小写，可以指定单数、复数或缩写形式<br>&emsp;&emsp;NAME：指定资源的名称，名称区分大小写<br>&emsp;&emsp;fags：指定可选的参数。例如，可以使用-s或-server参数指定Kubernetes API服务器的地址和端口</p>
<p><img src="/images/%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B.png" title="语法示例"></p>
<h2 id="8-1-Yaml语法"><a href="#8-1-Yaml语法" class="headerlink" title="8.1 Yaml语法"></a>8.1 Yaml语法</h2><p><img src="/images/yaml%E8%AF%AD%E6%B3%95.png" title="yaml语法"></p>
<p>注意每个层级之间的点（.），在YAML文件中，每个层级之间一般用两个空格来表</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl explain Pod.metadata</span><br><span class="line">KIND:       Pod</span><br><span class="line">VERSION:    v1</span><br><span class="line"></span><br><span class="line">FIELD: metadata &lt;ObjectMeta&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="8-1-1-生成YAML文件框架"><a href="#8-1-1-生成YAML文件框架" class="headerlink" title="8.1.1 生成YAML文件框架"></a>8.1.1 生成YAML文件框架</h3><p>&emsp;&emsp;通过在创建资源时加上—dry-run&#x3D;client –o yaml来生成YAML文件框架，可以用重定向到文件的方式生成文件，只需要稍作修改即可</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl create deployment --image httpd deployname --dry-run=client -o yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: deployname</span><br><span class="line">  name: deployname</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: deployname</span><br><span class="line">  strategy: &#123;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        app: deployname</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: httpd</span><br><span class="line">        name: httpd</span><br><span class="line">        resources: &#123;&#125;</span><br><span class="line">status: &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重定向到文件</span></span><br><span class="line">root@k8s-master:~# kubectl create deployment --image httpd deployname --dry-run=client -o yaml &gt; k8s.yml</span><br></pre></td></tr></table></figure>

<h3 id="8-1-2-apiVersion"><a href="#8-1-2-apiVersion" class="headerlink" title="8.1.2 apiVersion"></a>8.1.2 apiVersion</h3><p>Alpha:</p>
<p>&emsp;&emsp;1.版本名称包含了alpha</p>
<p>&emsp;&emsp;2.可能是有缺陷的。启用该功能可能会带来问题，默认是关闭的</p>
<p>&emsp;&emsp;3.支持的功能可能在没有通知的情况下随时删除</p>
<p>&emsp;&emsp;4.API的更改可能会带来兼容性问题，但是在后续的软件发布中不会有任何通知</p>
<p>&emsp;&emsp;5.由于bugs风险的增加和缺乏长期的支持，推荐在短暂的集群测试中使用。</p>
<p>Beta:</p>
<p>&emsp;&emsp;1.版本名称包含了beta</p>
<p>&emsp;&emsp;2.代码已经测试过。启用该功能被 认为是安全的，功能默认已启用</p>
<p>&emsp;&emsp;3.所有已支持的功能不会被删除，细节可能会发生变化</p>
<p>&emsp;&emsp;4.对象的模式和&#x2F;或语义可能会在后续的beta测试版或稳定版中以不兼容的方式进行更改。</p>
<p>&emsp;&emsp;5.建议仅用于非业务关键型用途，因为后续版本中可能存在不兼容的更改。 如果有多个可以独立升级的集群，则可以放宽此限制</p>
<p>Stable：</p>
<p>&emsp;&emsp;1.版本名称是 vX，其中X是整数</p>
<p>&emsp;&emsp;2.功能的稳定版本将出现在许多后续版本的发行软件中</p>
<p>&emsp;&emsp;3.有时候也会被称为GA或者毕业等词汇</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl api-resources</span><br><span class="line">NAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KIND</span><br><span class="line">bindings                           v1                           <span class="literal">true</span>            Binding</span><br><span class="line">componentstatuses    cs            v1                           <span class="literal">false</span>           ComponentStatus</span><br><span class="line">configmaps           cm            v1                           <span class="literal">true</span>            ConfigMap</span><br><span class="line">endpoints            ep            v1                           <span class="literal">true</span>            Endpoints</span><br><span class="line">events               ev            v1                           <span class="literal">true</span>            Event</span><br><span class="line">limitranges          limits        v1                           <span class="literal">true</span>            LimitRange</span><br><span class="line">namespaces           ns            v1                           <span class="literal">false</span>           Namespace</span><br><span class="line">nodes                no            v1                           <span class="literal">false</span>           Node</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以使用单数、复数、缩写</span></span><br><span class="line">root@k8s-master:~# kubectl get configmaps</span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      5h17m</span><br><span class="line">root@k8s-master:~# kubectl get cm</span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      5h17m</span><br><span class="line">root@k8s-master:~# kubectl get configmap</span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      5h17m</span><br></pre></td></tr></table></figure>

<h2 id="8-2-Namespace"><a href="#8-2-Namespace" class="headerlink" title="8.2 Namespace"></a>8.2 Namespace</h2><p>&emsp;&emsp;Kubernetes支持多个虚拟集群，它们底层依赖于同一个物理集群。 这些虚拟集群被称为命名空间，它适用于存在很多跨多个团队或项目的用户的场景，命名空间为名称提供了一个范围</p>
<p>&emsp;&emsp;资源的名称需要在名字空间内是唯一的，但不能跨名字空间</p>
<p>&emsp;&emsp;名字空间不能相互嵌套，每个Kubernetes资源只能在一个名字空间中</p>
<p>&emsp;&emsp;命名空间是在多个用户之间通过资源配额划分集群资源的一种方法</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl get namespace</span><br><span class="line">NAME               STATUS   AGE</span><br><span class="line">calico-apiserver   Active   3h18m</span><br><span class="line">calico-system      Active   3h18m</span><br><span class="line">default            Active   6h10m</span><br><span class="line">kube-node-lease    Active   6h10m</span><br><span class="line">kube-public        Active   6h10m</span><br><span class="line">kube-system        Active   6h10m</span><br><span class="line">tigera-operator    Active   3h33m</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">No resources found <span class="keyword">in</span> default namespace.</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -n kube-system</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-76fccbbb6b-l7jq9             1/1     Running   0          6h14m</span><br><span class="line">coredns-76fccbbb6b-nd68g             1/1     Running   0          6h14m</span><br><span class="line">etcd-k8s-master                      1/1     Running   0          6h15m</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   0          6h14m</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   0          6h15m</span><br><span class="line">kube-proxy-8n6x5                     1/1     Running   0          169m</span><br><span class="line">kube-proxy-mcwv7                     1/1     Running   0          6h14m</span><br><span class="line">kube-proxy-xk4h4                     1/1     Running   0          169m</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   0          6h15m</span><br></pre></td></tr></table></figure>

<h3 id="8-2-1-命令行创建"><a href="#8-2-1-命令行创建" class="headerlink" title="8.2.1 命令行创建"></a>8.2.1 命令行创建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl create namespace luovip</span><br><span class="line">namespace/luovip created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get namespace</span><br><span class="line">NAME               STATUS   AGE</span><br><span class="line">calico-apiserver   Active   3h26m</span><br><span class="line">calico-system      Active   3h26m</span><br><span class="line">default            Active   6h18m</span><br><span class="line">kube-node-lease    Active   6h18m</span><br><span class="line">kube-public        Active   6h18m</span><br><span class="line">kube-system        Active   6h18m</span><br><span class="line">luovip             Active   7s</span><br><span class="line">tigera-operator    Active   3h41m</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2-YAML文件创建"><a href="#8-2-2-YAML文件创建" class="headerlink" title="8.2.2 YAML文件创建"></a>8.2.2 YAML文件创建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; namespace.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Namespace</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: luovipyu</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f namespace.yml</span><br><span class="line">namespace/luovipyu created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get namespace</span><br><span class="line">NAME               STATUS   AGE</span><br><span class="line">calico-apiserver   Active   3h33m</span><br><span class="line">calico-system      Active   3h33m</span><br><span class="line">default            Active   6h25m</span><br><span class="line">kube-node-lease    Active   6h25m</span><br><span class="line">kube-public        Active   6h25m</span><br><span class="line">kube-system        Active   6h25m</span><br><span class="line">luovip             Active   6m54s</span><br><span class="line">luovipyu           Active   26s</span><br><span class="line">tigera-operator    Active   3h48m</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3-删除namespace"><a href="#8-2-3-删除namespace" class="headerlink" title="8.2.3 删除namespace"></a>8.2.3 删除namespace</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl delete namespace luovipyu   <span class="comment"># 会删除名字空间下的所有内容</span></span><br><span class="line">namespace <span class="string">&quot;luovipyu&quot;</span> deleted</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f namespace.yml</span><br><span class="line">namespace/luovipyu created</span><br><span class="line">root@k8s-master:~# <span class="built_in">cat</span> namespace.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: luovipyu</span><br><span class="line">root@k8s-master:~# kubectl get namespace</span><br><span class="line">NAME               STATUS   AGE</span><br><span class="line">calico-apiserver   Active   3h39m</span><br><span class="line">calico-system      Active   3h39m</span><br><span class="line">default            Active   6h30m</span><br><span class="line">kube-node-lease    Active   6h30m</span><br><span class="line">kube-public        Active   6h30m</span><br><span class="line">kube-system        Active   6h30m</span><br><span class="line">luovip             Active   12m</span><br><span class="line">luovipyu           Active   13s</span><br><span class="line">tigera-operator    Active   3h54m</span><br></pre></td></tr></table></figure>

<h3 id="8-2-4-创建带有namespace属性的资源"><a href="#8-2-4-创建带有namespace属性的资源" class="headerlink" title="8.2.4 创建带有namespace属性的资源"></a>8.2.4 创建带有namespace属性的资源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl run httpd --image=httpd --namespace=luovipyu</span><br><span class="line">pod/httpd created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -n luovipyu</span><br><span class="line">NAME    READY   STATUS             RESTARTS   AGE</span><br><span class="line">httpd   1/1     Running            0          18s</span><br><span class="line">nginx   0/1     ImagePullBackOff   0          106s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每次查询和创建资源都需要带–namespace=luovipyu挺麻烦，可以设置默认值</span></span><br><span class="line">root@k8s-master:~# kubectl config set-context --current --namespace=luovipyu</span><br><span class="line">Context <span class="string">&quot;kubernetes-admin@kubernetes&quot;</span> modified.</span><br><span class="line">root@k8s-master:~# kubectl config view | grep namespace</span><br><span class="line">    namespace: luovipyu</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME    READY   STATUS             RESTARTS   AGE</span><br><span class="line">httpd   1/1     Running            0          3m3s</span><br><span class="line">nginx   0/1     ImagePullBackOff   0          4m31s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除namespace会删除其下所有资源，但如果要删除已经切换为默认值的namespace时，可能会卡住，所以先把默认值切换为其他，然后再删除</span></span><br><span class="line">root@k8s-master:~# kubectl config set-context --current --namespace=default</span><br><span class="line">Context <span class="string">&quot;kubernetes-admin@kubernetes&quot;</span> modified.</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete namespaces luovip luovipyu</span><br><span class="line">namespace <span class="string">&quot;luovip&quot;</span> deleted</span><br><span class="line">namespace <span class="string">&quot;luovipyu&quot;</span> deleted</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get namespace</span><br><span class="line">NAME               STATUS   AGE</span><br><span class="line">calico-apiserver   Active   3h49m</span><br><span class="line">calico-system      Active   3h49m</span><br><span class="line">default            Active   6h41m</span><br><span class="line">kube-node-lease    Active   6h41m</span><br><span class="line">kube-public        Active   6h41m</span><br><span class="line">kube-system        Active   6h41m</span><br><span class="line">tigera-operator    Active   4h4m</span><br></pre></td></tr></table></figure>

<h2 id="8-3-CRD自定义资源"><a href="#8-3-CRD自定义资源" class="headerlink" title="8.3 CRD自定义资源"></a>8.3 CRD自定义资源</h2><p>&emsp;&emsp;CRD（Custom Resource Definition，自定义资源定义）是Kubernetes提供的一种扩展机制，允许用户通过YAML文件定义自定义资源类型，并将其注册到Kubernetes API中，使其与内置资源（如Pod、 Deployment）一样被管理</p>
<p>&emsp;&emsp;本质：CRD是对自定义资源的元数据描述，定义了资源的名称、结构、版本、作用域等<br>&emsp;&emsp;作用：扩展Kubernetes API，支持用户自定义资源的管理和自动化操作</p>
<p>CRD核心字段：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>apiVersion</td>
<td>CRD的API版本，固定为apiextensions.k8s.io&#x2F;v1</td>
<td>apiVersion:apiextensions.k8s.io&#x2F;v1</td>
</tr>
<tr>
<td>kind</td>
<td>资源类型，固定为CustomResourceDefinition</td>
<td>kind: CustomResourceDefinition</td>
</tr>
<tr>
<td>metadata</td>
<td>元数据，如名称、命名空间等(名称需符合DNS子域名规则)</td>
<td>name:crontabs.stable.example.com</td>
</tr>
<tr>
<td>spec</td>
<td>核心配置，包括 API组、版本、资源范围<br/>(Namespaced&#x2F;Cluster)、字段验证规则等</td>
<td>group: stable.example.com</td>
</tr>
<tr>
<td>versions</td>
<td>支持的API版本列表，需指定至少一个存储版本( storage:true)</td>
<td>version:[v1][@ref)</td>
</tr>
<tr>
<td>names</td>
<td>资源的复数形式、单数形式、简称等(如plural:crontabs)</td>
<td>plural: crontabs</td>
</tr>
<tr>
<td>scope</td>
<td>资源作用域，Namespaced(命名空间级别)或Cluster(集群级别)</td>
<td>scope: Namespaced</td>
</tr>
</tbody></table>
<h3 id="8-3-1-CRD介绍"><a href="#8-3-1-CRD介绍" class="headerlink" title="8.3.1 CRD介绍"></a>8.3.1 CRD介绍</h3><p>&emsp;&emsp;K8S资源类型不止有namespace，还有很多，不过那都是系统自带的，现在我们来看看怎么自定义k8s中的资源</p>
<p>1.什么是CRD？</p>
<p>&emsp;&emsp;CRD（Custom Resource Definition）是 Kubernetes 提供的一种机制，允许用户定义自己的资源类型</p>
<p>&emsp;&emsp;这些自定义资源可以像 Kubernetes 原生资源（如 Pod、Service、Deployment 等）一样被管理。<br>2.为什么需要CRD？</p>
<p>&emsp;&emsp;扩展 Kubernetes API：Kubernetes 的原生资源可能无法满足所有用户的需求。CRD 允许用户定义自己的资源类型，从而扩展 Kubernetes 的功能。</p>
<p>&emsp;&emsp;管理复杂应用：有些应用可能需要管理一些特定的资源，这些资源不属于Kubernetes原生支持的范围。通过CRD可以将这些资源纳入 Kubernetes的管理范围，实现统一的资源管理</p>
<p>3.CRD的作用</p>
<p>&emsp;&emsp;定义资源结构：CRD 允许你定义资源的结构，包括其字段和数据类型</p>
<p>&emsp;&emsp;管理资源生命周期：Kubernetes 将为你管理这些自定义资源的生命周期，包括创建、更新、删除等操作</p>
<p>&emsp;&emsp;集成 Kubernetes 生态系统：CRD 可以与 Kubernetes 的其他组件（如控制器、操作符等）集成，实现更复杂的业务逻辑</p>
<p>&emsp;&emsp;在Kubernetes 的自定义资源定义（CRD）中，CRD 本身只定义了资源的结构和 API，但它不会直接执行任何创建、更新或删除操作。这些操作需要通过一个控制器（Controller）来实现。控制器是一个独立的程序，它监听 CRD 的变化，并根据这些变化执行实际的操作</p>
<h3 id="8-3-2-查询CRD以及API资源"><a href="#8-3-2-查询CRD以及API资源" class="headerlink" title="8.3.2 查询CRD以及API资源"></a>8.3.2 查询CRD以及API资源</h3><p>1.先看看系统中的api资源都有哪些，然后创建一个</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl api-resources</span><br><span class="line">NAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KIND</span><br><span class="line">bindings                           v1                           <span class="literal">true</span>            Binding</span><br><span class="line">componentstatuses    cs            v1                           <span class="literal">false</span>           ComponentStatus</span><br><span class="line">configmaps           cm            v1                           <span class="literal">true</span>            ConfigMap</span><br><span class="line">endpoints            ep            v1                           <span class="literal">true</span>            Endpoints</span><br><span class="line">events               ev            v1                           <span class="literal">true</span>            Event</span><br><span class="line">limitranges          limits        v1                           <span class="literal">true</span>            LimitRange</span><br><span class="line">namespaces           ns            v1                           <span class="literal">false</span>           Namespace</span><br><span class="line">nodes                no            v1                           <span class="literal">false</span>           Node</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>2.查看现在都有哪些自定义资源</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下资源不属于K8s，但是k8s是有的</span></span><br><span class="line">root@k8s-master:~# kubectl get crd</span><br><span class="line">NAME                                                  CREATED AT</span><br><span class="line">adminnetworkpolicies.policy.networking.k8s.io         2025-05-17T03:05:26Z</span><br><span class="line">apiservers.operator.tigera.io                         2025-05-17T03:05:26Z</span><br><span class="line">bgpconfigurations.crd.projectcalico.org               2025-05-17T03:05:26Z</span><br><span class="line">bgpfilters.crd.projectcalico.org                      2025-05-17T03:05:26Z</span><br><span class="line">bgppeers.crd.projectcalico.org                        2025-05-17T03:05:26Z</span><br><span class="line">blockaffinities.crd.projectcalico.org                 2025-05-17T03:05:26Z</span><br><span class="line">caliconodestatuses.crd.projectcalico.org              2025-05-17T03:05:26Z</span><br><span class="line">clusterinformations.crd.projectcalico.org             2025-05-17T03:05:26Z</span><br><span class="line">felixconfigurations.crd.projectcalico.org             2025-05-17T03:05:26Z</span><br><span class="line">globalnetworkpolicies.crd.projectcalico.org           2025-05-17T03:05:26Z</span><br><span class="line">globalnetworksets.crd.projectcalico.org               2025-05-17T03:05:26Z</span><br><span class="line">hostendpoints.crd.projectcalico.org                   2025-05-17T03:05:26Z</span><br><span class="line">imagesets.operator.tigera.io                          2025-05-17T03:05:26Z</span><br><span class="line">installations.operator.tigera.io                      2025-05-17T03:05:26Z</span><br><span class="line">ipamblocks.crd.projectcalico.org                      2025-05-17T03:05:26Z</span><br><span class="line">ipamconfigs.crd.projectcalico.org                     2025-05-17T03:05:26Z</span><br><span class="line">ipamhandles.crd.projectcalico.org                     2025-05-17T03:05:26Z</span><br><span class="line">ippools.crd.projectcalico.org                         2025-05-17T03:05:26Z</span><br><span class="line">ipreservations.crd.projectcalico.org                  2025-05-17T03:05:26Z</span><br><span class="line">kubecontrollersconfigurations.crd.projectcalico.org   2025-05-17T03:05:26Z</span><br><span class="line">networkpolicies.crd.projectcalico.org                 2025-05-17T03:05:26Z</span><br><span class="line">networksets.crd.projectcalico.org                     2025-05-17T03:05:26Z</span><br><span class="line">tiers.crd.projectcalico.org                           2025-05-17T03:05:26Z</span><br><span class="line">tigerastatuses.operator.tigera.io                     2025-05-17T03:05:26Z</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3-创建CRD以及API资源"><a href="#8-3-3-创建CRD以及API资源" class="headerlink" title="8.3.3 创建CRD以及API资源"></a>8.3.3 创建CRD以及API资源</h3><p>1.创建一个自己的crd，crd将注册为api资源</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; crd.yaml &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  <span class="comment"># 名字必需与下面的 spec 字段匹配，并且格式为 &#x27;&lt;名称的复数形式&gt;.&lt;组名&gt;&#x27;</span></span><br><span class="line">  name: crontabs.stable.example.com</span><br><span class="line">spec:</span><br><span class="line">  <span class="comment"># 组名称，用于 REST API：/apis/&lt;组&gt;/&lt;版本&gt;</span></span><br><span class="line">  group: stable.example.com</span><br><span class="line">  <span class="comment"># 列举此 CustomResourceDefinition 所支持的版本</span></span><br><span class="line">  versions:</span><br><span class="line">    - name: v1</span><br><span class="line">      <span class="comment"># 每个版本都可以通过 served 标志来独立启用或禁止</span></span><br><span class="line">      served: <span class="literal">true</span></span><br><span class="line">      <span class="comment"># 其中一个且只有一个版本必需被标记为存储版本</span></span><br><span class="line">      storage: <span class="literal">true</span></span><br><span class="line">      schema:</span><br><span class="line">        openAPIV3Schema:</span><br><span class="line">          <span class="built_in">type</span>: object</span><br><span class="line">          properties:</span><br><span class="line">            spec:</span><br><span class="line">              <span class="built_in">type</span>: object</span><br><span class="line">              properties:</span><br><span class="line">                cronSpec:</span><br><span class="line">                  <span class="built_in">type</span>: string</span><br><span class="line">                image:</span><br><span class="line">                  <span class="built_in">type</span>: string</span><br><span class="line">                replicas:</span><br><span class="line">                  <span class="built_in">type</span>: <span class="built_in">integer</span></span><br><span class="line">  <span class="comment"># 可以是 Namespaced 或 Cluster</span></span><br><span class="line">  scope: Namespaced</span><br><span class="line">  names:</span><br><span class="line">    <span class="comment"># 名称的复数形式，用于 URL：/apis/&lt;组&gt;/&lt;版本&gt;/&lt;名称的复数形式&gt;</span></span><br><span class="line">    plural: crontabs</span><br><span class="line">    <span class="comment"># 名称的单数形式，作为命令行使用时和显示时的别名</span></span><br><span class="line">    singular: crontab</span><br><span class="line">    <span class="comment"># kind 通常是单数形式的驼峰命名（CamelCased）形式。你的资源清单会使用这一形式。</span></span><br><span class="line">    kind: CronTab</span><br><span class="line">    <span class="comment"># shortNames 允许你在命令行使用较短的字符串来匹配资源</span></span><br><span class="line">    shortNames:</span><br><span class="line">    - ct</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl apply -f crd.yaml</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.再看就会有自己的crd资源和api资源了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl get crd</span><br><span class="line">NAME                                                  CREATED AT</span><br><span class="line">...</span><br><span class="line">crontabs.stable.example.com                           2025-05-17T06:16:04Z</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl api-resources | grep crontabs</span><br><span class="line">NAME          SHORTNAMES                      APIVERSION                          NAMESPACED   KIND</span><br><span class="line">crontabs      ct                              stable.example.com/v1               <span class="literal">true</span>         CronTab</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl describe crd crontabs.stable.example.com</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4-查询API资源结构与参数"><a href="#8-3-4-查询API资源结构与参数" class="headerlink" title="8.3.4 查询API资源结构与参数"></a>8.3.4 查询API资源结构与参数</h3><p>&emsp;&emsp;既然已经注册为api资源，来看看能否explain字段？</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl explain crontabs</span><br><span class="line">GROUP:      stable.example.com</span><br><span class="line">KIND:       CronTab</span><br><span class="line">VERSION:    v1</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">    &lt;empty&gt;</span><br><span class="line">FIELDS:</span><br><span class="line">  apiVersion    &lt;string&gt;</span><br><span class="line">  kind  &lt;string&gt;</span><br><span class="line">  metadata      &lt;ObjectMeta&gt;</span><br><span class="line">  spec  &lt;Object&gt;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看有哪些spec</span></span><br><span class="line">root@k8s-master:~# kubectl explain crontabs.spec</span><br><span class="line">GROUP:      stable.example.com</span><br><span class="line">KIND:       CronTab</span><br><span class="line">VERSION:    v1</span><br><span class="line"></span><br><span class="line">FIELD: spec &lt;Object&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line">    &lt;empty&gt;</span><br><span class="line">FIELDS:</span><br><span class="line">  cronSpec      &lt;string&gt;</span><br><span class="line">    &lt;no description&gt;</span><br><span class="line"></span><br><span class="line">  image &lt;string&gt;</span><br><span class="line">    &lt;no description&gt;</span><br><span class="line"></span><br><span class="line">  replicas      &lt;<span class="built_in">integer</span>&gt;</span><br><span class="line">    &lt;no description&gt;</span><br><span class="line"><span class="comment"># 一切正常，看来已经创建了自定义资源，接下来就是等开发人员通过编程等方式创建operator等控制器，来使用我们的资源了</span></span><br></pre></td></tr></table></figure>

<h1 id="9-Pod"><a href="#9-Pod" class="headerlink" title="9 Pod"></a>9 Pod</h1><h2 id="9-1-关于pod"><a href="#9-1-关于pod" class="headerlink" title="9.1 关于pod"></a>9.1 关于pod</h2><p>&emsp;&emsp;Pod由一个或多个紧密耦合的容器组成</p>
<p>&emsp;&emsp;它们之间共享网络、存储等资源</p>
<p>&emsp;&emsp;pod是Kubernetes中最小的工作单元</p>
<p>&emsp;&emsp;Pod中的容器会一起启动和停止</p>
<h2 id="9-2-Pod生命周期"><a href="#9-2-Pod生命周期" class="headerlink" title="9.2 Pod生命周期"></a>9.2 Pod生命周期</h2><p>&emsp;&emsp;Pod遵循一个预定义的生命周期，起始于Pending阶段，如果至少其中有一个主要容器正常启动，则进入Running，之后取决于Pod中是否有容器以失败状态结束而进入Succeeded或者Failed阶段。但有时集群节点之间出现网络故障，无法获取Pod状态时，就会出现Unknown状态</p>
<h2 id="9-3-创建Pod"><a href="#9-3-创建Pod" class="headerlink" title="9.3 创建Pod"></a>9.3 创建Pod</h2><p>&emsp;&emsp;1.一个Pod中只有一个业务容器</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.yml文件创建pod</span></span><br><span class="line"><span class="built_in">cat</span> &gt; pod.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: luovippod</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: hello</span></span><br><span class="line"><span class="string">    image: httpd</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo &quot;Hello, China!&quot; &amp;&amp; sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">  restartPolicy: OnFailure</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f pod.yml</span><br><span class="line">pod/luovippod created</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">luovippod   1/1     Running   0          5s</span><br><span class="line">root@k8s-master:~# kubectl logs luovippod</span><br><span class="line">Hello, China!</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete pod luovippod    删除pod</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.命令行创建pod</span></span><br><span class="line">root@k8s-master:~# kubectl run luoyupod --image=nginx --port=80</span><br><span class="line">pod/luoyupod created</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">luovippod   1/1     Running   0          7m56s</span><br><span class="line">luoyupod    1/1     Running   0          3m38s</span><br><span class="line">root@k8s-master:~# kubectl get pod -o wide</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE     IP              NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">luovippod   1/1     Running   0          8m6s    172.16.194.71   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">luoyupod    1/1     Running   0          3m48s   172.16.194.72   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;2.一个Pod中有多个业务容器</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; multicontainer.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: pod</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: nginx</span></span><br><span class="line"><span class="string">    image: nginx</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo &quot;Hello, luoyu!&quot; &amp;&amp; sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">  - name: httpd</span></span><br><span class="line"><span class="string">    image: httpd</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    ports:</span></span><br><span class="line"><span class="string">      - name: web</span></span><br><span class="line"><span class="string">        containerPort: 80</span></span><br><span class="line"><span class="string">  restartPolicy: OnFailure</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f multicontainer.yml</span><br><span class="line">pod/pod created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">luovippod   1/1     Running   0          18m</span><br><span class="line">luoyupod    1/1     Running   0          14m</span><br><span class="line">pod         2/2     Running   0          9s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get -f multicontainer.yml -o wide</span><br><span class="line">NAME   READY   STATUS    RESTARTS   AGE   IP             NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">pod    2/2     Running   0          68s   172.16.126.3   k8s-worker2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# curl 172.16.126.3</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="9-4-修改Pod"><a href="#9-4-修改Pod" class="headerlink" title="9.4 修改Pod"></a>9.4 修改Pod</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接修改yaml文件，然后执行以下命令</span></span><br><span class="line">kubectl apply -f pod.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑Etcd数据</span></span><br><span class="line">kubectl edit pod luovippod</span><br><span class="line"></span><br><span class="line"><span class="comment"># patch参数</span></span><br><span class="line">kubectl get pod luovippod -o json</span><br><span class="line">kubectl get pod luovippod -o json | grep cnlxh</span><br><span class="line"></span><br><span class="line">注明：工作中的修改pod一般时k8s会创建新的pod并删除旧的pod</span><br></pre></td></tr></table></figure>

<h2 id="9-5-进入pod中的容器"><a href="#9-5-进入pod中的容器" class="headerlink" title="9.5 进入pod中的容器"></a>9.5 进入pod中的容器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl get pod -o wide</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">luovippod   1/1     Running   0          37m   172.16.194.71   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">luoyupod    1/1     Running   0          33m   172.16.194.72   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod         2/2     Running   0          19m   172.16.126.3    k8s-worker2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl <span class="built_in">exec</span> -it pod -c httpd  -- /bin/bash</span><br><span class="line">root@pod:/usr/local/apache2# <span class="built_in">echo</span> MyCity is ChengDu! &gt; htdocs/index.html</span><br><span class="line">root@pod:/usr/local/apache2# <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">root@k8s-master:~# curl http://172.16.126.3</span><br><span class="line">MyCity is ChengDu!</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数说明：</span></span><br><span class="line"> 1、-c 参数可以指定需要进入pod中的哪个容器</span><br><span class="line"> 2、-- 是K8S命令和预期容器内部执行命令的连接符</span><br><span class="line"> 3、/bin/sh是指进入容器中执行什么命令 </span><br><span class="line"> 4、退出执行<span class="built_in">exit</span></span><br></pre></td></tr></table></figure>

<h2 id="9-6-Init类型容器"><a href="#9-6-Init类型容器" class="headerlink" title="9.6 Init类型容器"></a>9.6 Init类型容器</h2><p>&emsp;&emsp;Init容器是一种特殊容器，在Pod内的应用容器启动之前运行，如果Pod的Init容器失败，kubelet会不断地重启该 Init 容器直到该容器成功为止。 然而，如果 Pod 对应的 restartPolicy 值为 “Never”，并且 Pod的 Init 容器失败， 则 Kubernetes 会将整个 Pod 状态设置为失败</p>
<p>&emsp;&emsp;Init容器与普通的容器非常像，除了如下两点：</p>
<p>&emsp;&emsp;&emsp;1.正常情况下，它们最终都会处于completed状态</p>
<p>&emsp;&emsp;&emsp;2.每个都必须在下一个启动之前成功完成</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据安排，myapp-container的容器将等待两个init结束之后才会启动，也就是40秒之后才会启动</span></span><br><span class="line"><span class="built_in">cat</span> &gt; init.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: initpd</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    app: myapp</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: myapp-container</span></span><br><span class="line"><span class="string">    image: busybox</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">  initContainers:</span></span><br><span class="line"><span class="string">  - name: init-myservice</span></span><br><span class="line"><span class="string">    image: busybox</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &quot;sleep 20&quot;]</span></span><br><span class="line"><span class="string">  - name: init-mydb</span></span><br><span class="line"><span class="string">    image: busybox</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &quot;sleep 20&quot;]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f init.yml</span><br><span class="line">pod/initpd created</span><br><span class="line"></span><br><span class="line"><span class="comment"># -w参数可以实时查看pod的状态变化</span></span><br><span class="line">root@k8s-master:~# kubectl get -f init.yml -w</span><br><span class="line">NAME     READY   STATUS     RESTARTS   AGE</span><br><span class="line">initpd   0/1     Init:0/2   0          19s</span><br><span class="line">initpd   0/1     Init:1/2   0          21s</span><br><span class="line">initpd   0/1     Init:1/2   0          22s</span><br><span class="line">initpd   0/1     PodInitializing   0          42s</span><br><span class="line">initpd   1/1     Running           0          43s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -w</span><br><span class="line">NAME        READY   STATUS     RESTARTS   AGE</span><br><span class="line">initpd      0/1     Init:1/2   0          34s</span><br><span class="line">luovippod   1/1     Running    0          56m</span><br><span class="line">luoyupod    1/1     Running    0          51m</span><br><span class="line">pod         2/2     Running    0          37m</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pods</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">initpd      1/1     Running   0          104s</span><br><span class="line">luovippod   1/1     Running   0          57m</span><br><span class="line">luoyupod    1/1     Running   0          52m</span><br><span class="line">pod         2/2     Running   0          39m</span><br></pre></td></tr></table></figure>

<h2 id="9-7-Sidecar类型容器"><a href="#9-7-Sidecar类型容器" class="headerlink" title="9.7 Sidecar类型容器"></a>9.7 Sidecar类型容器</h2><p>&emsp;&emsp;一般来讲，Sidecar容器可以：</p>
<p>&emsp;&emsp;&emsp;1.日志代理&#x2F;转发，例如 fluentd</p>
<p>&emsp;&emsp;&emsp;2.Service Mesh，比如 Istio，Linkerd</p>
<p>&emsp;&emsp;&emsp;3.代理，比如 Docker Ambassador</p>
<p>&emsp;&emsp;&emsp;4.探活：检查某些组件是不是正常工作</p>
<p>&emsp;&emsp;&emsp;5.其他辅助性的工作，比如拷贝文件，下载文件等</p>
<p><img src="/images/Sidecar.png" title="Sidecar容器"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两个容器挂载了同一个目录，一个容器负责写入数据，一个容器负责对外展示</span></span><br><span class="line"><span class="built_in">cat</span> &gt; sidecar.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: sidecarpod</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: httpd</span></span><br><span class="line"><span class="string">    image: httpd</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    volumeMounts:</span></span><br><span class="line"><span class="string">      - mountPath: /usr/local/apache2/htdocs/</span></span><br><span class="line"><span class="string">        name: luoyuvolume</span></span><br><span class="line"><span class="string">  - name: busybox</span></span><br><span class="line"><span class="string">    image: busybox</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo &quot;Hello sidecar&quot; &gt; /usr/local/apache2/htdocs/index.html &amp;&amp; sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">    volumeMounts:</span></span><br><span class="line"><span class="string">      - mountPath: /usr/local/apache2/htdocs/</span></span><br><span class="line"><span class="string">        name: luoyuvolume</span></span><br><span class="line"><span class="string">  restartPolicy: OnFailure</span></span><br><span class="line"><span class="string">  volumes:</span></span><br><span class="line"><span class="string">    - name: luoyuvolume</span></span><br><span class="line"><span class="string">      emptyDir: &#123;&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f sidecar.yml</span><br><span class="line">pod/sidecarpod created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get -f sidecar.yml -o wide</span><br><span class="line">NAME         READY   STATUS    RESTARTS   AGE   IP              NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">sidecarpod   2/2     Running   0          9s    172.16.194.74   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# curl http://172.16.194.74</span><br><span class="line">Hello sidecar</span><br></pre></td></tr></table></figure>

<h2 id="9-8-静态Pod"><a href="#9-8-静态Pod" class="headerlink" title="9.8 静态Pod"></a>9.8 静态Pod</h2><p>&emsp;&emsp;静态 Pod 在指定的节点上由 kubelet 守护进程直接管理，不需要 API 服务器监管。 与由控制面管理的Pod（例如，Deployment） 不同；kubelet 监视每个静态 Pod（在它崩溃之后重新启动）</p>
<p>&emsp;&emsp;静态 Pod 永远都会绑定到一个指定节点上的 Kubelet</p>
<p>&emsp;&emsp;kubelet 会尝试通过 Kubernetes API 服务器为每个静态 Pod 自动创建一个 mirror Pod。 这意味着节点上运行的静态 Pod 对 API 服务来说是可见的，但是不能通过 API 服务器来控制。 Pod 名称将把以连字符开头的节点主机名作为后缀</p>
<p>&emsp;&emsp;运行中的 kubelet 会定期扫描配置的目录中的变化， 并且根据文件中出现&#x2F;消失的 Pod 来添加&#x2F;删除Pod</p>
<p>1.查找静态pod的编写路径</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# systemctl status kubelet</span><br><span class="line">...</span><br><span class="line">    Drop-In: /usr/lib/systemd/system/kubelet.service.d</span><br><span class="line">             └─10-kubeadm.conf</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# <span class="built_in">tail</span> /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line">[Service]</span><br><span class="line">...</span><br><span class="line">Environment=<span class="string">&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# grep -i static /var/lib/kubelet/config.yaml</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br></pre></td></tr></table></figure>

<p>2.编写静态pod</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; static.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Pod</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: staticpod</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  containers:</span></span><br><span class="line"><span class="string">  - name: hello</span></span><br><span class="line"><span class="string">    image: busybox</span></span><br><span class="line"><span class="string">    imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">    command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo &quot;Hello, lixiaohui!&quot; &amp;&amp; sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">  restartPolicy: OnFailure</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把这个yaml文件复制到/etc/kubernetes/manifests，然后观察pod列表，然后把yaml文件移出此文件夹，再观察pod列表</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">cp</span> static.yml /etc/kubernetes/manifests/</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME                   READY   STATUS      RESTARTS   AGE</span><br><span class="line">initpd                 1/1     Running     0          40m</span><br><span class="line">luovippod              0/1     Completed   0          95m</span><br><span class="line">luoyupod               1/1     Running     0          91m</span><br><span class="line">pod                    1/2     NotReady    0          77m</span><br><span class="line">sidecarpod             2/2     Running     0          31m</span><br><span class="line">staticpod-k8s-master   1/1     Running     0          12s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除/etc/kubernetes/manifests文件中的yml文件，再观察pod列表</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">rm</span> -rf /etc/kubernetes/manifests/static.yml</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">NAME         READY   STATUS      RESTARTS   AGE</span><br><span class="line">initpd       1/1     Running     0          41m</span><br><span class="line">luovippod    0/1     Completed   0          97m</span><br><span class="line">luoyupod     1/1     Running     0          92m</span><br><span class="line">pod          1/2     NotReady    0          78m</span><br><span class="line">sidecarpod   2/2     Running     0          32m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 维持集群运行的文件如下：</span></span><br><span class="line">root@k8s-master:/etc/kubernetes/manifests# <span class="built_in">ls</span></span><br><span class="line">etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml  static.yml</span><br></pre></td></tr></table></figure>

<h2 id="9-9-Pod删除"><a href="#9-9-Pod删除" class="headerlink" title="9.9 Pod删除"></a>9.9 Pod删除</h2><p>&emsp;&emsp;kubectl delete pod –all会删除所有pod</p>
<p>&emsp;&emsp;kubectl delete pod pod名称—删除指定的pod</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl get pods</span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">initpd                 1/1     Running   0          13m</span><br><span class="line">luovippod              1/1     Running   0          9m23s</span><br><span class="line">luoyupod               1/1     Running   0          169m</span><br><span class="line">pod                    2/2     Running   0          7m51s</span><br><span class="line">sidecarpod             2/2     Running   0          27s</span><br><span class="line">staticpod-k8s-master   1/1     Running   0          2s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete pod luovippod</span><br><span class="line">root@k8s-master:~# kubectl delete pod -all</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pods</span><br><span class="line">No resources found <span class="keyword">in</span> default namespace.</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -n kube-system</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-76fccbbb6b-l7jq9             1/1     Running   0          35h</span><br><span class="line">coredns-76fccbbb6b-nd68g             1/1     Running   0          35h</span><br><span class="line">etcd-k8s-master                      1/1     Running   0          35h</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   0          35h</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   0          35h</span><br><span class="line">kube-proxy-8n6x5                     1/1     Running   0          32h</span><br><span class="line">kube-proxy-mcwv7                     1/1     Running   0          35h</span><br><span class="line">kube-proxy-xk4h4                     1/1     Running   0          32h</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   0          35h</span><br></pre></td></tr></table></figure>

<h1 id="10-Kubernetes控制器"><a href="#10-Kubernetes控制器" class="headerlink" title="10 Kubernetes控制器"></a>10 Kubernetes控制器</h1><h2 id="10-1-什么是控制器"><a href="#10-1-什么是控制器" class="headerlink" title="10.1 什么是控制器"></a>10.1 什么是控制器</h2><p>&emsp;&emsp;当你设置了温度，告诉了空调遥控器你的期望状态（Desired State）。 房间的实际温度是当前状态（Current State）。 通过对遥控器的开关控制，遥控器让其当前状态接近期望状态<br>&emsp;&emsp;在 Kubernetes 中，控制器通过监控集群的公共状态，并致力于将当前状态转变为期望的状态</p>
<p>&emsp;&emsp;作为设计原则之一，Kubernetes 使用了很多控制器，每个控制器管理集群状态的一个特定方面。 最常见的一个特定的控制器使用一种类型的资源作为它的期望状态， 控制器管理控制另外一种类型的资源向它的期望状态演化</p>
<h2 id="10-2-Replica-Set概念"><a href="#10-2-Replica-Set概念" class="headerlink" title="10.2 Replica Set概念"></a>10.2 Replica Set概念</h2><p>&emsp;&emsp;ReplicationController确保在任何时候都有特定数量的Pod副本处于运行状态。 换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的<br>&emsp;&emsp;ReplicaSet的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p>
<p>说明： 现在推荐使用配置ReplicaSet的Deployment来建立副本管理机制</p>
<h2 id="10-3-Replica-Set-工作原理"><a href="#10-3-Replica-Set-工作原理" class="headerlink" title="10.3 Replica Set 工作原理"></a>10.3 Replica Set 工作原理</h2><p>&emsp;&emsp;RepicaSet是通过一组字段来定义的，包括一个用来识别可获得的 Pod 的集合的选择算符、一个用来标明应该维护的副本个数的数值、一个用来指定应该创建新 Pod 以满足副本个数条件时要使用的 Pod 模板等等。 每个 ReplicaSet 都通过根据需要创建和 删除 Pod 以使得副本个数达到期望值， 进而实现其存在价值。当 ReplicaSet 需要创建新的 Pod 时，会使用所提供的 Pod 模板</p>
<p>&emsp;&emsp;1.ReplicaSet也需要apiVersion、kind和metadata字段</p>
<p>&emsp;&emsp;2.Pod 选择算符：.spec.selector 字段是一个标签选择算符。在 ReplicaSet 中，.spec.template.metadata.labels 的值必须与 spec.selector 值 相匹配，否则该配置会被API拒绝</p>
<p>&emsp;&emsp;3.可以通过设置 .spec.replicas 来指定要同时运行的 Pod个数。 ReplicaSet 创建、删除 Pods 以与此值匹配</p>
<h2 id="10-4-ReplicaSet使用"><a href="#10-4-ReplicaSet使用" class="headerlink" title="10.4 ReplicaSet使用"></a>10.4 ReplicaSet使用</h2><p>&emsp;&emsp;使用nginx镜像创建具有3个pod的RS,并分配合适的标签</p>
<h3 id="10-4-1-创建yml文件"><a href="#10-4-1-创建yml文件" class="headerlink" title="10.4.1 创建yml文件"></a>10.4.1 创建yml文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; rs.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: ReplicaSet</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nginxrstest</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    app: nginxrstest</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 3</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      app: nginxrstest</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        app: nginxrstest</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: nginx</span></span><br><span class="line"><span class="string">        image: nginx</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">          - name: http</span></span><br><span class="line"><span class="string">            containerPort: 80</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="10-4-2-操作ReplicaSet"><a href="#10-4-2-操作ReplicaSet" class="headerlink" title="10.4.2 操作ReplicaSet"></a>10.4.2 操作ReplicaSet</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl create -f rs.yml</span><br><span class="line">root@k8s-master:~# kubectl get rs</span><br><span class="line">NAME          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginxrstest   3         3         3       3m45s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod --show-labels</span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE    LABELS</span><br><span class="line">nginxrstest-5bvpr   1/1     Running   0          7m1s   app=nginxrstest</span><br><span class="line">nginxrstest-9d86s   1/1     Running   0          7m1s   app=nginxrstest</span><br><span class="line">nginxrstest-k79cw   1/1     Running   0          7m1s   app=nginxrstest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 被动高可用</span></span><br><span class="line">root@k8s-master:~# kubectl delete pod --all</span><br><span class="line">pod <span class="string">&quot;nginxrstest-5bvpr&quot;</span> deleted</span><br><span class="line">pod <span class="string">&quot;nginxrstest-9d86s&quot;</span> deleted</span><br><span class="line">pod <span class="string">&quot;nginxrstest-k79cw&quot;</span> deleted</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get replicasets.apps,pods</span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginxrstest   3         3         3       12m</span><br><span class="line"></span><br><span class="line">NAME                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginxrstest-86dd7   1/1     Running   0          3m6s</span><br><span class="line">pod/nginxrstest-bbzxd   1/1     Running   0          3m6s</span><br><span class="line">pod/nginxrstest-ndgxg   1/1     Running   0          3m6s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩容</span></span><br><span class="line">root@k8s-master:~# kubectl scale replicaset nginxrstest --replicas 4</span><br><span class="line">replicaset.apps/nginxrstest scaled</span><br><span class="line">root@k8s-master:~# kubectl get replicasets.apps nginxrstest</span><br><span class="line">NAME          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginxrstest   4         4         4       16m</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get replicasets.apps,pods -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除</span></span><br><span class="line">root@k8s-master:~# kubectl delete replicasets.apps nginxrstest</span><br><span class="line">replicaset.apps <span class="string">&quot;nginxrstest&quot;</span> deleted</span><br><span class="line">root@k8s-master:~# kubectl get pod</span><br><span class="line">No resources found <span class="keyword">in</span> default namespace.</span><br></pre></td></tr></table></figure>

<h2 id="10-5-Deployment"><a href="#10-5-Deployment" class="headerlink" title="10.5 Deployment"></a>10.5 Deployment</h2><p>&emsp;&emsp;ReplicaSet确保任何时间都有指定数量的Pod副本在运行。 然而，Deployment是一个更高级的概念，它管理ReplicaSet，并向Pod提供声明式的更新以及许多其他有用的功能。 因此，建议使用 Deployment 而不是直接使用 ReplicaSet，除非需要自定义更新业务流程或根本不需要更新<br>&emsp;&emsp;这实际上意味着，可能永远不需要操作ReplicaSet对象：而是使用Deployment，并在spec部分定义应用</p>
<p><img src="/images/Deployment.png" title="Deployment"></p>
<h3 id="10-5-1-创建yml文件"><a href="#10-5-1-创建yml文件" class="headerlink" title="10.5.1 创建yml文件"></a>10.5.1 创建yml文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; deployment.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nginx-deployment</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 3</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      app: nginx</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        app: nginx</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: nginx</span></span><br><span class="line"><span class="string">        image: nginx:1.16.1</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="10-5-2-创建Deployment"><a href="#10-5-2-创建Deployment" class="headerlink" title="10.5.2 创建Deployment"></a>10.5.2 创建Deployment</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用nginx镜像创建具有3个副本的Deployment，并分配合适的属性</span></span><br><span class="line"><span class="comment"># 发现deployment管理了一个RS，而RS又实现了3个pod</span></span><br><span class="line">root@k8s-master:~# kubectl create -f deployment.yml</span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployment.apps</span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3/3     3            3           20s</span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl get pods --show-labels(可选)</span></span><br><span class="line">  Deployment控制器将pod-template-hash标签添加到Deployment所创建或收留的每个ReplicaSet，此标签可确保Deployment的子 ReplicaSets不重叠</span><br><span class="line">root@k8s-master:~# kubectl get pods --show-labels</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE   LABELS</span><br><span class="line">nginx-deployment-8d94c585f-ngm9d   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585f</span><br><span class="line">nginx-deployment-8d94c585f-wf4mc   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585f</span><br><span class="line">nginx-deployment-8d94c585f-wjzkw   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585f</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployments.apps,replicasets.apps,pods -l app=nginx</span><br><span class="line">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment   3/3     3            3           2m20s</span><br><span class="line"></span><br><span class="line">NAME                                         DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginx-deployment-8d94c585f   3         3         3       2m20s</span><br><span class="line"></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-deployment-8d94c585f-ngm9d   1/1     Running   0          2m20s</span><br><span class="line">pod/nginx-deployment-8d94c585f-wf4mc   1/1     Running   0          2m20s</span><br><span class="line">pod/nginx-deployment-8d94c585f-wjzkw   1/1     Running   0          2m20s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="10-5-3-更新Deployment"><a href="#10-5-3-更新Deployment" class="headerlink" title="10.5.3 更新Deployment"></a>10.5.3 更新Deployment</h3><p>&emsp;&emsp;1.将deployment的镜像更改一次</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment的更新策略</span></span><br><span class="line">root@k8s-master:~# kubectl get deployments.apps nginx-deployment -o yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">...</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 25%</span><br><span class="line">      maxUnavailable: 25%</span><br><span class="line">    <span class="built_in">type</span>: RollingUpdate</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl <span class="built_in">set</span> image deployments/nginx-deployment nginx=nginx:1.17.1 --record</span><br><span class="line">Flag --record has been deprecated, --record will be removed <span class="keyword">in</span> the future</span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看更新的进度---更新过程是多了一个replicaset</span></span><br><span class="line">root@k8s-master:~# kubectl rollout status deployment/nginx-deployment</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">deployment <span class="string">&quot;nginx-deployment&quot;</span> successfully rolled out</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployments.apps,replicasets.apps,pods -l app=nginx</span><br><span class="line">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment   3/3     3            3           5m43s</span><br><span class="line"></span><br><span class="line">NAME                                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginx-deployment-5d457cdfc8   3         3         3       84s</span><br><span class="line">replicaset.apps/nginx-deployment-8d94c585f    0         0         0       5m43s</span><br><span class="line"></span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-deployment-5d457cdfc8-7whnx   1/1     Running   0          66s</span><br><span class="line">pod/nginx-deployment-5d457cdfc8-b7njk   1/1     Running   0          84s</span><br><span class="line">pod/nginx-deployment-5d457cdfc8-x4zv8   1/1     Running   0          55s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;2.更新的策略</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先创建了一个新的Pod，然后删除了一些旧的Pods， 并创建了新的Pods。不会杀死老Pods，直到有足够的数量新的Pods已经出现</span></span><br><span class="line"><span class="comment"># 在足够数量的旧Pods被杀死前并没有创建新Pods。确保至少2个Pod可用，同时最多总共4个pod可用</span></span><br><span class="line"><span class="comment"># Deployment可确保在更新时仅关闭一定数量的Pod。默认情况下确保至少所需Pods 75%处于运行状态（最大不可用比例为 25%）</span></span><br><span class="line">root@k8s-master:~# kubectl describe deployments.apps nginx-deployment</span><br></pre></td></tr></table></figure>

<h3 id="10-5-4-回滚Deployment"><a href="#10-5-4-回滚Deployment" class="headerlink" title="10.5.4 回滚Deployment"></a>10.5.4 回滚Deployment</h3><p>&emsp;&emsp;假设在更新时犯错误了，将镜像名称命名设置为nginx:1.172，而不是nginx:1.17.2，发现永远无法更新成功，此时就需要回退</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl <span class="built_in">set</span> image deployments/nginx-deployment nginx=nginx:1.172 --record</span><br><span class="line">Flag --record has been deprecated, --record will be removed <span class="keyword">in</span> the future</span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl rollout status deployment/nginx-deployment</span><br><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;nginx-deployment&quot;</span> rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像拉取失败</span></span><br><span class="line">root@k8s-master:~# kubectl get pods</span><br><span class="line">NAME                                READY   STATUS             RESTARTS   AGE</span><br><span class="line">nginx-deployment-5d457cdfc8-7whnx   1/1     Running            0          7m50s</span><br><span class="line">nginx-deployment-5d457cdfc8-b7njk   1/1     Running            0          8m8s</span><br><span class="line">nginx-deployment-5d457cdfc8-x4zv8   1/1     Running            0          7m39s</span><br><span class="line">nginx-deployment-6b7d6c469c-zcjps   0/1     ImagePullBackOff   0          92s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始回滚</span></span><br><span class="line">1.查看历史版本</span><br><span class="line">root@k8s-master:~# kubectl rollout <span class="built_in">history</span> deployments/nginx-deployment</span><br><span class="line">deployment.apps/nginx-deployment</span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br><span class="line">2         kubectl <span class="built_in">set</span> image deployments/nginx-deployment nginx=nginx:1.17.1 --record=<span class="literal">true</span></span><br><span class="line">3         kubectl <span class="built_in">set</span> image deployments/nginx-deployment nginx=nginx:1.172 --record=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line">2.查看某个版本</span><br><span class="line">root@k8s-master:~# kubectl rollout <span class="built_in">history</span> deployment.v1.apps/nginx-deployment --revision=2</span><br><span class="line">deployment.apps/nginx-deployment with revision <span class="comment">#2</span></span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:       app=nginx</span><br><span class="line">        pod-template-hash=5d457cdfc8</span><br><span class="line">  Annotations:  kubernetes.io/change-cause: kubectl <span class="built_in">set</span> image deployments/nginx-deployment nginx=nginx:1.17.1 --record=<span class="literal">true</span></span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:      nginx:1.17.1</span><br><span class="line">    Port:       80/TCP</span><br><span class="line">    Host Port:  0/TCP</span><br><span class="line">    Environment:        &lt;none&gt;</span><br><span class="line">    Mounts:     &lt;none&gt;</span><br><span class="line">  Volumes:      &lt;none&gt;</span><br><span class="line">  Node-Selectors:       &lt;none&gt;</span><br><span class="line">  Tolerations:  &lt;none&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3.回滚到某个版本</span><br><span class="line">root@k8s-master:~# kubectl rollout undo deployments/nginx-deployment --to-revision=2</span><br><span class="line">deployment.apps/nginx-deployment rolled back</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl rollout status deployment/nginx-deployment</span><br><span class="line">deployment <span class="string">&quot;nginx-deployment&quot;</span> successfully rolled out</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployment.apps</span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3/3     3            3           23m</span><br></pre></td></tr></table></figure>

<h3 id="10-5-5-伸缩Deployment"><a href="#10-5-5-伸缩Deployment" class="headerlink" title="10.5.5 伸缩Deployment"></a>10.5.5 伸缩Deployment</h3><p>&emsp;&emsp;将指定的deployment副本更改为10</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl scale deployments/nginx-deployment --replicas=10</span><br><span class="line">deployment.apps/nginx-deployment scaled</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployments.apps,replicasets.apps -l app=nginx</span><br><span class="line">NAME                               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment   10/10   10           10          25m</span><br><span class="line"></span><br><span class="line">NAME                                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/nginx-deployment-5d457cdfc8   10        10        10      21m</span><br><span class="line">replicaset.apps/nginx-deployment-6b7d6c469c   0         0         0       14m</span><br><span class="line">replicaset.apps/nginx-deployment-8d94c585f    0         0         0       25m</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete deployments.apps nginx-deployment</span><br></pre></td></tr></table></figure>

<h2 id="10-6-DaemonSet"><a href="#10-6-DaemonSet" class="headerlink" title="10.6 DaemonSet"></a>10.6 DaemonSet</h2><p>&emsp;&emsp;DaemonSet确保全部（或某些）节点上运行一个 Pod 的副本。 当有节点加入集群时， 也会为他们新增一个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除DaemonSet将会删除它创建的所有Pod</p>
<p>&emsp;&emsp;DaemonSet 的一些典型用法：</p>
<p>&emsp;&emsp;1.在每个节点上运行集群守护进程</p>
<p>&emsp;&emsp;2.在每个节点上运行日志收集守护进程</p>
<p>&emsp;&emsp;3.在每个节点上运行监控守护进程</p>
<p><img src="/images/DaemonSet.png" title="DaemonSet"></p>
<p>使用busybox镜像，在每一个节点上都运行一个pod：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; daemonset.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: DaemonSet</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: luovip</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    daemonset: test</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      name: testpod</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        name: testpod</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: hello</span></span><br><span class="line"><span class="string">        image: busybox</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;sleep 3600&#x27;]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f daemonset.yml</span><br><span class="line">daemonset.apps/luovip created</span><br><span class="line">root@k8s-master:~# kubectl get daemonsets.apps</span><br><span class="line">NAME     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">luovip   2         2         2       2            2           &lt;none&gt;          19s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -o wide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">luovip-bxkmh      1/1     Running   0          95s   172.16.126.33    k8s-worker2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">luovip-fj5mz      1/1     Running   0          95s   172.16.194.105   k8s-worker1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f daemonset.yml</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;DaemonSet总结：</p>
<p>&emsp;&emsp;1.默认情况下， DaemonSet会在所有Node上创建一个Pod</p>
<p>&emsp;&emsp;2.如果将运行的pod删除，DaemonSet会自动启动一个新的</p>
<p>&emsp;&emsp;3.当有新节点加入集群时，会自动向其部署Pod</p>
<p>&emsp;&emsp;4.当节点离开集群时，其上的节点会销毁，而不会跑到其他节点上</p>
<h2 id="10-7-StatefulSet"><a href="#10-7-StatefulSet" class="headerlink" title="10.7  StatefulSet"></a>10.7  StatefulSet</h2><p>&emsp;&emsp;StatefulSet管理基于相同容器规约的一组 Pod。但和Deployment不同的是， StatefulSet为它们的每个Pod维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID<br>&emsp;&emsp;StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值：</p>
<p>&emsp;&emsp;1.稳定的、唯一的网络标识符</p>
<p>&emsp;&emsp;2.稳定的、持久的存储</p>
<p>&emsp;&emsp;3.有序的、优雅的部署和缩放</p>
<p>&emsp;&emsp;4.有序的、自动的滚动更新</p>
<p><img src="/images/StatefulSet.png" title="StatefulSet"></p>
<h3 id="10-7-1-创建yml文件"><a href="#10-7-1-创建yml文件" class="headerlink" title="10.7.1 创建yml文件"></a>10.7.1 创建yml文件</h3><p>&emsp;&emsp;使用nginx镜像，创建一个副本数为3的有状态应用，并挂载本地目录到容器中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; statefulset.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: StatefulSet</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: web</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      app: nginx</span></span><br><span class="line"><span class="string">  serviceName: &quot;nginx&quot;</span></span><br><span class="line"><span class="string">  replicas: 3</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        app: nginx</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: nginx</span></span><br><span class="line"><span class="string">        image: nginx:1.17.2</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">          name: web</span></span><br><span class="line"><span class="string">        volumeMounts:</span></span><br><span class="line"><span class="string">        - name: www</span></span><br><span class="line"><span class="string">          mountPath: /usr/share/nginx/html</span></span><br><span class="line"><span class="string">      volumes:</span></span><br><span class="line"><span class="string">         - name: www</span></span><br><span class="line"><span class="string">           emptyDir: &#123;&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="10-7-2-操作StatefulSet"><a href="#10-7-2-操作StatefulSet" class="headerlink" title="10.7.2 操作StatefulSet"></a>10.7.2 操作StatefulSet</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发现创建的过程是有次序的，这也验证了有状态应用的启动顺序</span></span><br><span class="line">root@k8s-master:~# kubectl create -f statefulset.yml</span><br><span class="line">statefulset.apps/web created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pods -w</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">web-0                               0/1     Pending   0          0s</span><br><span class="line">web-0                               0/1     Pending   0          0s</span><br><span class="line">web-0                               0/1     ContainerCreating   0          1s</span><br><span class="line">web-0                               0/1     ContainerCreating   0          1s</span><br><span class="line">web-0                               0/1     ErrImagePull        0          82s</span><br><span class="line">web-0                               0/1     ImagePullBackOff    0          96s</span><br><span class="line">web-0                               1/1     Running             0          108s</span><br><span class="line">web-1                               0/1     Pending             0          0s</span><br><span class="line">web-1                               0/1     Pending             0          0s</span><br><span class="line">web-1                               0/1     ContainerCreating   0          0s</span><br><span class="line">web-1                               0/1     ContainerCreating   0          0s</span><br><span class="line">web-1                               1/1     Running             0          11s</span><br><span class="line">web-2                               0/1     Pending             0          0s</span><br><span class="line">web-2                               0/1     Pending             0          0s</span><br><span class="line">web-2                               0/1     ContainerCreating   0          0s</span><br><span class="line">web-2                               0/1     ContainerCreating   0          0s</span><br><span class="line">web-2                               1/1     Running             0          1s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pods</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">web-0                               1/1     Running   0          3m36s</span><br><span class="line">web-1                               1/1     Running   0          108s</span><br><span class="line">web-2                               1/1     Running   0          97s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f statefulset.yml</span><br><span class="line">statefulset.apps <span class="string">&quot;web&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="10-8-Job"><a href="#10-8-Job" class="headerlink" title="10.8 Job"></a>10.8 Job</h2><p>&emsp;&emsp;不断打印CKA JOB字符串，失败最多重试4次</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; job.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: batch/v1</span></span><br><span class="line"><span class="string">kind: Job</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: pi</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: pi</span></span><br><span class="line"><span class="string">        image: busybox</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        command: [&quot;sh&quot;,  &quot;-c&quot;, &quot;while true;do echo CKA JOB;done&quot;]</span></span><br><span class="line"><span class="string">      restartPolicy: Never</span></span><br><span class="line"><span class="string">  backoffLimit: 4</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f job.yml</span><br><span class="line">job.batch/pi created</span><br><span class="line">root@k8s-master:~# kubectl get <span class="built_in">jobs</span>,pods</span><br><span class="line">NAME           STATUS    COMPLETIONS   DURATION   AGE</span><br><span class="line">job.batch/pi   Running   0/1           10s        10s</span><br><span class="line"></span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/pi-rglzp   1/1     Running   0          10s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl logs pi-rglzp</span><br><span class="line">CKA JOB</span><br><span class="line">CKA JOB</span><br><span class="line">CKA JOB</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f job.yml</span><br><span class="line">job.batch <span class="string">&quot;pi&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="10-9-CronJob"><a href="#10-9-CronJob" class="headerlink" title="10.9 CronJob"></a>10.9 CronJob</h2><p>&emsp;&emsp;每分钟打印一次指定字符串</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; cronjob.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: batch/v1</span></span><br><span class="line"><span class="string">kind: CronJob</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: cronjobtest</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  schedule: &quot;*/1 * * * *&quot;</span></span><br><span class="line"><span class="string">  jobTemplate:</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      template:</span></span><br><span class="line"><span class="string">        spec:</span></span><br><span class="line"><span class="string">          containers:</span></span><br><span class="line"><span class="string">          - name: hello</span></span><br><span class="line"><span class="string">            image: busybox</span></span><br><span class="line"><span class="string">            imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">            command:</span></span><br><span class="line"><span class="string">            - /bin/sh</span></span><br><span class="line"><span class="string">            - -c</span></span><br><span class="line"><span class="string">            - date; echo Hello from the Kubernetes cluster</span></span><br><span class="line"><span class="string">          restartPolicy: OnFailure</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f cronjob.yml</span><br><span class="line">cronjob.batch/cronjobtest created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get cronjobs,pod</span><br><span class="line">NAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">cronjob.batch/cronjobtest   */1 * * * *   &lt;none&gt;     False     0        34s             35s</span><br><span class="line"></span><br><span class="line">NAME                             READY   STATUS      RESTARTS   AGE</span><br><span class="line">pod/cronjobtest-29127403-mb9qx   0/1     Completed   0          34s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl logs cronjobtest-29127403-mb9qx</span><br><span class="line">Mon May 19 08:43:01 UTC 2025</span><br><span class="line">Hello from the Kubernetes cluster</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get cronjobs,pod</span><br><span class="line">NAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE</span><br><span class="line">cronjob.batch/cronjobtest   */1 * * * *   &lt;none&gt;     False     0        9s              2m10s</span><br><span class="line"></span><br><span class="line">NAME                             READY   STATUS      RESTARTS   AGE</span><br><span class="line">pod/cronjobtest-29127403-mb9qx   0/1     Completed   0          2m9s</span><br><span class="line">pod/cronjobtest-29127404-9jmbj   0/1     Completed   0          69s</span><br><span class="line">pod/cronjobtest-29127405-h5cc7   0/1     Completed   0          9s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关于展示的任务次数的显示等的修改</span></span><br><span class="line">root@k8s-master:~# kubectl explain cronjob.spec</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f cronjob.yml</span><br><span class="line">cronjob.batch <span class="string">&quot;cronjobtest&quot;</span> deleted</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="11-Service-服务发现"><a href="#11-Service-服务发现" class="headerlink" title="11 Service 服务发现"></a>11 Service 服务发现</h1><h2 id="11-1-Service"><a href="#11-1-Service" class="headerlink" title="11.1 Service"></a>11.1 Service</h2><p>&emsp;&emsp;Pod是非永久性资源，每个Pod都有自己的IP地址</p>
<p>&emsp;&emsp;如果一组Pod（称为“后端”）为集群内的其他Pod（称为“前端”）提供功能， 那么前端如何找出并跟踪要连接的IP地址，以便前端可以使用提供工作负载的后端部分？</p>
<p><img src="/images/Service.png" title="Service"></p>
<h2 id="11-2-Service类型"><a href="#11-2-Service类型" class="headerlink" title="11.2 Service类型"></a>11.2 Service类型</h2><p>&emsp;&emsp;ClusterIP：通过集群的内部IP暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的ServiceType<br>&emsp;&emsp;NodePort：通过每个节点上的IP和静态端口（NodePort）暴露服务。 NodePort服务会路由到自动创建的ClusterIP服务。 通过请求 &lt;节点 IP&gt;:&lt;节点端口&gt;，可以从集群的外部访问一个NodePort服务<br>&emsp;&emsp;LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的NodePort服务和ClusterIP 服务上<br>&emsp;&emsp;ExternalName：通过返回CNAME和对应值，可以将服务映射到externalName字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理</p>
<p><img src="/images/Service%E8%AE%BF%E9%97%AE.png" title="Service访问"></p>
<h2 id="11-3-iptables代理模式的Service"><a href="#11-3-iptables代理模式的Service" class="headerlink" title="11.3 iptables代理模式的Service"></a>11.3 iptables代理模式的Service</h2><p>&emsp;&emsp;kube-proxy会监视Kubernetes 控制节点对Service对象和Endpoints对象的添加和移除。 对每个Service，它会配置iptables规则，从而捕获到达该Service的clusterIP和端口的请求，进而将请求重定向到 Service 的一组后端中的某个Pod上面。 对于每个Endpoints对象，它也会配置iptables规则，这个规则会选择一个后端组合<br>&emsp;&emsp;默认的策略是，kube-proxy在iptables模式下随机选择一个后端<br>&emsp;&emsp;使用iptables处理流量具有较低的系统开销，因为流量由Linux netfilter处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠</p>
<h2 id="11-4-IPVS代理模式的Service"><a href="#11-4-IPVS代理模式的Service" class="headerlink" title="11.4 IPVS代理模式的Service"></a>11.4 IPVS代理模式的Service</h2><p>&emsp;&emsp;在ipvs模式下，kube-proxy监视Kubernetes服务和端点，调用netlink接口相应地创建IPVS规则， 并定期将IPVS规则与Kubernetes服务和端点同步。 该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS将流量定向到后端Pod之一<br>&emsp;&emsp;IPVS代理模式基于类似于iptables模式的netfilter挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables模式下的kube-proxy相比，IPVS模式下的kube-proxy重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS模式还支持更高的网络流量吞吐量</p>
<h2 id="11-5-生成Service"><a href="#11-5-生成Service" class="headerlink" title="11.5 生成Service"></a>11.5 生成Service</h2><h3 id="11-5-1-准备后端Pod"><a href="#11-5-1-准备后端Pod" class="headerlink" title="11.5.1 准备后端Pod"></a>11.5.1 准备后端Pod</h3><p>&emsp;&emsp;用nginx镜像准备一个3副本的deployment作为后端，并开放80端口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; deployment-service.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nginx-deployment-servicetest</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 3</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      app: nginx</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        app: nginx</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: nginx</span></span><br><span class="line"><span class="string">        image: nginx:1.16.1</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f deployment-service.yml</span><br><span class="line">deployment.apps/nginx-deployment-servicetest created</span><br><span class="line">root@k8s-master:~# kubectl get pods -o wide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP        NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-deployment-servicetest-8d94c585f-6ktj9 1/1  Running 0 13s 172.16.126.35 k8s-worker2 &lt;none&gt;   &lt;none&gt;</span><br><span class="line">nginx-deployment-servicetest-8d94c585f-jclrr 1/1  Running 0 13s 172.16.194.117 k8s-worker1 &lt;none&gt;     &lt;none&gt;</span><br><span class="line">nginx-deployment-servicetest-8d94c585f-wgztv 1/1  Running 0 13s 172.16.194.116 k8s-worker1   &lt;none&gt;  &lt;none&gt;</span><br><span class="line">root@k8s-master:~# curl 172.16.126.35</span><br></pre></td></tr></table></figure>

<h3 id="11-5-2-命令行生成Service"><a href="#11-5-2-命令行生成Service" class="headerlink" title="11.5.2 命令行生成Service"></a>11.5.2 命令行生成Service</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用kubectl expose的命令创建一个针对deployment的服务，并查询endpoint是否准备就绪</span></span><br><span class="line">root@k8s-master:~# kubectl expose deployment nginx-deployment-servicetest --port=9000 --name=luoyuservice --target-port=80 --<span class="built_in">type</span>=NodePort</span><br><span class="line">service/luoyuservice exposed</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get service,endpoints</span><br><span class="line">NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/kubernetes     ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP          2d13h</span><br><span class="line">service/luoyuservice   NodePort    10.105.8.223   &lt;none&gt;        9000:32646/TCP   26s</span><br><span class="line"></span><br><span class="line">NAME                     ENDPOINTS                                              AGE</span><br><span class="line">endpoints/kubernetes     192.168.8.3:6443                                       2d13h</span><br><span class="line">endpoints/luoyuservice   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   26s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# curl http://192.168.8.3:32646</span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete service luoyuservice</span><br><span class="line">service <span class="string">&quot;luoyuservice&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="11-6-ClusterIP类型的Service"><a href="#11-6-ClusterIP类型的Service" class="headerlink" title="11.6 ClusterIP类型的Service"></a>11.6 ClusterIP类型的Service</h2><p>&emsp;&emsp;ClusterIP是默认的Service类型，对外提供8000端口，并把流量引流到具有app: nginx的后端80端口上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; clusterip.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: my-service</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">  ports:</span></span><br><span class="line"><span class="string">    - protocol: TCP</span></span><br><span class="line"><span class="string">      port: 8000</span></span><br><span class="line"><span class="string">      targetPort: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f clusterip.yml</span><br><span class="line">service/my-service created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get service,endpoints</span><br><span class="line">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service/kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    3d2h</span><br><span class="line">service/my-service   ClusterIP   10.101.56.206   &lt;none&gt;        8000/TCP   2m35s</span><br><span class="line"></span><br><span class="line">NAME                   ENDPOINTS                                              AGE</span><br><span class="line">endpoints/kubernetes   192.168.8.3:6443                                       3d2h</span><br><span class="line">endpoints/my-service   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   2m35s</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# curl 10.101.56.206:8000</span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f clusterip.yml</span><br><span class="line">service <span class="string">&quot;my-service&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="11-7-NodePort类型的Service"><a href="#11-7-NodePort类型的Service" class="headerlink" title="11.7 NodePort类型的Service"></a>11.7 NodePort类型的Service</h2><p>&emsp;&emsp;Type: NodePort将会在节点的特定端口上开通服务，指定了端口为31788</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; nodeport.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nodeservice</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  type: NodePort</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">  ports:</span></span><br><span class="line"><span class="string">    - protocol: TCP</span></span><br><span class="line"><span class="string">      port: 8000</span></span><br><span class="line"><span class="string">      targetPort: 80</span></span><br><span class="line"><span class="string">      nodePort: 31788</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f nodeport.yml</span><br><span class="line">service/nodeservice created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get service,endpoints</span><br><span class="line">NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/kubernetes    ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP          3d3h</span><br><span class="line">service/nodeservice   NodePort    10.102.124.139   &lt;none&gt;        8000:31788/TCP   27s</span><br><span class="line"></span><br><span class="line">NAME                    ENDPOINTS                                              AGE</span><br><span class="line">endpoints/kubernetes    192.168.8.3:6443                                       3d3h</span><br><span class="line">endpoints/nodeservice   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   27s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为是nodeport，所以用节点IP</span></span><br><span class="line">root@k8s-master:~# curl 192.168.8.4:31788</span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f nodeport.yml</span><br><span class="line">service <span class="string">&quot;nodeservice&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="11-8-Headless类型的Service"><a href="#11-8-Headless类型的Service" class="headerlink" title="11.8 Headless类型的Service"></a>11.8 Headless类型的Service</h2><h3 id="11-8-1-服务实现"><a href="#11-8-1-服务实现" class="headerlink" title="11.8.1 服务实现"></a>11.8.1 服务实现</h3><p>&emsp;&emsp;在此类型的Service中，将不会只返回Service IP，会直接返回众多Pod 的IP地址，所以需要进入pod中用集群内DNS进行测试</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; headless.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: headless</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  clusterIP: None</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">  ports:</span></span><br><span class="line"><span class="string">    - protocol: TCP</span></span><br><span class="line"><span class="string">      port: 8000</span></span><br><span class="line"><span class="string">      targetPort: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f headless.yml</span><br><span class="line">service/headless created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get service,endpoints</span><br><span class="line">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service/headless     ClusterIP   None         &lt;none&gt;        8000/TCP   25s</span><br><span class="line">service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP    3d3h</span><br><span class="line"></span><br><span class="line">NAME                   ENDPOINTS                                              AGE</span><br><span class="line">endpoints/headless     172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   25s</span><br><span class="line">endpoints/kubernetes   192.168.8.3:6443                                       3d3h</span><br></pre></td></tr></table></figure>

<h3 id="11-8-2-测试Headless服务发现"><a href="#11-8-2-测试Headless服务发现" class="headerlink" title="11.8.2 测试Headless服务发现"></a>11.8.2 测试Headless服务发现</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl run --<span class="built_in">rm</span> --image=busybox:1.28 -it testpod</span><br><span class="line">If you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span></span><br><span class="line"><span class="string">/ # nslookup headless</span></span><br><span class="line"><span class="string">Server:    10.96.0.10</span></span><br><span class="line"><span class="string">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Name:      headless</span></span><br><span class="line"><span class="string">Address 1: 172.16.194.117 172-16-194-117.headless.default.svc.cluster.local</span></span><br><span class="line"><span class="string">Address 2: 172.16.194.116 172-16-194-116.headless.default.svc.cluster.local</span></span><br><span class="line"><span class="string">Address 3: 172.16.126.35 172-16-126-35.headless.default.svc.cluster.local</span></span><br><span class="line"><span class="string">/ # exit</span></span><br><span class="line"><span class="string">Session ended, resume using &#x27;</span>kubectl attach testpod -c testpod -i -t<span class="string">&#x27; command when the pod is running</span></span><br><span class="line"><span class="string">pod &quot;testpod&quot; deleted</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">root@k8s-master:~# kubectl delete -f headless.yml</span></span><br><span class="line"><span class="string">service &quot;headless&quot; deleted</span></span><br></pre></td></tr></table></figure>

<p>服务的DNS记录名称为：</p>
<p>&emsp;&emsp;servicename.namespace.svc.cluster.local </p>
<p>deployment中Pod的DNS记录名称为：</p>
<p>&emsp;&emsp;podIP.servicename.namespace.svc.cluster.local</p>
<p>Client访问服务时，可以使用DNS记录便捷抵达服务，甚至与服务在同一namespace时，直接用 servicename进行访问</p>
<h2 id="11-9-LoadBalancer类型的Service"><a href="#11-9-LoadBalancer类型的Service" class="headerlink" title="11.9 LoadBalancer类型的Service"></a>11.9 LoadBalancer类型的Service</h2><h3 id="11-9-1-部署metallb负载均衡"><a href="#11-9-1-部署metallb负载均衡" class="headerlink" title="11.9.1 部署metallb负载均衡"></a>11.9.1 部署metallb负载均衡</h3><p>1.先部署一个metallb controller和Speaker：</p>
<p>&emsp;&emsp;1.metallb controller用于负责监听Kubernetes Service的变化，当服务类型被设置为LoadBalancer时，Controller会从一个预先配置的IP地址池中分配一个 IP地址给该服务，并管理这个IP地址的生命周期</p>
<p>&emsp;&emsp;2.Speaker负责将服务的 IP 地址通过标准的路由协议广播到网络中，确保外部流量能够正确路由到集群中的服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@k8s-master:~# kubectl apply -f https://www.linuxcenter.cn/files/cka/cka-yaml/metallb-native.yaml</span><br></pre></td></tr></table></figure>

<p>2.定义一组由负载均衡对外分配的IP地址范围</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ippool.yml &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: metallb.io/v1beta1</span></span><br><span class="line"><span class="string">kind: IPAddressPool</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: lxh-ip-pool-192-168-8-10-100</span></span><br><span class="line"><span class="string">  namespace: metallb-system</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  addresses:</span></span><br><span class="line"><span class="string">  - 192.168.8.10-192.168.8.100</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl apply -f ippool.yml</span><br><span class="line">ipaddresspool.metallb.io/lxh-ip-pool-192-168-8-10-100 created</span><br></pre></td></tr></table></figure>

<p>3.在 Layer 2 模式下用于控制如何通过 ARP（Address Resolution Protocol）或 NDP（Neighbor Discovery Protocol）协议宣告服务的 IP 地址，使得这些 IP 地址在本地网络中可解析</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; l2Advertisement.yml &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: metallb.io/v1beta1</span></span><br><span class="line"><span class="string">kind: L2Advertisement</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: l2-myippool</span></span><br><span class="line"><span class="string">  namespace: metallb-system</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  ipAddressPools:</span></span><br><span class="line"><span class="string">  - lxh-ip-pool-192-168-8-10-100</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl apply -f l2Advertisement.yml</span><br><span class="line">l2advertisement.metallb.io/l2-myippool created</span><br></pre></td></tr></table></figure>

<h3 id="11-9-2-部署LoadBalancer服务"><a href="#11-9-2-部署LoadBalancer服务" class="headerlink" title="11.9.2 部署LoadBalancer服务"></a>11.9.2 部署LoadBalancer服务</h3><p>&emsp;&emsp;负载均衡准备好之后，创建LoadBalancer类型的服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; loadbalancer.yml &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: loadbalance-service</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">  ports:</span></span><br><span class="line"><span class="string">    - protocol: TCP</span></span><br><span class="line"><span class="string">      port: 80</span></span><br><span class="line"><span class="string">      targetPort: 80</span></span><br><span class="line"><span class="string">  type: LoadBalancer</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl apply -f loadbalancer.yml</span><br><span class="line">service/loadbalance-service created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取服务看看是否分配到了负载均衡IP  从输出上看，分配到了192.168.8.10</span></span><br><span class="line">root@k8s-master:~# kubectl get service</span><br><span class="line">NAME                  TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)        AGE</span><br><span class="line">kubernetes            ClusterIP      10.96.0.1      &lt;none&gt;         443/TCP        3d4h</span><br><span class="line">loadbalance-service   LoadBalancer   10.99.147.16   192.168.8.10   80:30972/TCP   10s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用负载均衡IP访问</span></span><br><span class="line">root@k8s-master:~# curl 192.168.8.10</span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除service资源</span></span><br><span class="line">root@k8s-master:~# kubectl delete -f loadbalancer.yml</span><br><span class="line">service <span class="string">&quot;loadbalance-service&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="11-10-Ingress"><a href="#11-10-Ingress" class="headerlink" title="11.10 Ingress"></a>11.10 Ingress</h2><p>&emsp;&emsp;Ingress公开了从集群外部到集群内服务的HTTP和HTTPS路由</p>
<p>&emsp;&emsp;流量路由由Ingress资源上定义的规则控制</p>
<p>&emsp;&emsp;Ingress可以提供负载均衡、SSL卸载和基于名称的虚拟托管，为了让Ingress资源工作，集群必须有一个正在运行的Ingress控制器</p>
<p><img src="/images/Ingress.png" title="Ingress"></p>
<h3 id="11-10-1-Ingress控制器部署"><a href="#11-10-1-Ingress控制器部署" class="headerlink" title="11.10.1 Ingress控制器部署"></a>11.10.1 Ingress控制器部署</h3><p>&emsp;&emsp;Ingress需要Ingress控制器支持，先部署控制器</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取v1.1.0版本的yaml文件</span></span><br><span class="line"><span class="comment"># 使用如下路径下载-可能会失败</span></span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/baremetal/deploy.yaml</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/cka-yaml/ingressdeploy.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从阿里云的镜像仓库上面拉取镜像</span></span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Kubernetes Ingress 的使用场景中，尤其是使用Ingress-Nginx作为 Ingress Controller 时，kube-webhook-certgen工具被用来创建和更新用于TLS认证的证书。这些证书被用于确保 Webhook 与 Kubernetes API 服务器之间的通信是安全的</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改ingressdeploy.yaml文件</span></span><br><span class="line">440行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1</span><br><span class="line">542行改为image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2</span><br><span class="line">596行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2</span><br><span class="line">root@k8s-master:~# kubectl apply -f ingressdeploy.yaml</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get pod -n ingress-nginx</span><br><span class="line">NAME                                   READY   STATUS      RESTARTS   AGE</span><br><span class="line">ingress-nginx-admission-create-k9smq   0/1     Completed   0          17m</span><br><span class="line">ingress-nginx-admission-patch-46hk7    0/1     Completed   2          17m</span><br><span class="line">ingress-nginx-controller-47nzv         1/1     Running     0          17m</span><br><span class="line">ingress-nginx-controller-svcpx         1/1     Running     0          17m</span><br><span class="line"></span><br><span class="line"><span class="comment"># admission相关pod状态为Completed为正常</span></span><br></pre></td></tr></table></figure>

<h3 id="11-10-2-Ingress路径类型"><a href="#11-10-2-Ingress路径类型" class="headerlink" title="11.10.2 Ingress路径类型"></a>11.10.2 Ingress路径类型</h3><p>&emsp;&emsp;Ingress中的每个路径都需要有对应的路径类型，未明确设置pathType的路径无法通过合法性检查。当前支持的路径类型有三种：</p>
<p>&emsp;&emsp;1.ImplementationSpecific：对于这种路径类型，匹配方法取决于IngressClass。 具体实现可以将其作为单独的pathType处理或者与Prefix或 Exact类型作相同处理</p>
<p>&emsp;&emsp;2.Exact：精确匹配URL路径，且区分大小写</p>
<p>&emsp;&emsp;3.Prefix：基于以 &#x2F; 分隔的URL路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成。 路径元素指的是由&#x2F;分隔符分隔的路径中的标签列表。 如果每个p都是请求路径p的元素前缀，则请求与路径p匹配</p>
<h3 id="11-10-3-Ingress的使用"><a href="#11-10-3-Ingress的使用" class="headerlink" title="11.10.3 Ingress的使用"></a>11.10.3 Ingress的使用</h3><p>&emsp;&emsp;用nginx镜像生成一个3副本的Pod，并通过Service提供服务，然后再用ingress，以特定域名的方式对外暴露</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ingress.yml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nginx-deployment-ingress</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 3</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      app: nginx</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        app: nginx</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: nginx</span></span><br><span class="line"><span class="string">        image: nginx:1.16.1</span></span><br><span class="line"><span class="string">        imagePullPolicy: IfNotPresent</span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: ingressservice</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    app: nginx</span></span><br><span class="line"><span class="string">  ports:</span></span><br><span class="line"><span class="string">    - protocol: TCP</span></span><br><span class="line"><span class="string">      port: 80</span></span><br><span class="line"><span class="string">      targetPort: 80</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: networking.k8s.io/v1</span></span><br><span class="line"><span class="string">kind: Ingress</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: luovip</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  ingressClassName: nginx</span></span><br><span class="line"><span class="string">  rules:</span></span><br><span class="line"><span class="string">    - host: www.luovip.com</span></span><br><span class="line"><span class="string">      http:</span></span><br><span class="line"><span class="string">        paths:</span></span><br><span class="line"><span class="string">          - pathType: Prefix</span></span><br><span class="line"><span class="string">            path: &quot;/&quot;</span></span><br><span class="line"><span class="string">            backend:</span></span><br><span class="line"><span class="string">              service:</span></span><br><span class="line"><span class="string">                name: ingressservice</span></span><br><span class="line"><span class="string">                port:</span></span><br><span class="line"><span class="string">                  number: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl create -f ingress.yml</span><br><span class="line">deployment.apps/nginx-deployment-ingress created</span><br><span class="line">service/ingressservice created</span><br><span class="line">ingress.networking.k8s.io/luovip created</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl get deployments,service,ingress</span><br><span class="line">NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/nginx-deployment-ingress       3/3     3            3           38s</span><br><span class="line">deployment.apps/nginx-deployment-servicetest   3/3     3            3           24h</span><br><span class="line"></span><br><span class="line">NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/ingressservice   ClusterIP   10.98.162.124   &lt;none&gt;        80/TCP    38s</span><br><span class="line">service/kubernetes       ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   3d13h</span><br><span class="line"></span><br><span class="line">NAME                               CLASS   HOSTS            ADDRESS                   PORTS   AGE</span><br><span class="line">ingress.networking.k8s.io/luovip   nginx   www.luovip.com   192.168.8.4,192.168.8.5   80      38s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把上述ADDRESS部分的IP和域名绑定解析</span></span><br><span class="line">root@k8s-master:~# <span class="built_in">echo</span> 192.168.8.4 www.luovip.com &gt;&gt; /etc/hosts</span><br><span class="line">root@k8s-master:~# curl http://www.luovip.com</span><br><span class="line"></span><br><span class="line">root@k8s-master:~# kubectl delete -f ingress.yml</span><br></pre></td></tr></table></figure>

<h2 id="11-11-Gateway-API"><a href="#11-11-Gateway-API" class="headerlink" title="11.11 Gateway API"></a>11.11 Gateway API</h2><h3 id="11-11-1-Gateway-API-基本介绍"><a href="#11-11-1-Gateway-API-基本介绍" class="headerlink" title="11.11.1 Gateway API 基本介绍"></a>11.11.1 Gateway API 基本介绍</h3></div><div class="article-licensing box"><div class="licensing-title"><p>容器&amp;K8S</p><p><a href="http://example.com/2025/05/12/Kubernetes/容器&amp;K8S/">http://example.com/2025/05/12/Kubernetes/容器&amp;K8S/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="http://example.com"><p>罗宇</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-05-12 15:21:42</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-05-20 22:20:41</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2025/05/10/Kubernetes/Kubernetes%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/" target="_blank">Kubernetes网络系统原理</a><br></span><span>  2.<a class="is-size-6" href="/2025/05/10/Kubernetes/Kubernetes%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%BF%90%E7%BB%B4/" target="_blank">Kubernetes企业级运维</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2025/05/11/Linux/Linux%E5%91%BD%E4%BB%A4/"><span class="level-item">Linux命令</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-微服务"><span>1 微服务</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-1-应用架构的发展"><span>1.1 应用架构的发展</span></a></li><li><a class="is-flex is-mobile" href="#1-2-传统单体架构vs微服务软件架构"><span>1.2 传统单体架构vs微服务软件架构</span></a></li><li><a class="is-flex is-mobile" href="#1-3-基于微服务的系统架构"><span>1.3 基于微服务的系统架构</span></a></li><li><a class="is-flex is-mobile" href="#1-4-微服务的特征"><span>1.4 微服务的特征</span></a></li><li><a class="is-flex is-mobile" href="#1-5-单体架构"><span>1.5 单体架构</span></a></li><li><a class="is-flex is-mobile" href="#1-6-解耦架构"><span>1.6 解耦架构</span></a></li><li><a class="is-flex is-mobile" href="#1-7-消息队列"><span>1.7 消息队列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-7-1-传统架构"><span>1.7.1 传统架构</span></a></li><li><a class="is-flex is-mobile" href="#1-7-2-消息队列架构"><span>1.7.2 消息队列架构</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#1-8-微服务面临的挑战"><span>1.8 微服务面临的挑战</span></a></li><li><a class="is-flex is-mobile" href="#1-9-虚拟机与容器的比较"><span>1.9 虚拟机与容器的比较</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#2-容器的基本使用"><span>2 容器的基本使用</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#2-1-容器介绍"><span>2.1 容器介绍</span></a></li><li><a class="is-flex is-mobile" href="#2-2-部署Docker"><span>2.2 部署Docker</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#2-2-1-安装依赖"><span>2.2.1 安装依赖</span></a></li><li><a class="is-flex is-mobile" href="#2-2-2-安装GPG公钥"><span>2.2.2 安装GPG公钥</span></a></li><li><a class="is-flex is-mobile" href="#2-2-3-添加Docker仓库"><span>2.2.3 添加Docker仓库</span></a></li><li><a class="is-flex is-mobile" href="#2-2-4-安装Docker"><span>2.2.4 安装Docker</span></a></li><li><a class="is-flex is-mobile" href="#2-2-5-Docker镜像加速器"><span>2.2.5 Docker镜像加速器</span></a></li><li><a class="is-flex is-mobile" href="#2-2-6-重启Docker服务"><span>2.2.6 重启Docker服务</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#2-3-操作容器"><span>2.3 操作容器</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#2-3-1-创建持续运行的容器"><span>2.3.1 创建持续运行的容器</span></a></li><li><a class="is-flex is-mobile" href="#2-3-2-进入容器"><span>2.3.2 进入容器</span></a></li><li><a class="is-flex is-mobile" href="#2-3-3-删除容器"><span>2.3.3 删除容器</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#2-4-构建-使用镜像"><span>2.4 构建&amp;使用镜像</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#2-4-1-镜像概述"><span>2.4.1 镜像概述</span></a></li><li><a class="is-flex is-mobile" href="#2-4-2-公共镜像仓库"><span>2.4.2 公共镜像仓库</span></a></li><li><a class="is-flex is-mobile" href="#2-4-3-镜像分层技术"><span>2.4.3 镜像分层技术</span></a></li><li><a class="is-flex is-mobile" href="#2-4-4-构建镜像的方法"><span>2.4.4 构建镜像的方法</span></a></li><li><a class="is-flex is-mobile" href="#2-4-5-Dockerfile-image"><span>2.4.5 Dockerfile image</span></a></li><li><a class="is-flex is-mobile" href="#2-4-6-使用Dockerfile镜像"><span>2.4.6 使用Dockerfile镜像</span></a></li><li><a class="is-flex is-mobile" href="#2-4-7-关于镜像命名"><span>2.4.7 关于镜像命名</span></a></li><li><a class="is-flex is-mobile" href="#2-4-8-删除镜像"><span>2.4.8 删除镜像</span></a></li><li><a class="is-flex is-mobile" href="#2-4-9-私有镜像仓库"><span>2.4.9 私有镜像仓库</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#3-部署Harbor私有仓库"><span>3 部署Harbor私有仓库</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#3-1-RedHat9镜像源配置"><span>3.1 RedHat9镜像源配置</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#3-1-1-国内镜像源"><span>3.1.1 国内镜像源</span></a></li><li><a class="is-flex is-mobile" href="#3-1-2-本地yum源配置"><span>3.1.2 本地yum源配置</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#3-2-主机名和IP地址映射"><span>3.2 主机名和IP地址映射</span></a></li><li><a class="is-flex is-mobile" href="#3-3-部署Docker-CE"><span>3.3 部署Docker CE</span></a></li><li><a class="is-flex is-mobile" href="#3-4-Docker镜像加速器"><span>3.4 Docker镜像加速器</span></a></li><li><a class="is-flex is-mobile" href="#3-5-Compose支持"><span>3.5 Compose支持</span></a></li><li><a class="is-flex is-mobile" href="#3-6-下载Harbor"><span>3.6 下载Harbor</span></a></li><li><a class="is-flex is-mobile" href="#3-7-修改harbor-yml文件"><span>3.7 修改harbor.yml文件</span></a></li><li><a class="is-flex is-mobile" href="#3-8-安装Harbor"><span>3.8 安装Harbor</span></a></li><li><a class="is-flex is-mobile" href="#3-9-重启Harbor"><span>3.9 重启Harbor</span></a></li><li><a class="is-flex is-mobile" href="#3-10-生成服务文件"><span>3.10 生成服务文件</span></a></li><li><a class="is-flex is-mobile" href="#3-11-推送镜像到Harbor"><span>3.11 推送镜像到Harbor</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-管理容器的资源"><span>4 管理容器的资源</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-1-容器的内存配额"><span>4.1 容器的内存配额</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-1-1-用户内存限制"><span>4.1.1 用户内存限制</span></a></li><li><a class="is-flex is-mobile" href="#4-1-2-内核内存限制"><span>4.1.2 内核内存限制</span></a></li><li><a class="is-flex is-mobile" href="#4-1-3-内存预留实现软限制"><span>4.1.3 内存预留实现软限制</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-2-容器的CPU配额"><span>4.2 容器的CPU配额</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-2-1-CPU份额限制"><span>4.2.1 CPU份额限制</span></a></li><li><a class="is-flex is-mobile" href="#4-2-2-CPU周期限制"><span>4.2.2 CPU周期限制</span></a></li><li><a class="is-flex is-mobile" href="#4-2-3-CPU放置限制"><span>4.2.3 CPU放置限制</span></a></li><li><a class="is-flex is-mobile" href="#4-2-4-CPU配额限制"><span>4.2.4 CPU配额限制</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-3-容器的I-O配额"><span>4.3 容器的I/O配额</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-3-1-设置块I-O权重"><span>4.3.1 设置块I/O权重</span></a></li><li><a class="is-flex is-mobile" href="#4-3-2-限制设备读写速率"><span>4.3.2 限制设备读写速率</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4-4-容器底层技术实现"><span>4.4 容器底层技术实现</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#4-4-1-资源限制的底层实现"><span>4.4.1 资源限制的底层实现</span></a></li><li><a class="is-flex is-mobile" href="#4-4-2-容器的隔离底层实现"><span>4.4.2 容器的隔离底层实现</span></a></li><li><a class="is-flex is-mobile" href="#4-4-3-namespace"><span>4.4.3 namespace</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#5-容器原生网络与存储"><span>5 容器原生网络与存储</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#5-1-容器原生网络"><span>5.1 容器原生网络</span></a></li><li><a class="is-flex is-mobile" href="#5-2-容器和层"><span>5.2 容器和层</span></a></li><li><a class="is-flex is-mobile" href="#5-3-主流存储驱动"><span>5.3 主流存储驱动</span></a></li><li><a class="is-flex is-mobile" href="#5-4-Copy-on-write策略"><span>5.4 Copy-on-write策略</span></a></li><li><a class="is-flex is-mobile" href="#5-5-容器数据管理"><span>5.5 容器数据管理</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#6-Kubernetes"><span>6 Kubernetes</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#6-1-K8S的概念"><span>6.1 K8S的概念</span></a></li><li><a class="is-flex is-mobile" href="#6-2-K8S的特点"><span>6.2 K8S的特点</span></a></li><li><a class="is-flex is-mobile" href="#6-3-K8S的作用"><span>6.3 K8S的作用</span></a></li><li><a class="is-flex is-mobile" href="#6-4-K8S的整体架构"><span>6.4 K8S的整体架构</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#6-4-1-Master节点"><span>6.4.1 Master节点</span></a></li><li><a class="is-flex is-mobile" href="#6-4-2-Node节点"><span>6.4.2 Node节点</span></a></li><li><a class="is-flex is-mobile" href="#6-4-3-插件-Addons"><span>6.4.3 插件(Addons)</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#7-Kubernetes集群部署"><span>7 Kubernetes集群部署</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-1-Kubernetes的安装流程"><span>7.1 Kubernetes的安装流程</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-1-1-先决条件"><span>7.1.1 先决条件</span></a></li><li><a class="is-flex is-mobile" href="#7-1-2-安装runtime"><span>7.1.2 安装runtime</span></a></li><li><a class="is-flex is-mobile" href="#7-1-3-安装kubeadm、kubelet和kubectl"><span>7.1.3 安装kubeadm、kubelet和kubectl</span></a></li><li><a class="is-flex is-mobile" href="#7-1-4-检查所需端口"><span>7.1.4 检查所需端口</span></a></li><li><a class="is-flex is-mobile" href="#7-1-5-Iptables桥接流量"><span>7.1.5 Iptables桥接流量</span></a></li><li><a class="is-flex is-mobile" href="#7-1-6-环境准备"><span>7.1.6 环境准备</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#7-2-Docker-CE-部署"><span>7.2 Docker CE 部署</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-2-1-添加Docker仓库"><span>7.2.1 添加Docker仓库</span></a></li><li><a class="is-flex is-mobile" href="#7-2-2-安装Docker-CE"><span>7.2.2 安装Docker CE</span></a></li><li><a class="is-flex is-mobile" href="#7-2-3-CRI-Docker部署"><span>7.2.3 CRI-Docker部署</span></a></li><li><a class="is-flex is-mobile" href="#7-2-4-Docker镜像加速器"><span>7.2.4 Docker镜像加速器</span></a></li><li><a class="is-flex is-mobile" href="#7-2-5-将镜像指引到国内"><span>7.2.5 将镜像指引到国内</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#7-3-Kubernetes部署"><span>7.3 Kubernetes部署</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#7-3-1-关闭swap分区"><span>7.3.1 关闭swap分区</span></a></li><li><a class="is-flex is-mobile" href="#7-3-2-允许iptables检查桥接流量"><span>7.3.2 允许iptables检查桥接流量</span></a></li><li><a class="is-flex is-mobile" href="#7-3-3-安装kubeadm"><span>7.3.3 安装kubeadm</span></a></li><li><a class="is-flex is-mobile" href="#7-3-4-添加命令自动补齐"><span>7.3.4 添加命令自动补齐</span></a></li><li><a class="is-flex is-mobile" href="#7-3-5-集成CRI-Docker"><span>7.3.5 集成CRI-Docker</span></a></li><li><a class="is-flex is-mobile" href="#7-3-6-集群部署"><span>7.3.6 集群部署</span></a></li><li><a class="is-flex is-mobile" href="#7-3-7-部署Calico网络插件"><span>7.3.7 部署Calico网络插件</span></a></li><li><a class="is-flex is-mobile" href="#7-3-8-设置calico在集群的网段"><span>7.3.8 设置calico在集群的网段</span></a></li><li><a class="is-flex is-mobile" href="#7-3-9-确认资源的地址"><span>7.3.9 确认资源的地址</span></a></li><li><a class="is-flex is-mobile" href="#7-3-10-自定义资源发布到集群"><span>7.3.10 自定义资源发布到集群</span></a></li><li><a class="is-flex is-mobile" href="#7-3-11-加入Worker节点"><span>7.3.11 加入Worker节点</span></a></li><li><a class="is-flex is-mobile" href="#7-3-12-重置集群"><span>7.3.12 重置集群</span></a></li><li><a class="is-flex is-mobile" href="#7-3-13-标签和注解"><span>7.3.13 标签和注解</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#8-Kubernetes的语法"><span>8 Kubernetes的语法</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#8-1-Yaml语法"><span>8.1 Yaml语法</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#8-1-1-生成YAML文件框架"><span>8.1.1 生成YAML文件框架</span></a></li><li><a class="is-flex is-mobile" href="#8-1-2-apiVersion"><span>8.1.2 apiVersion</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#8-2-Namespace"><span>8.2 Namespace</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#8-2-1-命令行创建"><span>8.2.1 命令行创建</span></a></li><li><a class="is-flex is-mobile" href="#8-2-2-YAML文件创建"><span>8.2.2 YAML文件创建</span></a></li><li><a class="is-flex is-mobile" href="#8-2-3-删除namespace"><span>8.2.3 删除namespace</span></a></li><li><a class="is-flex is-mobile" href="#8-2-4-创建带有namespace属性的资源"><span>8.2.4 创建带有namespace属性的资源</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#8-3-CRD自定义资源"><span>8.3 CRD自定义资源</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#8-3-1-CRD介绍"><span>8.3.1 CRD介绍</span></a></li><li><a class="is-flex is-mobile" href="#8-3-2-查询CRD以及API资源"><span>8.3.2 查询CRD以及API资源</span></a></li><li><a class="is-flex is-mobile" href="#8-3-3-创建CRD以及API资源"><span>8.3.3 创建CRD以及API资源</span></a></li><li><a class="is-flex is-mobile" href="#8-3-4-查询API资源结构与参数"><span>8.3.4 查询API资源结构与参数</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#9-Pod"><span>9 Pod</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#9-1-关于pod"><span>9.1 关于pod</span></a></li><li><a class="is-flex is-mobile" href="#9-2-Pod生命周期"><span>9.2 Pod生命周期</span></a></li><li><a class="is-flex is-mobile" href="#9-3-创建Pod"><span>9.3 创建Pod</span></a></li><li><a class="is-flex is-mobile" href="#9-4-修改Pod"><span>9.4 修改Pod</span></a></li><li><a class="is-flex is-mobile" href="#9-5-进入pod中的容器"><span>9.5 进入pod中的容器</span></a></li><li><a class="is-flex is-mobile" href="#9-6-Init类型容器"><span>9.6 Init类型容器</span></a></li><li><a class="is-flex is-mobile" href="#9-7-Sidecar类型容器"><span>9.7 Sidecar类型容器</span></a></li><li><a class="is-flex is-mobile" href="#9-8-静态Pod"><span>9.8 静态Pod</span></a></li><li><a class="is-flex is-mobile" href="#9-9-Pod删除"><span>9.9 Pod删除</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10-Kubernetes控制器"><span>10 Kubernetes控制器</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#10-1-什么是控制器"><span>10.1 什么是控制器</span></a></li><li><a class="is-flex is-mobile" href="#10-2-Replica-Set概念"><span>10.2 Replica Set概念</span></a></li><li><a class="is-flex is-mobile" href="#10-3-Replica-Set-工作原理"><span>10.3 Replica Set 工作原理</span></a></li><li><a class="is-flex is-mobile" href="#10-4-ReplicaSet使用"><span>10.4 ReplicaSet使用</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#10-4-1-创建yml文件"><span>10.4.1 创建yml文件</span></a></li><li><a class="is-flex is-mobile" href="#10-4-2-操作ReplicaSet"><span>10.4.2 操作ReplicaSet</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10-5-Deployment"><span>10.5 Deployment</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#10-5-1-创建yml文件"><span>10.5.1 创建yml文件</span></a></li><li><a class="is-flex is-mobile" href="#10-5-2-创建Deployment"><span>10.5.2 创建Deployment</span></a></li><li><a class="is-flex is-mobile" href="#10-5-3-更新Deployment"><span>10.5.3 更新Deployment</span></a></li><li><a class="is-flex is-mobile" href="#10-5-4-回滚Deployment"><span>10.5.4 回滚Deployment</span></a></li><li><a class="is-flex is-mobile" href="#10-5-5-伸缩Deployment"><span>10.5.5 伸缩Deployment</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10-6-DaemonSet"><span>10.6 DaemonSet</span></a></li><li><a class="is-flex is-mobile" href="#10-7-StatefulSet"><span>10.7  StatefulSet</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#10-7-1-创建yml文件"><span>10.7.1 创建yml文件</span></a></li><li><a class="is-flex is-mobile" href="#10-7-2-操作StatefulSet"><span>10.7.2 操作StatefulSet</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10-8-Job"><span>10.8 Job</span></a></li><li><a class="is-flex is-mobile" href="#10-9-CronJob"><span>10.9 CronJob</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11-Service-服务发现"><span>11 Service 服务发现</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-1-Service"><span>11.1 Service</span></a></li><li><a class="is-flex is-mobile" href="#11-2-Service类型"><span>11.2 Service类型</span></a></li><li><a class="is-flex is-mobile" href="#11-3-iptables代理模式的Service"><span>11.3 iptables代理模式的Service</span></a></li><li><a class="is-flex is-mobile" href="#11-4-IPVS代理模式的Service"><span>11.4 IPVS代理模式的Service</span></a></li><li><a class="is-flex is-mobile" href="#11-5-生成Service"><span>11.5 生成Service</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-5-1-准备后端Pod"><span>11.5.1 准备后端Pod</span></a></li><li><a class="is-flex is-mobile" href="#11-5-2-命令行生成Service"><span>11.5.2 命令行生成Service</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11-6-ClusterIP类型的Service"><span>11.6 ClusterIP类型的Service</span></a></li><li><a class="is-flex is-mobile" href="#11-7-NodePort类型的Service"><span>11.7 NodePort类型的Service</span></a></li><li><a class="is-flex is-mobile" href="#11-8-Headless类型的Service"><span>11.8 Headless类型的Service</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-8-1-服务实现"><span>11.8.1 服务实现</span></a></li><li><a class="is-flex is-mobile" href="#11-8-2-测试Headless服务发现"><span>11.8.2 测试Headless服务发现</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11-9-LoadBalancer类型的Service"><span>11.9 LoadBalancer类型的Service</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-9-1-部署metallb负载均衡"><span>11.9.1 部署metallb负载均衡</span></a></li><li><a class="is-flex is-mobile" href="#11-9-2-部署LoadBalancer服务"><span>11.9.2 部署LoadBalancer服务</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11-10-Ingress"><span>11.10 Ingress</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-10-1-Ingress控制器部署"><span>11.10.1 Ingress控制器部署</span></a></li><li><a class="is-flex is-mobile" href="#11-10-2-Ingress路径类型"><span>11.10.2 Ingress路径类型</span></a></li><li><a class="is-flex is-mobile" href="#11-10-3-Ingress的使用"><span>11.10.3 Ingress的使用</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11-11-Gateway-API"><span>11.11 Gateway API</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#11-11-1-Gateway-API-基本介绍"><span>11.11.1 Gateway API 基本介绍</span></a></li></ul></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="罗宇"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">罗宇</p><p class="is-size-6 is-block">用开放的思维，解决封闭的问题</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国-四川-成都</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives/"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories/"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags/"><p class="title">11</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://luovip.github.io" target="_blank" rel="noopener">关注我</a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.iloveimg.com/zh-cn/compress-image" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">图片压缩</span></span><span class="level-right"><span class="level-item tag">www.iloveimg.com</span></span></a></li><li><a class="level is-mobile" href="https://mirrors.nju.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">南京大学镜像站</span></span><span class="level-right"><span class="level-item tag">mirrors.nju.edu.cn</span></span></a></li><li><a class="level is-mobile" href="https://developer.aliyun.com/mirror/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">阿里云镜像站</span></span><span class="level-right"><span class="level-item tag">developer.aliyun.com</span></span></a></li><li><a class="level is-mobile" href="https://docs.docker.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">docker官网</span></span><span class="level-right"><span class="level-item tag">docs.docker.com</span></span></a></li><li><a class="level is-mobile" href="https://hub.docker.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">docker官方仓库</span></span><span class="level-right"><span class="level-item tag">hub.docker.com</span></span></a></li><li><a class="level is-mobile" href="https://containerd.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">containerd官网</span></span><span class="level-right"><span class="level-item tag">containerd.io</span></span></a></li><li><a class="level is-mobile" href="https://goharbor.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">harbor官网</span></span><span class="level-right"><span class="level-item tag">goharbor.io</span></span></a></li><li><a class="level is-mobile" href="https://kubernetes.io/zh-cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">kubernetes官网</span></span><span class="level-right"><span class="level-item tag">kubernetes.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/05/12/Kubernetes/%E5%AE%B9%E5%99%A8&amp;K8S/"><img src="/img/docker&amp;k8s.jpg" alt="容器&amp;K8S"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-12T07:21:42.000Z">2025-05-12 15:21:42</time></p><p class="title"><a href="/2025/05/12/Kubernetes/%E5%AE%B9%E5%99%A8&amp;K8S/">容器&amp;K8S</a></p><p class="categories"><a href="/categories/Kubernetes/">Kubernetes</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/11/Linux/Linux%E5%91%BD%E4%BB%A4/"><img src="/img/Linux.jpg" alt="Linux命令"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-11T14:36:42.000Z">2025-05-11 22:36:42</time></p><p class="title"><a href="/2025/05/11/Linux/Linux%E5%91%BD%E4%BB%A4/">Linux命令</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/10/Kubernetes/Kubernetes%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"><img src="/img/K8S.jpg" alt="Kubernetes网络系统原理"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-10T11:29:42.000Z">2025-05-10 19:29:42</time></p><p class="title"><a href="/2025/05/10/Kubernetes/Kubernetes%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/">Kubernetes网络系统原理</a></p><p class="categories"><a href="/categories/Kubernetes/">Kubernetes</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/10/Kubernetes/Kubernetes%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%BF%90%E7%BB%B4/"><img src="/img/K8S.jpg" alt="Kubernetes企业级运维"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-10T11:28:42.000Z">2025-05-10 19:28:42</time></p><p class="title"><a href="/2025/05/10/Kubernetes/Kubernetes%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%BF%90%E7%BB%B4/">Kubernetes企业级运维</a></p><p class="categories"><a href="/categories/Kubernetes/">Kubernetes</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/10/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/Shell%E8%84%9A%E6%9C%AC/"><img src="/img/shell.jpg" alt="Shell脚本"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-10T09:55:42.000Z">2025-05-10 17:55:42</time></p><p class="title"><a href="/2025/05/10/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/Shell%E8%84%9A%E6%9C%AC/">Shell脚本</a></p><p class="categories"><a href="/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/">自动化运维</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Kubernetes/"><span class="level-start"><span class="level-item">Kubernetes</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"><span class="level-start"><span class="level-item">容器技术</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="level-start"><span class="level-item">数据库</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"><span class="level-start"><span class="level-item">自动化运维</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Ansible%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"><span class="tag">Ansible的基本使用</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kubernetes%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%BF%90%E7%BB%B4/"><span class="tag">Kubernetes企业级运维</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kubernetes%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"><span class="tag">Kubernetes网络系统原理</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux%E5%91%BD%E4%BB%A4/"><span class="tag">Linux命令</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"><span class="tag">Linux的基本使用</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux%E7%9A%84%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1/"><span class="tag">Linux的基础服务</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux%E8%BF%9B%E9%98%B6/"><span class="tag">Linux进阶</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">MySQL数据库</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell%E8%84%9A%E6%9C%AC/"><span class="tag">Shell脚本</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/podman%E5%AE%B9%E5%99%A8/"><span class="tag">podman容器</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%B9%E5%99%A8-K8S/"><span class="tag">容器&amp;K8S</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Linux技术博客</a><p class="size-small"><span>&copy; 2021-2025</span>  Powered by 罗宇 <br><span>© <a href="http://www.beian.miit.gov.cn/" target="_blank">川ICP备88888888号</a><br></span><span>© 版权说明:本网站所有内容均自己创作,方便用于技术交流和日常总结!<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2021/12/17 00:00:00')", 250,"");</script><br></span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(false){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('undefined','undefined','undefined','undefined',undefined);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>